PEMSBAY
--------- DMRCMLP ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        15,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "adaptive_mask": true,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 74418540,
    "gpu": [
        6
    ],
    "save": false,
    "model_args": {
        "num_nodes": 325,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        385,212
├─Linear: 1-1                                 [16, 12, 325, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 325, 48]         --
│    └─Embedding: 2-1                         [16, 12, 325, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 325, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 325, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 325, 144]        158,224
├─Predictor: 1-4                              [16, 12, 325, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 325, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 325, 144]        41,760
│    └─Linear: 2-6                            [16, 325, 12]             20,748
===============================================================================================
Total params: 1,129,504
Trainable params: 1,129,504
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.75
Forward/backward pass size (MB): 2847.94
Params size (MB): 2.98
Estimated Total Size (MB): 2851.66
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMSBAY-2025-01-19-05-04-50.pt
2025-01-19 05:08:29.556483 Epoch 1, Train Y Loss = 2.05823,  Train X Loss = 1.01957, Val Loss = 1.98593
2025-01-19 05:12:08.857806 Epoch 2, Train Y Loss = 1.72413,  Train X Loss = 0.81281, Val Loss = 1.79210
2025-01-19 05:15:48.004899 Epoch 3, Train Y Loss = 1.62938,  Train X Loss = 0.78295, Val Loss = 1.73794
2025-01-19 05:19:27.256202 Epoch 4, Train Y Loss = 1.58632,  Train X Loss = 0.76917, Val Loss = 1.69393
2025-01-19 05:23:06.494474 Epoch 5, Train Y Loss = 1.55712,  Train X Loss = 0.75484, Val Loss = 1.68808
2025-01-19 05:26:45.646096 Epoch 6, Train Y Loss = 1.53696,  Train X Loss = 0.70303, Val Loss = 1.68612
2025-01-19 05:30:24.937220 Epoch 7, Train Y Loss = 1.51974,  Train X Loss = 0.67072, Val Loss = 1.62426
2025-01-19 05:34:03.987235 Epoch 8, Train Y Loss = 1.50254,  Train X Loss = 0.66012, Val Loss = 1.63574
2025-01-19 05:37:42.839616 Epoch 9, Train Y Loss = 1.49233,  Train X Loss = 0.65363, Val Loss = 1.64063
2025-01-19 05:41:21.370072 Epoch 10, Train Y Loss = 1.48260,  Train X Loss = 0.65022, Val Loss = 1.59945
2025-01-19 05:44:59.770644 Epoch 11, Train Y Loss = 1.47459,  Train X Loss = 0.64678, Val Loss = 1.61178
2025-01-19 05:48:38.151209 Epoch 12, Train Y Loss = 1.46786,  Train X Loss = 0.64368, Val Loss = 1.59015
2025-01-19 05:52:16.760584 Epoch 13, Train Y Loss = 1.46321,  Train X Loss = 0.64207, Val Loss = 1.60094
2025-01-19 05:55:55.688881 Epoch 14, Train Y Loss = 1.45788,  Train X Loss = 0.63961, Val Loss = 1.59630
2025-01-19 05:59:34.054616 Epoch 15, Train Y Loss = 1.45215,  Train X Loss = 0.63816, Val Loss = 1.59538
2025-01-19 06:03:12.351296 Epoch 16, Train Y Loss = 1.40310,  Train X Loss = 0.61915, Val Loss = 1.54121
2025-01-19 06:06:51.156286 Epoch 17, Train Y Loss = 1.39371,  Train X Loss = 0.61681, Val Loss = 1.55450
2025-01-19 06:10:29.716202 Epoch 18, Train Y Loss = 1.38941,  Train X Loss = 0.61557, Val Loss = 1.54950
2025-01-19 06:14:08.486171 Epoch 19, Train Y Loss = 1.38581,  Train X Loss = 0.61547, Val Loss = 1.53928
2025-01-19 06:17:47.077474 Epoch 20, Train Y Loss = 1.38338,  Train X Loss = 0.61478, Val Loss = 1.55615
2025-01-19 06:21:25.711908 Epoch 21, Train Y Loss = 1.38141,  Train X Loss = 0.61383, Val Loss = 1.53670
2025-01-19 06:25:04.328465 Epoch 22, Train Y Loss = 1.37934,  Train X Loss = 0.61348, Val Loss = 1.53734
2025-01-19 06:28:43.081848 Epoch 23, Train Y Loss = 1.37694,  Train X Loss = 0.61336, Val Loss = 1.54109
2025-01-19 06:32:21.798988 Epoch 24, Train Y Loss = 1.37507,  Train X Loss = 0.61288, Val Loss = 1.53407
2025-01-19 06:36:00.704884 Epoch 25, Train Y Loss = 1.37351,  Train X Loss = 0.61251, Val Loss = 1.53771
2025-01-19 06:39:39.158003 Epoch 26, Train Y Loss = 1.37213,  Train X Loss = 0.61200, Val Loss = 1.53675
2025-01-19 06:43:17.913359 Epoch 27, Train Y Loss = 1.37006,  Train X Loss = 0.61194, Val Loss = 1.54009
2025-01-19 06:46:56.510245 Epoch 28, Train Y Loss = 1.36814,  Train X Loss = 0.61147, Val Loss = 1.55058
2025-01-19 06:50:34.870757 Epoch 29, Train Y Loss = 1.36771,  Train X Loss = 0.61178, Val Loss = 1.53644
2025-01-19 06:54:13.229294 Epoch 30, Train Y Loss = 1.36595,  Train X Loss = 0.61116, Val Loss = 1.54286
2025-01-19 06:57:52.042553 Epoch 31, Train Y Loss = 1.36435,  Train X Loss = 0.61090, Val Loss = 1.54163
2025-01-19 07:01:30.424389 Epoch 32, Train Y Loss = 1.36345,  Train X Loss = 0.61096, Val Loss = 1.56010
Change mask ratio: 0.075
2025-01-19 07:05:06.877435 Epoch 33, Train Y Loss = 1.35599,  Train X Loss = 0.29253, Val Loss = 1.54188
2025-01-19 07:08:43.867897 Epoch 34, Train Y Loss = 1.35332,  Train X Loss = 0.29324, Val Loss = 1.54497
2025-01-19 07:12:19.697545 Epoch 35, Train Y Loss = 1.35156,  Train X Loss = 0.29372, Val Loss = 1.53863
2025-01-19 07:15:56.407478 Epoch 36, Train Y Loss = 1.34244,  Train X Loss = 0.29289, Val Loss = 1.53996
2025-01-19 07:19:33.132777 Epoch 37, Train Y Loss = 1.34025,  Train X Loss = 0.29260, Val Loss = 1.54812
2025-01-19 07:23:09.853456 Epoch 38, Train Y Loss = 1.33984,  Train X Loss = 0.29272, Val Loss = 1.54416
2025-01-19 07:26:46.690269 Epoch 39, Train Y Loss = 1.33934,  Train X Loss = 0.29249, Val Loss = 1.54284
2025-01-19 07:30:23.574570 Epoch 40, Train Y Loss = 1.33874,  Train X Loss = 0.29255, Val Loss = 1.53997
Change mask ratio: 0.0375
2025-01-19 07:33:59.648545 Epoch 41, Train Y Loss = 1.33565,  Train X Loss = 0.14314, Val Loss = 1.53644
2025-01-19 07:37:35.853018 Epoch 42, Train Y Loss = 1.33532,  Train X Loss = 0.14341, Val Loss = 1.53804
2025-01-19 07:41:11.887110 Epoch 43, Train Y Loss = 1.33448,  Train X Loss = 0.14343, Val Loss = 1.53789
2025-01-19 07:44:47.909211 Epoch 44, Train Y Loss = 1.33489,  Train X Loss = 0.14361, Val Loss = 1.54416
2025-01-19 07:48:23.946699 Epoch 45, Train Y Loss = 1.33401,  Train X Loss = 0.14349, Val Loss = 1.54371
2025-01-19 07:51:59.884056 Epoch 46, Train Y Loss = 1.33401,  Train X Loss = 0.14363, Val Loss = 1.54205
2025-01-19 07:55:35.808471 Epoch 47, Train Y Loss = 1.33276,  Train X Loss = 0.14384, Val Loss = 1.54038
2025-01-19 07:59:11.420657 Epoch 48, Train Y Loss = 1.33249,  Train X Loss = 0.14386, Val Loss = 1.54464
Change mask ratio: 0.0
2025-01-19 08:02:30.951023 Epoch 49, Train Y Loss = 1.32949,  Train X Loss = 0.00000, Val Loss = 1.53536
2025-01-19 08:05:50.497097 Epoch 50, Train Y Loss = 1.32848,  Train X Loss = 0.00000, Val Loss = 1.54141
2025-01-19 08:09:10.105472 Epoch 51, Train Y Loss = 1.32749,  Train X Loss = 0.00000, Val Loss = 1.53931
2025-01-19 08:12:29.709486 Epoch 52, Train Y Loss = 1.32747,  Train X Loss = 0.00000, Val Loss = 1.54126
2025-01-19 08:15:49.252345 Epoch 53, Train Y Loss = 1.32756,  Train X Loss = 0.00000, Val Loss = 1.53839
2025-01-19 08:19:08.733340 Epoch 54, Train Y Loss = 1.32673,  Train X Loss = 0.00000, Val Loss = 1.53956
Early stopping at epoch: 54
Best at epoch 24:
Train Loss = 1.37507
Train RMSE = 3.02521, MAE = 1.34746, MAPE = 2.88592
Val Loss = 1.53407
Val RMSE = 3.51176, MAE = 1.53237, MAPE = 3.45576
--------- Test ---------
All Steps RMSE = 3.47366, MAE = 1.52101, MAPE = 3.39145
Step 1 RMSE = 1.54648, MAE = 0.84560, MAPE = 1.61847
Step 2 RMSE = 2.20989, MAE = 1.10989, MAPE = 2.22684
Step 3 RMSE = 2.70245, MAE = 1.28446, MAPE = 2.66723
Step 4 RMSE = 3.07176, MAE = 1.41152, MAPE = 3.01319
Step 5 RMSE = 3.34860, MAE = 1.50723, MAPE = 3.29501
Step 6 RMSE = 3.56329, MAE = 1.58343, MAPE = 3.52725
Step 7 RMSE = 3.73457, MAE = 1.64455, MAPE = 3.71928
Step 8 RMSE = 3.87432, MAE = 1.69536, MAPE = 3.88536
Step 9 RMSE = 3.98732, MAE = 1.73864, MAPE = 4.02221
Step 10 RMSE = 4.08250, MAE = 1.77610, MAPE = 4.14356
Step 11 RMSE = 4.16440, MAE = 1.81001, MAPE = 4.24058
Step 12 RMSE = 4.24337, MAE = 1.84528, MAPE = 4.33850
Inference time: 18.46 s
