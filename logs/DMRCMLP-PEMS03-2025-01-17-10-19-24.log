PEMS03
--------- DMRCMLP ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        50
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 51970489,
    "gpu": [
        3
    ],
    "save": false,
    "model_args": {
        "num_nodes": 358,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        434,604
├─Linear: 1-1                                 [16, 12, 358, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 358, 48]         --
│    └─Embedding: 2-1                         [16, 12, 358, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 358, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 358, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 358, 144]        158,224
├─Predictor: 1-4                              [16, 12, 358, 1]          --
│    └─Linear: 2-5                            [16, 12, 358, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 358, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 358, 144]        41,760
│    └─Linear: 2-7                            [16, 358, 12]             20,748
===============================================================================================
Total params: 1,199,776
Trainable params: 1,199,776
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.82
Forward/backward pass size (MB): 3216.29
Params size (MB): 3.06
Estimated Total Size (MB): 3220.18
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS03-2025-01-17-10-19-24.pt
2025-01-17 10:21:38.904383 Epoch 1, Train Y Loss = 21.99335,  Train X Loss = 16.37224, Val Loss = 16.76627
2025-01-17 10:23:53.049856 Epoch 2, Train Y Loss = 16.66285,  Train X Loss = 12.95024, Val Loss = 17.09099
2025-01-17 10:26:07.315997 Epoch 3, Train Y Loss = 15.63065,  Train X Loss = 12.57154, Val Loss = 15.69990
2025-01-17 10:28:22.662275 Epoch 4, Train Y Loss = 15.04411,  Train X Loss = 11.42252, Val Loss = 14.87267
2025-01-17 10:30:38.072915 Epoch 5, Train Y Loss = 14.74235,  Train X Loss = 9.39933, Val Loss = 14.30623
2025-01-17 10:32:53.490306 Epoch 6, Train Y Loss = 14.26338,  Train X Loss = 8.80829, Val Loss = 14.64446
2025-01-17 10:35:09.189967 Epoch 7, Train Y Loss = 14.07948,  Train X Loss = 8.64679, Val Loss = 13.74667
2025-01-17 10:37:24.868897 Epoch 8, Train Y Loss = 13.81816,  Train X Loss = 8.41215, Val Loss = 13.88910
2025-01-17 10:39:40.556386 Epoch 9, Train Y Loss = 13.65563,  Train X Loss = 8.27736, Val Loss = 13.54298
2025-01-17 10:41:56.276754 Epoch 10, Train Y Loss = 13.52659,  Train X Loss = 8.15861, Val Loss = 14.01664
2025-01-17 10:44:11.963770 Epoch 11, Train Y Loss = 13.40228,  Train X Loss = 8.07057, Val Loss = 13.65286
2025-01-17 10:46:27.507778 Epoch 12, Train Y Loss = 13.25877,  Train X Loss = 8.03591, Val Loss = 13.55224
2025-01-17 10:48:43.122513 Epoch 13, Train Y Loss = 13.16045,  Train X Loss = 7.91363, Val Loss = 13.43715
2025-01-17 10:50:58.860088 Epoch 14, Train Y Loss = 13.13891,  Train X Loss = 7.89204, Val Loss = 13.47087
2025-01-17 10:53:14.314860 Epoch 15, Train Y Loss = 13.00725,  Train X Loss = 7.85463, Val Loss = 13.89634
2025-01-17 10:55:29.819487 Epoch 16, Train Y Loss = 12.97022,  Train X Loss = 7.79818, Val Loss = 13.38388
2025-01-17 10:57:45.240327 Epoch 17, Train Y Loss = 12.88360,  Train X Loss = 7.75777, Val Loss = 13.32632
2025-01-17 11:00:00.794163 Epoch 18, Train Y Loss = 12.83841,  Train X Loss = 7.69109, Val Loss = 13.22132
2025-01-17 11:02:16.372158 Epoch 19, Train Y Loss = 12.78839,  Train X Loss = 7.71393, Val Loss = 13.30072
2025-01-17 11:04:31.979394 Epoch 20, Train Y Loss = 12.74099,  Train X Loss = 7.66198, Val Loss = 13.21974
2025-01-17 11:06:47.663109 Epoch 21, Train Y Loss = 12.20192,  Train X Loss = 7.36766, Val Loss = 12.86762
2025-01-17 11:09:03.217259 Epoch 22, Train Y Loss = 12.14447,  Train X Loss = 7.32127, Val Loss = 12.92147
2025-01-17 11:11:18.746406 Epoch 23, Train Y Loss = 12.12037,  Train X Loss = 7.31105, Val Loss = 12.91864
2025-01-17 11:13:34.339947 Epoch 24, Train Y Loss = 12.10248,  Train X Loss = 7.30500, Val Loss = 12.89144
2025-01-17 11:15:49.916843 Epoch 25, Train Y Loss = 12.08869,  Train X Loss = 7.29205, Val Loss = 12.87859
2025-01-17 11:18:05.453914 Epoch 26, Train Y Loss = 12.07304,  Train X Loss = 7.28535, Val Loss = 12.93080
2025-01-17 11:20:20.968221 Epoch 27, Train Y Loss = 12.06016,  Train X Loss = 7.27518, Val Loss = 12.87867
2025-01-17 11:22:36.521584 Epoch 28, Train Y Loss = 12.04772,  Train X Loss = 7.26858, Val Loss = 12.83882
2025-01-17 11:24:52.032184 Epoch 29, Train Y Loss = 12.04008,  Train X Loss = 7.26195, Val Loss = 12.87099
2025-01-17 11:27:07.569633 Epoch 30, Train Y Loss = 12.02577,  Train X Loss = 7.25946, Val Loss = 12.86197
2025-01-17 11:29:23.135232 Epoch 31, Train Y Loss = 12.02032,  Train X Loss = 7.25302, Val Loss = 12.93675
2025-01-17 11:31:38.622727 Epoch 32, Train Y Loss = 12.00849,  Train X Loss = 7.24195, Val Loss = 12.89514
2025-01-17 11:33:54.160242 Epoch 33, Train Y Loss = 11.99879,  Train X Loss = 7.24264, Val Loss = 12.86889
2025-01-17 11:36:09.645221 Epoch 34, Train Y Loss = 11.99210,  Train X Loss = 7.23948, Val Loss = 12.85640
2025-01-17 11:38:25.168827 Epoch 35, Train Y Loss = 11.98388,  Train X Loss = 7.23306, Val Loss = 12.98873
2025-01-17 11:40:40.684874 Epoch 36, Train Y Loss = 11.91472,  Train X Loss = 7.20010, Val Loss = 12.83613
2025-01-17 11:42:56.235712 Epoch 37, Train Y Loss = 11.90501,  Train X Loss = 7.19692, Val Loss = 12.85533
2025-01-17 11:45:11.873984 Epoch 38, Train Y Loss = 11.90211,  Train X Loss = 7.19585, Val Loss = 12.85341
2025-01-17 11:47:27.504360 Epoch 39, Train Y Loss = 11.90070,  Train X Loss = 7.18754, Val Loss = 12.82828
2025-01-17 11:49:43.195932 Epoch 40, Train Y Loss = 11.89801,  Train X Loss = 7.19359, Val Loss = 12.84222
2025-01-17 11:52:01.563003 Epoch 41, Train Y Loss = 11.89754,  Train X Loss = 7.18852, Val Loss = 12.84649
2025-01-17 11:54:21.154224 Epoch 42, Train Y Loss = 11.89477,  Train X Loss = 7.18913, Val Loss = 12.83935
2025-01-17 11:56:40.074594 Epoch 43, Train Y Loss = 11.89339,  Train X Loss = 7.19132, Val Loss = 12.83037
2025-01-17 11:58:56.173007 Epoch 44, Train Y Loss = 11.89251,  Train X Loss = 7.18718, Val Loss = 12.85590
2025-01-17 12:01:12.149349 Epoch 45, Train Y Loss = 11.89071,  Train X Loss = 7.18216, Val Loss = 12.86660
2025-01-17 12:03:28.154408 Epoch 46, Train Y Loss = 11.88966,  Train X Loss = 7.18064, Val Loss = 12.86444
2025-01-17 12:05:44.105609 Epoch 47, Train Y Loss = 11.88909,  Train X Loss = 7.18923, Val Loss = 12.86001
2025-01-17 12:07:59.939030 Epoch 48, Train Y Loss = 11.88662,  Train X Loss = 7.19048, Val Loss = 12.84412
2025-01-17 12:10:15.366765 Epoch 49, Train Y Loss = 11.88574,  Train X Loss = 7.18441, Val Loss = 12.83164
2025-01-17 12:12:30.783503 Epoch 50, Train Y Loss = 11.88426,  Train X Loss = 7.18608, Val Loss = 12.86787
2025-01-17 12:14:46.227597 Epoch 51, Train Y Loss = 11.87606,  Train X Loss = 7.18030, Val Loss = 12.85072
2025-01-17 12:17:01.617371 Epoch 52, Train Y Loss = 11.87497,  Train X Loss = 7.17927, Val Loss = 12.84793
2025-01-17 12:19:17.024946 Epoch 53, Train Y Loss = 11.87503,  Train X Loss = 7.18168, Val Loss = 12.85364
2025-01-17 12:21:34.642254 Epoch 54, Train Y Loss = 11.87430,  Train X Loss = 7.17594, Val Loss = 12.84975
2025-01-17 12:23:52.248814 Epoch 55, Train Y Loss = 11.87489,  Train X Loss = 7.18079, Val Loss = 12.84453
2025-01-17 12:26:09.304789 Epoch 56, Train Y Loss = 11.87469,  Train X Loss = 7.17566, Val Loss = 12.85078
2025-01-17 12:28:26.402630 Epoch 57, Train Y Loss = 11.87402,  Train X Loss = 7.17762, Val Loss = 12.84765
2025-01-17 12:30:43.300896 Epoch 58, Train Y Loss = 11.87330,  Train X Loss = 7.17842, Val Loss = 12.85073
2025-01-17 12:33:00.222029 Epoch 59, Train Y Loss = 11.87390,  Train X Loss = 7.18210, Val Loss = 12.85560
Early stopping at epoch: 59
Best at epoch 39:
Train Loss = 11.90070
Train RMSE = 20.37818, MAE = 12.37157, MAPE = 11.34940
Val Loss = 12.82828
Val RMSE = 21.60652, MAE = 13.36126, MAPE = 12.61859
--------- Test ---------
All Steps RMSE = 25.56571, MAE = 14.88020, MAPE = 14.96328
Step 1 RMSE = 19.48813, MAE = 12.15989, MAPE = 12.64615
Step 2 RMSE = 21.50925, MAE = 13.00456, MAPE = 13.48101
Step 3 RMSE = 22.94781, MAE = 13.61045, MAPE = 14.02497
Step 4 RMSE = 24.13345, MAE = 14.11805, MAPE = 14.32911
Step 5 RMSE = 25.01544, MAE = 14.53373, MAPE = 14.61266
Step 6 RMSE = 25.71181, MAE = 14.89224, MAPE = 14.89671
Step 7 RMSE = 26.38978, MAE = 15.26308, MAPE = 15.19856
Step 8 RMSE = 26.95051, MAE = 15.58201, MAPE = 15.52865
Step 9 RMSE = 27.47197, MAE = 15.89567, MAPE = 15.77244
Step 10 RMSE = 27.95151, MAE = 16.19264, MAPE = 16.09593
Step 11 RMSE = 28.44384, MAE = 16.49111, MAPE = 16.35800
Step 12 RMSE = 28.93319, MAE = 16.81905, MAPE = 16.61520
Inference time: 11.19 s
