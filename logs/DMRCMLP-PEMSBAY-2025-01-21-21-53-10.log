PEMSBAY
--------- DMRCMLP ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        15,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        6
    ],
    "save": false,
    "model_args": {
        "num_nodes": 325,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        385,212
├─Linear: 1-1                                 [16, 12, 325, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 325, 48]         --
│    └─Embedding: 2-1                         [16, 12, 325, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 325, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 325, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 325, 144]        158,224
├─Predictor: 1-4                              [16, 12, 325, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 325, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 325, 144]        41,760
│    └─Linear: 2-6                            [16, 325, 12]             20,748
===============================================================================================
Total params: 1,129,504
Trainable params: 1,129,504
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.75
Forward/backward pass size (MB): 2847.94
Params size (MB): 2.98
Estimated Total Size (MB): 2851.66
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMSBAY-2025-01-21-21-53-10.pt
2025-01-21 21:56:22.888773 Epoch 1, Train Y Loss = 2.02459,  Train X Loss = 0.00000, Val Loss = 1.82478
2025-01-21 21:59:34.757441 Epoch 2, Train Y Loss = 1.65356,  Train X Loss = 0.00000, Val Loss = 1.78105
2025-01-21 22:02:46.697207 Epoch 3, Train Y Loss = 1.58815,  Train X Loss = 0.00000, Val Loss = 1.70521
2025-01-21 22:05:58.535338 Epoch 4, Train Y Loss = 1.54503,  Train X Loss = 0.00000, Val Loss = 1.68856
2025-01-21 22:09:10.316820 Epoch 5, Train Y Loss = 1.51811,  Train X Loss = 0.00000, Val Loss = 1.63570
2025-01-21 22:12:22.134061 Epoch 6, Train Y Loss = 1.49246,  Train X Loss = 0.00000, Val Loss = 1.61447
2025-01-21 22:15:33.981795 Epoch 7, Train Y Loss = 1.47345,  Train X Loss = 0.00000, Val Loss = 1.61436
2025-01-21 22:18:45.666359 Epoch 8, Train Y Loss = 1.45814,  Train X Loss = 0.00000, Val Loss = 1.60685
2025-01-21 22:22:02.680773 Epoch 9, Train Y Loss = 1.44513,  Train X Loss = 0.00000, Val Loss = 1.61385
2025-01-21 22:25:21.230332 Epoch 10, Train Y Loss = 1.43337,  Train X Loss = 0.00000, Val Loss = 1.59864
2025-01-21 22:28:36.603724 Epoch 11, Train Y Loss = 1.42281,  Train X Loss = 0.00000, Val Loss = 1.58929
2025-01-21 22:31:48.378108 Epoch 12, Train Y Loss = 1.41378,  Train X Loss = 0.00000, Val Loss = 1.60144
2025-01-21 22:35:00.123108 Epoch 13, Train Y Loss = 1.40594,  Train X Loss = 0.00000, Val Loss = 1.59782
2025-01-21 22:38:11.641655 Epoch 14, Train Y Loss = 1.39604,  Train X Loss = 0.00000, Val Loss = 1.57484
2025-01-21 22:41:23.081564 Epoch 15, Train Y Loss = 1.38824,  Train X Loss = 0.00000, Val Loss = 1.58893
2025-01-21 22:44:34.616111 Epoch 16, Train Y Loss = 1.33211,  Train X Loss = 0.00000, Val Loss = 1.55663
2025-01-21 22:47:46.315696 Epoch 17, Train Y Loss = 1.31759,  Train X Loss = 0.00000, Val Loss = 1.55130
2025-01-21 22:50:58.025258 Epoch 18, Train Y Loss = 1.31034,  Train X Loss = 0.00000, Val Loss = 1.55384
2025-01-21 22:54:09.779786 Epoch 19, Train Y Loss = 1.30527,  Train X Loss = 0.00000, Val Loss = 1.56058
2025-01-21 22:57:21.587965 Epoch 20, Train Y Loss = 1.29960,  Train X Loss = 0.00000, Val Loss = 1.56168
2025-01-21 23:00:33.441505 Epoch 21, Train Y Loss = 1.29519,  Train X Loss = 0.00000, Val Loss = 1.56194
2025-01-21 23:03:47.557483 Epoch 22, Train Y Loss = 1.29122,  Train X Loss = 0.00000, Val Loss = 1.56181
2025-01-21 23:06:59.446469 Epoch 23, Train Y Loss = 1.28704,  Train X Loss = 0.00000, Val Loss = 1.56240
2025-01-21 23:10:11.057933 Epoch 24, Train Y Loss = 1.28322,  Train X Loss = 0.00000, Val Loss = 1.56172
2025-01-21 23:13:22.855526 Epoch 25, Train Y Loss = 1.27978,  Train X Loss = 0.00000, Val Loss = 1.56175
2025-01-21 23:16:34.759260 Epoch 26, Train Y Loss = 1.27601,  Train X Loss = 0.00000, Val Loss = 1.57596
2025-01-21 23:19:46.759644 Epoch 27, Train Y Loss = 1.27312,  Train X Loss = 0.00000, Val Loss = 1.57492
2025-01-21 23:22:58.772153 Epoch 28, Train Y Loss = 1.26920,  Train X Loss = 0.00000, Val Loss = 1.57679
2025-01-21 23:26:10.712828 Epoch 29, Train Y Loss = 1.26651,  Train X Loss = 0.00000, Val Loss = 1.56578
2025-01-21 23:29:23.054883 Epoch 30, Train Y Loss = 1.26330,  Train X Loss = 0.00000, Val Loss = 1.57474
2025-01-21 23:32:34.665810 Epoch 31, Train Y Loss = 1.26015,  Train X Loss = 0.00000, Val Loss = 1.56799
2025-01-21 23:35:46.514420 Epoch 32, Train Y Loss = 1.25704,  Train X Loss = 0.00000, Val Loss = 1.57504
2025-01-21 23:38:58.409138 Epoch 33, Train Y Loss = 1.25424,  Train X Loss = 0.00000, Val Loss = 1.57406
2025-01-21 23:42:10.733083 Epoch 34, Train Y Loss = 1.25114,  Train X Loss = 0.00000, Val Loss = 1.57483
2025-01-21 23:45:22.561047 Epoch 35, Train Y Loss = 1.24933,  Train X Loss = 0.00000, Val Loss = 1.57476
2025-01-21 23:48:34.723211 Epoch 36, Train Y Loss = 1.23724,  Train X Loss = 0.00000, Val Loss = 1.57583
2025-01-21 23:51:46.606492 Epoch 37, Train Y Loss = 1.23514,  Train X Loss = 0.00000, Val Loss = 1.57786
2025-01-21 23:54:58.297897 Epoch 38, Train Y Loss = 1.23403,  Train X Loss = 0.00000, Val Loss = 1.57780
2025-01-21 23:58:10.180670 Epoch 39, Train Y Loss = 1.23334,  Train X Loss = 0.00000, Val Loss = 1.57739
2025-01-22 00:01:22.532379 Epoch 40, Train Y Loss = 1.23262,  Train X Loss = 0.00000, Val Loss = 1.57795
2025-01-22 00:04:34.474949 Epoch 41, Train Y Loss = 1.23209,  Train X Loss = 0.00000, Val Loss = 1.57813
2025-01-22 00:07:46.352093 Epoch 42, Train Y Loss = 1.23135,  Train X Loss = 0.00000, Val Loss = 1.57706
2025-01-22 00:10:58.115766 Epoch 43, Train Y Loss = 1.23108,  Train X Loss = 0.00000, Val Loss = 1.57829
2025-01-22 00:14:09.962749 Epoch 44, Train Y Loss = 1.23047,  Train X Loss = 0.00000, Val Loss = 1.57757
2025-01-22 00:17:21.885349 Epoch 45, Train Y Loss = 1.23035,  Train X Loss = 0.00000, Val Loss = 1.57671
2025-01-22 00:20:34.207054 Epoch 46, Train Y Loss = 1.23021,  Train X Loss = 0.00000, Val Loss = 1.58005
2025-01-22 00:23:46.495235 Epoch 47, Train Y Loss = 1.22984,  Train X Loss = 0.00000, Val Loss = 1.58062
Early stopping at epoch: 47
Best at epoch 17:
Train Loss = 1.31759
Train RMSE = 2.88221, MAE = 1.29364, MAPE = 2.73268
Val Loss = 1.55130
Val RMSE = 3.61301, MAE = 1.54942, MAPE = 3.52938
--------- Test ---------
All Steps RMSE = 3.61361, MAE = 1.56417, MAPE = 3.48619
Step 1 RMSE = 1.65459, MAE = 0.86440, MAPE = 1.66907
Step 2 RMSE = 2.32283, MAE = 1.13791, MAPE = 2.31314
Step 3 RMSE = 2.83645, MAE = 1.32008, MAPE = 2.78289
Step 4 RMSE = 3.22422, MAE = 1.45178, MAPE = 3.14580
Step 5 RMSE = 3.51339, MAE = 1.55216, MAPE = 3.42917
Step 6 RMSE = 3.73207, MAE = 1.63110, MAPE = 3.65736
Step 7 RMSE = 3.90199, MAE = 1.69474, MAPE = 3.84078
Step 8 RMSE = 4.03067, MAE = 1.74493, MAPE = 3.98550
Step 9 RMSE = 4.13342, MAE = 1.78838, MAPE = 4.10543
Step 10 RMSE = 4.21768, MAE = 1.82673, MAPE = 4.20918
Step 11 RMSE = 4.29379, MAE = 1.86141, MAPE = 4.30237
Step 12 RMSE = 4.36686, MAE = 1.89646, MAPE = 4.39358
Inference time: 18.12 s
