PEMS03
--------- DMRCMLP ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        50
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        3
    ],
    "save": false,
    "model_args": {
        "num_nodes": 358,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        434,604
├─Linear: 1-1                                 [16, 12, 358, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 358, 48]         --
│    └─Embedding: 2-1                         [16, 12, 358, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 358, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 358, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 358, 144]        158,224
├─Predictor: 1-4                              [16, 12, 358, 1]          --
│    └─Linear: 2-5                            [16, 12, 358, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 358, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 358, 144]        41,760
│    └─Linear: 2-7                            [16, 358, 12]             20,748
===============================================================================================
Total params: 1,199,776
Trainable params: 1,199,776
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.82
Forward/backward pass size (MB): 3216.29
Params size (MB): 3.06
Estimated Total Size (MB): 3220.18
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS03-2025-01-18-17-11-12.pt
2025-01-18 17:13:00.013286 Epoch 1, Train Y Loss = 20.86847,  Train X Loss = 0.00000, Val Loss = 17.72289
2025-01-18 17:14:48.055123 Epoch 2, Train Y Loss = 16.29708,  Train X Loss = 0.00000, Val Loss = 16.62173
2025-01-18 17:16:35.685597 Epoch 3, Train Y Loss = 15.21956,  Train X Loss = 0.00000, Val Loss = 15.13374
2025-01-18 17:18:23.145090 Epoch 4, Train Y Loss = 14.73867,  Train X Loss = 0.00000, Val Loss = 14.48467
2025-01-18 17:20:10.779772 Epoch 5, Train Y Loss = 14.32905,  Train X Loss = 0.00000, Val Loss = 14.74302
2025-01-18 17:21:58.482594 Epoch 6, Train Y Loss = 14.07850,  Train X Loss = 0.00000, Val Loss = 14.36003
2025-01-18 17:23:46.102711 Epoch 7, Train Y Loss = 13.79156,  Train X Loss = 0.00000, Val Loss = 14.10694
2025-01-18 17:25:33.958175 Epoch 8, Train Y Loss = 13.60232,  Train X Loss = 0.00000, Val Loss = 14.08081
2025-01-18 17:27:21.747109 Epoch 9, Train Y Loss = 13.46543,  Train X Loss = 0.00000, Val Loss = 13.88804
2025-01-18 17:29:09.087833 Epoch 10, Train Y Loss = 13.24832,  Train X Loss = 0.00000, Val Loss = 13.71936
2025-01-18 17:30:56.653763 Epoch 11, Train Y Loss = 13.07770,  Train X Loss = 0.00000, Val Loss = 13.65232
2025-01-18 17:32:44.357702 Epoch 12, Train Y Loss = 13.02407,  Train X Loss = 0.00000, Val Loss = 13.53004
2025-01-18 17:34:32.106579 Epoch 13, Train Y Loss = 12.90546,  Train X Loss = 0.00000, Val Loss = 13.35446
2025-01-18 17:36:19.935246 Epoch 14, Train Y Loss = 12.83170,  Train X Loss = 0.00000, Val Loss = 13.36046
2025-01-18 17:38:08.199727 Epoch 15, Train Y Loss = 12.74257,  Train X Loss = 0.00000, Val Loss = 13.34807
2025-01-18 17:39:56.424951 Epoch 16, Train Y Loss = 12.64823,  Train X Loss = 0.00000, Val Loss = 13.46355
2025-01-18 17:41:44.815123 Epoch 17, Train Y Loss = 12.60769,  Train X Loss = 0.00000, Val Loss = 13.27462
2025-01-18 17:43:32.813398 Epoch 18, Train Y Loss = 12.54612,  Train X Loss = 0.00000, Val Loss = 13.17233
2025-01-18 17:45:20.406376 Epoch 19, Train Y Loss = 12.47346,  Train X Loss = 0.00000, Val Loss = 13.32533
2025-01-18 17:47:07.974352 Epoch 20, Train Y Loss = 12.39108,  Train X Loss = 0.00000, Val Loss = 13.25324
2025-01-18 17:48:55.422608 Epoch 21, Train Y Loss = 11.92675,  Train X Loss = 0.00000, Val Loss = 12.95231
2025-01-18 17:50:43.143853 Epoch 22, Train Y Loss = 11.85591,  Train X Loss = 0.00000, Val Loss = 12.92664
2025-01-18 17:52:30.426958 Epoch 23, Train Y Loss = 11.82907,  Train X Loss = 0.00000, Val Loss = 12.95982
2025-01-18 17:54:17.989027 Epoch 24, Train Y Loss = 11.80772,  Train X Loss = 0.00000, Val Loss = 12.94610
2025-01-18 17:56:05.230188 Epoch 25, Train Y Loss = 11.78823,  Train X Loss = 0.00000, Val Loss = 12.96648
2025-01-18 17:57:52.402187 Epoch 26, Train Y Loss = 11.76952,  Train X Loss = 0.00000, Val Loss = 12.92192
2025-01-18 17:59:39.468275 Epoch 27, Train Y Loss = 11.75605,  Train X Loss = 0.00000, Val Loss = 12.92780
2025-01-18 18:01:26.557617 Epoch 28, Train Y Loss = 11.74023,  Train X Loss = 0.00000, Val Loss = 12.97400
2025-01-18 18:03:13.683659 Epoch 29, Train Y Loss = 11.72466,  Train X Loss = 0.00000, Val Loss = 12.97420
2025-01-18 18:05:00.880954 Epoch 30, Train Y Loss = 11.71009,  Train X Loss = 0.00000, Val Loss = 12.91175
2025-01-18 18:06:47.952481 Epoch 31, Train Y Loss = 11.69860,  Train X Loss = 0.00000, Val Loss = 12.97980
2025-01-18 18:08:34.769533 Epoch 32, Train Y Loss = 11.68399,  Train X Loss = 0.00000, Val Loss = 12.91416
2025-01-18 18:10:21.981172 Epoch 33, Train Y Loss = 11.66961,  Train X Loss = 0.00000, Val Loss = 12.93266
2025-01-18 18:12:09.141368 Epoch 34, Train Y Loss = 11.65923,  Train X Loss = 0.00000, Val Loss = 12.96224
2025-01-18 18:13:56.547309 Epoch 35, Train Y Loss = 11.64807,  Train X Loss = 0.00000, Val Loss = 12.97332
2025-01-18 18:15:43.773244 Epoch 36, Train Y Loss = 11.58259,  Train X Loss = 0.00000, Val Loss = 12.92251
2025-01-18 18:17:31.257110 Epoch 37, Train Y Loss = 11.57446,  Train X Loss = 0.00000, Val Loss = 12.92597
2025-01-18 18:19:19.008918 Epoch 38, Train Y Loss = 11.57123,  Train X Loss = 0.00000, Val Loss = 12.92415
2025-01-18 18:21:06.065359 Epoch 39, Train Y Loss = 11.56935,  Train X Loss = 0.00000, Val Loss = 12.92515
2025-01-18 18:22:53.157013 Epoch 40, Train Y Loss = 11.56678,  Train X Loss = 0.00000, Val Loss = 12.93304
2025-01-18 18:24:40.385661 Epoch 41, Train Y Loss = 11.56491,  Train X Loss = 0.00000, Val Loss = 12.91896
2025-01-18 18:26:27.473061 Epoch 42, Train Y Loss = 11.56279,  Train X Loss = 0.00000, Val Loss = 12.92892
2025-01-18 18:28:14.839712 Epoch 43, Train Y Loss = 11.56151,  Train X Loss = 0.00000, Val Loss = 12.92865
2025-01-18 18:30:01.931445 Epoch 44, Train Y Loss = 11.55883,  Train X Loss = 0.00000, Val Loss = 12.93104
2025-01-18 18:31:49.431692 Epoch 45, Train Y Loss = 11.55797,  Train X Loss = 0.00000, Val Loss = 12.93028
2025-01-18 18:33:36.477853 Epoch 46, Train Y Loss = 11.55588,  Train X Loss = 0.00000, Val Loss = 12.92335
2025-01-18 18:35:24.397464 Epoch 47, Train Y Loss = 11.55365,  Train X Loss = 0.00000, Val Loss = 12.93965
2025-01-18 18:37:11.923718 Epoch 48, Train Y Loss = 11.55304,  Train X Loss = 0.00000, Val Loss = 12.93419
2025-01-18 18:38:59.693415 Epoch 49, Train Y Loss = 11.55107,  Train X Loss = 0.00000, Val Loss = 12.93742
2025-01-18 18:40:47.769911 Epoch 50, Train Y Loss = 11.54950,  Train X Loss = 0.00000, Val Loss = 12.92177
Early stopping at epoch: 50
Best at epoch 30:
Train Loss = 11.71009
Train RMSE = 20.13920, MAE = 12.09187, MAPE = 11.21810
Val Loss = 12.91175
Val RMSE = 21.88423, MAE = 13.43430, MAPE = 12.69724
--------- Test ---------
All Steps RMSE = 24.99873, MAE = 14.92301, MAPE = 15.05410
Step 1 RMSE = 19.51700, MAE = 12.38945, MAPE = 13.01356
Step 2 RMSE = 21.21554, MAE = 13.09130, MAPE = 13.63173
Step 3 RMSE = 22.55761, MAE = 13.67698, MAPE = 14.07574
Step 4 RMSE = 23.62176, MAE = 14.17145, MAPE = 14.42963
Step 5 RMSE = 24.38404, MAE = 14.55277, MAPE = 14.69433
Step 6 RMSE = 25.12374, MAE = 14.92906, MAPE = 14.97974
Step 7 RMSE = 25.67996, MAE = 15.25261, MAPE = 15.37853
Step 8 RMSE = 26.22164, MAE = 15.55747, MAPE = 15.54105
Step 9 RMSE = 26.73127, MAE = 15.86919, MAPE = 15.88185
Step 10 RMSE = 27.25459, MAE = 16.19896, MAPE = 16.07495
Step 11 RMSE = 27.74973, MAE = 16.51269, MAPE = 16.36660
Step 12 RMSE = 28.30459, MAE = 16.87428, MAPE = 16.58134
Inference time: 11.00 s
