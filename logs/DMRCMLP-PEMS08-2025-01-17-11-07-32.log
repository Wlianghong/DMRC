PEMS08
--------- DMRCMLP ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0015,
    "milestones": [
        30,
        50,
        70
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        2
    ],
    "save": true,
    "model_args": {
        "num_nodes": 170,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        272,172
├─Linear: 1-1                                 [16, 12, 170, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 170, 48]         --
│    └─Embedding: 2-1                         [16, 12, 170, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 170, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 170, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 170, 144]        158,224
├─Predictor: 1-4                              [16, 12, 170, 1]          --
│    └─Linear: 2-5                            [16, 12, 170, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 170, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 170, 144]        41,760
│    └─Linear: 2-7                            [16, 170, 12]             20,748
===============================================================================================
Total params: 1,037,344
Trainable params: 1,037,344
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.39
Forward/backward pass size (MB): 1527.29
Params size (MB): 3.06
Estimated Total Size (MB): 1530.74
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS08-2025-01-17-11-07-32.pt
2025-01-17 11:08:07.446092 Epoch 1, Train Y Loss = 23.38097,  Train X Loss = 0.00000, Val Loss = 18.80874
2025-01-17 11:08:42.102354 Epoch 2, Train Y Loss = 18.13686,  Train X Loss = 0.00000, Val Loss = 17.32323
2025-01-17 11:09:16.636018 Epoch 3, Train Y Loss = 17.06418,  Train X Loss = 0.00000, Val Loss = 16.24779
2025-01-17 11:09:51.361719 Epoch 4, Train Y Loss = 16.35385,  Train X Loss = 0.00000, Val Loss = 17.27916
2025-01-17 11:10:25.952524 Epoch 5, Train Y Loss = 15.98239,  Train X Loss = 0.00000, Val Loss = 16.08855
2025-01-17 11:11:00.675585 Epoch 6, Train Y Loss = 15.59170,  Train X Loss = 0.00000, Val Loss = 15.32113
2025-01-17 11:11:35.238041 Epoch 7, Train Y Loss = 15.34275,  Train X Loss = 0.00000, Val Loss = 15.10443
2025-01-17 11:12:09.907294 Epoch 8, Train Y Loss = 15.06844,  Train X Loss = 0.00000, Val Loss = 15.71894
2025-01-17 11:12:44.628242 Epoch 9, Train Y Loss = 14.84756,  Train X Loss = 0.00000, Val Loss = 15.01722
2025-01-17 11:13:19.292676 Epoch 10, Train Y Loss = 14.68749,  Train X Loss = 0.00000, Val Loss = 15.21432
2025-01-17 11:13:53.885587 Epoch 11, Train Y Loss = 14.53891,  Train X Loss = 0.00000, Val Loss = 14.54038
2025-01-17 11:14:28.490661 Epoch 12, Train Y Loss = 14.29174,  Train X Loss = 0.00000, Val Loss = 14.38328
2025-01-17 11:15:03.176364 Epoch 13, Train Y Loss = 14.22744,  Train X Loss = 0.00000, Val Loss = 14.19295
2025-01-17 11:15:37.855358 Epoch 14, Train Y Loss = 13.94699,  Train X Loss = 0.00000, Val Loss = 14.04771
2025-01-17 11:16:12.354608 Epoch 15, Train Y Loss = 13.82346,  Train X Loss = 0.00000, Val Loss = 14.05886
2025-01-17 11:16:47.070686 Epoch 16, Train Y Loss = 13.72225,  Train X Loss = 0.00000, Val Loss = 14.02170
2025-01-17 11:17:21.692922 Epoch 17, Train Y Loss = 13.56098,  Train X Loss = 0.00000, Val Loss = 13.89530
2025-01-17 11:17:56.328127 Epoch 18, Train Y Loss = 13.46886,  Train X Loss = 0.00000, Val Loss = 13.80222
2025-01-17 11:18:30.846427 Epoch 19, Train Y Loss = 13.36960,  Train X Loss = 0.00000, Val Loss = 13.78278
2025-01-17 11:19:05.401544 Epoch 20, Train Y Loss = 13.30576,  Train X Loss = 0.00000, Val Loss = 14.03276
2025-01-17 11:19:40.037367 Epoch 21, Train Y Loss = 13.24222,  Train X Loss = 0.00000, Val Loss = 13.87631
2025-01-17 11:20:14.571758 Epoch 22, Train Y Loss = 13.18331,  Train X Loss = 0.00000, Val Loss = 13.65611
2025-01-17 11:20:49.134538 Epoch 23, Train Y Loss = 13.09620,  Train X Loss = 0.00000, Val Loss = 14.19582
2025-01-17 11:21:23.715482 Epoch 24, Train Y Loss = 13.09953,  Train X Loss = 0.00000, Val Loss = 13.59180
2025-01-17 11:21:58.282662 Epoch 25, Train Y Loss = 12.95884,  Train X Loss = 0.00000, Val Loss = 13.67890
2025-01-17 11:22:32.825898 Epoch 26, Train Y Loss = 12.92809,  Train X Loss = 0.00000, Val Loss = 13.61292
2025-01-17 11:23:07.303776 Epoch 27, Train Y Loss = 12.94074,  Train X Loss = 0.00000, Val Loss = 13.53976
2025-01-17 11:23:41.932319 Epoch 28, Train Y Loss = 12.84137,  Train X Loss = 0.00000, Val Loss = 13.57502
2025-01-17 11:24:16.474713 Epoch 29, Train Y Loss = 12.80021,  Train X Loss = 0.00000, Val Loss = 13.63503
2025-01-17 11:24:50.985232 Epoch 30, Train Y Loss = 12.73256,  Train X Loss = 0.00000, Val Loss = 13.60371
2025-01-17 11:25:25.630878 Epoch 31, Train Y Loss = 12.20747,  Train X Loss = 0.00000, Val Loss = 13.21663
2025-01-17 11:26:00.252374 Epoch 32, Train Y Loss = 12.12875,  Train X Loss = 0.00000, Val Loss = 13.28986
2025-01-17 11:26:34.923755 Epoch 33, Train Y Loss = 12.10197,  Train X Loss = 0.00000, Val Loss = 13.27122
2025-01-17 11:27:09.404591 Epoch 34, Train Y Loss = 12.08203,  Train X Loss = 0.00000, Val Loss = 13.26182
2025-01-17 11:27:44.055607 Epoch 35, Train Y Loss = 12.06547,  Train X Loss = 0.00000, Val Loss = 13.28261
2025-01-17 11:28:18.707087 Epoch 36, Train Y Loss = 12.04660,  Train X Loss = 0.00000, Val Loss = 13.24894
2025-01-17 11:28:53.297441 Epoch 37, Train Y Loss = 12.03358,  Train X Loss = 0.00000, Val Loss = 13.28769
2025-01-17 11:29:27.796242 Epoch 38, Train Y Loss = 12.02027,  Train X Loss = 0.00000, Val Loss = 13.30824
2025-01-17 11:30:02.338256 Epoch 39, Train Y Loss = 12.00614,  Train X Loss = 0.00000, Val Loss = 13.35034
2025-01-17 11:30:36.969170 Epoch 40, Train Y Loss = 11.99429,  Train X Loss = 0.00000, Val Loss = 13.40581
2025-01-17 11:31:11.554944 Epoch 41, Train Y Loss = 11.98155,  Train X Loss = 0.00000, Val Loss = 13.36496
2025-01-17 11:31:46.066770 Epoch 42, Train Y Loss = 11.96876,  Train X Loss = 0.00000, Val Loss = 13.35886
2025-01-17 11:32:20.725801 Epoch 43, Train Y Loss = 11.95806,  Train X Loss = 0.00000, Val Loss = 13.41680
2025-01-17 11:32:55.338915 Epoch 44, Train Y Loss = 11.94455,  Train X Loss = 0.00000, Val Loss = 13.38239
2025-01-17 11:33:29.987437 Epoch 45, Train Y Loss = 11.93670,  Train X Loss = 0.00000, Val Loss = 13.49960
2025-01-17 11:34:04.440423 Epoch 46, Train Y Loss = 11.92875,  Train X Loss = 0.00000, Val Loss = 13.47320
2025-01-17 11:34:39.020631 Epoch 47, Train Y Loss = 11.91624,  Train X Loss = 0.00000, Val Loss = 13.41428
2025-01-17 11:35:13.624687 Epoch 48, Train Y Loss = 11.90786,  Train X Loss = 0.00000, Val Loss = 13.39352
2025-01-17 11:35:48.211061 Epoch 49, Train Y Loss = 11.89821,  Train X Loss = 0.00000, Val Loss = 13.38890
2025-01-17 11:36:22.738753 Epoch 50, Train Y Loss = 11.89115,  Train X Loss = 0.00000, Val Loss = 13.46679
2025-01-17 11:36:57.316584 Epoch 51, Train Y Loss = 11.82513,  Train X Loss = 0.00000, Val Loss = 13.43091
2025-01-17 11:37:31.887110 Epoch 52, Train Y Loss = 11.81702,  Train X Loss = 0.00000, Val Loss = 13.43463
2025-01-17 11:38:06.451554 Epoch 53, Train Y Loss = 11.81447,  Train X Loss = 0.00000, Val Loss = 13.44056
2025-01-17 11:38:40.862183 Epoch 54, Train Y Loss = 11.81132,  Train X Loss = 0.00000, Val Loss = 13.43360
2025-01-17 11:39:15.400305 Epoch 55, Train Y Loss = 11.81023,  Train X Loss = 0.00000, Val Loss = 13.42222
2025-01-17 11:39:49.919190 Epoch 56, Train Y Loss = 11.80712,  Train X Loss = 0.00000, Val Loss = 13.44965
2025-01-17 11:40:24.472464 Epoch 57, Train Y Loss = 11.80652,  Train X Loss = 0.00000, Val Loss = 13.43943
2025-01-17 11:40:58.963186 Epoch 58, Train Y Loss = 11.80591,  Train X Loss = 0.00000, Val Loss = 13.43510
2025-01-17 11:41:33.521327 Epoch 59, Train Y Loss = 11.80438,  Train X Loss = 0.00000, Val Loss = 13.42397
2025-01-17 11:42:08.146282 Epoch 60, Train Y Loss = 11.80199,  Train X Loss = 0.00000, Val Loss = 13.44514
2025-01-17 11:42:42.748362 Epoch 61, Train Y Loss = 11.80017,  Train X Loss = 0.00000, Val Loss = 13.43402
Early stopping at epoch: 61
Best at epoch 31:
Train Loss = 12.20747
Train RMSE = 21.97314, MAE = 12.45698, MAPE = 8.24837
Val Loss = 13.21663
Val RMSE = 24.62006, MAE = 13.64264, MAPE = 10.57110
--------- Test ---------
All Steps RMSE = 23.34785, MAE = 13.45882, MAPE = 8.83142
Step 1 RMSE = 19.50002, MAE = 11.69044, MAPE = 7.71107
Step 2 RMSE = 20.60367, MAE = 12.15962, MAPE = 8.00206
Step 3 RMSE = 21.48754, MAE = 12.56693, MAPE = 8.24519
Step 4 RMSE = 22.24430, MAE = 12.90547, MAPE = 8.45113
Step 5 RMSE = 22.88504, MAE = 13.20721, MAPE = 8.63053
Step 6 RMSE = 23.42339, MAE = 13.47258, MAPE = 8.79883
Step 7 RMSE = 23.90320, MAE = 13.71317, MAPE = 8.96002
Step 8 RMSE = 24.33268, MAE = 13.93716, MAPE = 9.11087
Step 9 RMSE = 24.71608, MAE = 14.14140, MAPE = 9.26447
Step 10 RMSE = 25.07244, MAE = 14.34784, MAPE = 9.42000
Step 11 RMSE = 25.37745, MAE = 14.55607, MAPE = 9.59112
Step 12 RMSE = 25.70676, MAE = 14.80786, MAPE = 9.79180
Inference time: 3.36 s
