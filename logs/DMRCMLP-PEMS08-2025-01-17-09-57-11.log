PEMS08
--------- DMRCMLP ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0015,
    "milestones": [
        30,
        50,
        70
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 34110658,
    "gpu": [
        2
    ],
    "save": true,
    "model_args": {
        "num_nodes": 170,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        272,172
├─Linear: 1-1                                 [16, 12, 170, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 170, 48]         --
│    └─Embedding: 2-1                         [16, 12, 170, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 170, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 170, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 170, 144]        158,224
├─Predictor: 1-4                              [16, 12, 170, 1]          --
│    └─Linear: 2-5                            [16, 12, 170, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 170, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 170, 144]        41,760
│    └─Linear: 2-7                            [16, 170, 12]             20,748
===============================================================================================
Total params: 1,037,344
Trainable params: 1,037,344
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.39
Forward/backward pass size (MB): 1527.29
Params size (MB): 3.06
Estimated Total Size (MB): 1530.74
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS08-2025-01-17-09-57-11.pt
2025-01-17 09:57:45.777240 Epoch 1, Train Y Loss = 23.28095,  Train X Loss = 0.00000, Val Loss = 18.15470
2025-01-17 09:58:20.154660 Epoch 2, Train Y Loss = 17.93672,  Train X Loss = 0.00000, Val Loss = 17.15208
2025-01-17 09:58:54.566550 Epoch 3, Train Y Loss = 16.94318,  Train X Loss = 0.00000, Val Loss = 16.29318
2025-01-17 09:59:28.756862 Epoch 4, Train Y Loss = 16.42740,  Train X Loss = 0.00000, Val Loss = 16.10217
2025-01-17 10:00:03.229947 Epoch 5, Train Y Loss = 15.90294,  Train X Loss = 0.00000, Val Loss = 16.14125
2025-01-17 10:00:37.654747 Epoch 6, Train Y Loss = 15.54073,  Train X Loss = 0.00000, Val Loss = 15.40610
2025-01-17 10:01:12.109485 Epoch 7, Train Y Loss = 15.32536,  Train X Loss = 0.00000, Val Loss = 15.43264
2025-01-17 10:01:46.520473 Epoch 8, Train Y Loss = 14.91950,  Train X Loss = 0.00000, Val Loss = 14.71608
2025-01-17 10:02:20.736740 Epoch 9, Train Y Loss = 14.84111,  Train X Loss = 0.00000, Val Loss = 14.98133
2025-01-17 10:02:54.909293 Epoch 10, Train Y Loss = 14.61779,  Train X Loss = 0.00000, Val Loss = 14.54384
2025-01-17 10:03:29.116647 Epoch 11, Train Y Loss = 14.47387,  Train X Loss = 0.00000, Val Loss = 14.26262
2025-01-17 10:04:03.335013 Epoch 12, Train Y Loss = 14.22490,  Train X Loss = 0.00000, Val Loss = 14.35391
2025-01-17 10:04:37.545523 Epoch 13, Train Y Loss = 14.11529,  Train X Loss = 0.00000, Val Loss = 14.40567
2025-01-17 10:05:11.740302 Epoch 14, Train Y Loss = 13.90869,  Train X Loss = 0.00000, Val Loss = 14.06543
2025-01-17 10:05:45.885615 Epoch 15, Train Y Loss = 13.76118,  Train X Loss = 0.00000, Val Loss = 13.94261
2025-01-17 10:06:19.968266 Epoch 16, Train Y Loss = 13.59018,  Train X Loss = 0.00000, Val Loss = 13.93402
2025-01-17 10:06:54.040477 Epoch 17, Train Y Loss = 13.48958,  Train X Loss = 0.00000, Val Loss = 14.08669
2025-01-17 10:07:28.108100 Epoch 18, Train Y Loss = 13.39390,  Train X Loss = 0.00000, Val Loss = 13.80284
2025-01-17 10:08:02.199185 Epoch 19, Train Y Loss = 13.29486,  Train X Loss = 0.00000, Val Loss = 13.71927
2025-01-17 10:08:36.293567 Epoch 20, Train Y Loss = 13.18208,  Train X Loss = 0.00000, Val Loss = 13.47622
2025-01-17 10:09:10.344882 Epoch 21, Train Y Loss = 13.11034,  Train X Loss = 0.00000, Val Loss = 13.63523
2025-01-17 10:09:44.365566 Epoch 22, Train Y Loss = 13.07118,  Train X Loss = 0.00000, Val Loss = 13.70029
2025-01-17 10:10:18.386104 Epoch 23, Train Y Loss = 12.96295,  Train X Loss = 0.00000, Val Loss = 13.45753
2025-01-17 10:10:52.393876 Epoch 24, Train Y Loss = 12.93456,  Train X Loss = 0.00000, Val Loss = 13.71019
2025-01-17 10:11:26.392443 Epoch 25, Train Y Loss = 12.88642,  Train X Loss = 0.00000, Val Loss = 13.67862
2025-01-17 10:12:00.398498 Epoch 26, Train Y Loss = 12.80623,  Train X Loss = 0.00000, Val Loss = 13.61494
2025-01-17 10:12:34.383268 Epoch 27, Train Y Loss = 12.78707,  Train X Loss = 0.00000, Val Loss = 13.53005
2025-01-17 10:13:08.350872 Epoch 28, Train Y Loss = 12.71232,  Train X Loss = 0.00000, Val Loss = 13.64644
2025-01-17 10:13:42.314351 Epoch 29, Train Y Loss = 12.73014,  Train X Loss = 0.00000, Val Loss = 13.67385
2025-01-17 10:14:16.289062 Epoch 30, Train Y Loss = 12.62885,  Train X Loss = 0.00000, Val Loss = 13.46363
2025-01-17 10:14:50.266539 Epoch 31, Train Y Loss = 12.11070,  Train X Loss = 0.00000, Val Loss = 13.01880
2025-01-17 10:15:24.293023 Epoch 32, Train Y Loss = 12.02850,  Train X Loss = 0.00000, Val Loss = 13.07452
2025-01-17 10:15:58.326282 Epoch 33, Train Y Loss = 12.00300,  Train X Loss = 0.00000, Val Loss = 13.04782
2025-01-17 10:16:32.350193 Epoch 34, Train Y Loss = 11.98258,  Train X Loss = 0.00000, Val Loss = 13.03424
2025-01-17 10:17:06.355304 Epoch 35, Train Y Loss = 11.96776,  Train X Loss = 0.00000, Val Loss = 13.06607
2025-01-17 10:17:40.358067 Epoch 36, Train Y Loss = 11.95230,  Train X Loss = 0.00000, Val Loss = 13.08444
2025-01-17 10:18:14.360860 Epoch 37, Train Y Loss = 11.93740,  Train X Loss = 0.00000, Val Loss = 13.09307
2025-01-17 10:18:48.359340 Epoch 38, Train Y Loss = 11.92293,  Train X Loss = 0.00000, Val Loss = 13.09319
2025-01-17 10:19:22.479164 Epoch 39, Train Y Loss = 11.91481,  Train X Loss = 0.00000, Val Loss = 13.14664
2025-01-17 10:19:56.548590 Epoch 40, Train Y Loss = 11.90269,  Train X Loss = 0.00000, Val Loss = 13.10684
2025-01-17 10:20:30.562711 Epoch 41, Train Y Loss = 11.89251,  Train X Loss = 0.00000, Val Loss = 13.12137
2025-01-17 10:21:04.564339 Epoch 42, Train Y Loss = 11.88258,  Train X Loss = 0.00000, Val Loss = 13.15373
2025-01-17 10:21:38.570216 Epoch 43, Train Y Loss = 11.87238,  Train X Loss = 0.00000, Val Loss = 13.07548
2025-01-17 10:22:12.572848 Epoch 44, Train Y Loss = 11.86362,  Train X Loss = 0.00000, Val Loss = 13.11582
2025-01-17 10:22:46.556443 Epoch 45, Train Y Loss = 11.85415,  Train X Loss = 0.00000, Val Loss = 13.14452
2025-01-17 10:23:20.523368 Epoch 46, Train Y Loss = 11.84485,  Train X Loss = 0.00000, Val Loss = 13.13670
2025-01-17 10:23:54.491488 Epoch 47, Train Y Loss = 11.83393,  Train X Loss = 0.00000, Val Loss = 13.13442
2025-01-17 10:24:28.496648 Epoch 48, Train Y Loss = 11.82678,  Train X Loss = 0.00000, Val Loss = 13.16576
2025-01-17 10:25:02.486332 Epoch 49, Train Y Loss = 11.81877,  Train X Loss = 0.00000, Val Loss = 13.12400
2025-01-17 10:25:36.476204 Epoch 50, Train Y Loss = 11.81425,  Train X Loss = 0.00000, Val Loss = 13.17076
2025-01-17 10:26:10.640539 Epoch 51, Train Y Loss = 11.74966,  Train X Loss = 0.00000, Val Loss = 13.13199
2025-01-17 10:26:45.059908 Epoch 52, Train Y Loss = 11.73868,  Train X Loss = 0.00000, Val Loss = 13.11974
2025-01-17 10:27:19.452749 Epoch 53, Train Y Loss = 11.73685,  Train X Loss = 0.00000, Val Loss = 13.11905
2025-01-17 10:27:53.838460 Epoch 54, Train Y Loss = 11.73456,  Train X Loss = 0.00000, Val Loss = 13.11405
2025-01-17 10:28:28.125383 Epoch 55, Train Y Loss = 11.73283,  Train X Loss = 0.00000, Val Loss = 13.12813
2025-01-17 10:29:02.604231 Epoch 56, Train Y Loss = 11.73226,  Train X Loss = 0.00000, Val Loss = 13.14328
2025-01-17 10:29:37.082994 Epoch 57, Train Y Loss = 11.72996,  Train X Loss = 0.00000, Val Loss = 13.14089
2025-01-17 10:30:11.585029 Epoch 58, Train Y Loss = 11.72923,  Train X Loss = 0.00000, Val Loss = 13.13314
2025-01-17 10:30:45.968005 Epoch 59, Train Y Loss = 11.72724,  Train X Loss = 0.00000, Val Loss = 13.13768
2025-01-17 10:31:20.465454 Epoch 60, Train Y Loss = 11.72459,  Train X Loss = 0.00000, Val Loss = 13.12606
2025-01-17 10:31:54.928252 Epoch 61, Train Y Loss = 11.72488,  Train X Loss = 0.00000, Val Loss = 13.13204
Early stopping at epoch: 61
Best at epoch 31:
Train Loss = 12.11070
Train RMSE = 21.85194, MAE = 12.35147, MAPE = 8.15978
Val Loss = 13.01880
Val RMSE = 23.93686, MAE = 13.44935, MAPE = 9.98606
--------- Test ---------
All Steps RMSE = 23.23566, MAE = 13.43344, MAPE = 8.79240
Step 1 RMSE = 19.43495, MAE = 11.67663, MAPE = 7.68505
Step 2 RMSE = 20.52023, MAE = 12.14446, MAPE = 7.96631
Step 3 RMSE = 21.40860, MAE = 12.54988, MAPE = 8.20255
Step 4 RMSE = 22.16609, MAE = 12.90846, MAPE = 8.45918
Step 5 RMSE = 22.77645, MAE = 13.19697, MAPE = 8.62529
Step 6 RMSE = 23.30709, MAE = 13.44860, MAPE = 8.78035
Step 7 RMSE = 23.79224, MAE = 13.68594, MAPE = 8.92145
Step 8 RMSE = 24.21180, MAE = 13.90781, MAPE = 9.08352
Step 9 RMSE = 24.56396, MAE = 14.09819, MAPE = 9.21078
Step 10 RMSE = 24.91464, MAE = 14.30131, MAPE = 9.35313
Step 11 RMSE = 25.23370, MAE = 14.50492, MAPE = 9.50532
Step 12 RMSE = 25.59612, MAE = 14.77815, MAPE = 9.71579
Inference time: 3.32 s
