PEMS08
--------- DMRCMLP ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0015,
    "milestones": [
        30,
        50,
        70
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 51970489,
    "gpu": [
        2
    ],
    "save": true,
    "model_args": {
        "num_nodes": 170,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        272,172
├─Linear: 1-1                                 [16, 12, 170, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 170, 48]         --
│    └─Embedding: 2-1                         [16, 12, 170, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 170, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 170, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 170, 144]        158,224
├─Predictor: 1-4                              [16, 12, 170, 1]          --
│    └─Linear: 2-5                            [16, 12, 170, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 170, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 170, 144]        41,760
│    └─Linear: 2-7                            [16, 170, 12]             20,748
===============================================================================================
Total params: 1,037,344
Trainable params: 1,037,344
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.39
Forward/backward pass size (MB): 1527.29
Params size (MB): 3.06
Estimated Total Size (MB): 1530.74
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS08-2025-01-17-09-21-44.pt
2025-01-17 09:22:18.719716 Epoch 1, Train Y Loss = 23.83952,  Train X Loss = 0.00000, Val Loss = 20.92830
2025-01-17 09:22:53.187759 Epoch 2, Train Y Loss = 18.15195,  Train X Loss = 0.00000, Val Loss = 16.74617
2025-01-17 09:23:27.617446 Epoch 3, Train Y Loss = 16.96979,  Train X Loss = 0.00000, Val Loss = 16.24717
2025-01-17 09:24:02.085952 Epoch 4, Train Y Loss = 16.32349,  Train X Loss = 0.00000, Val Loss = 15.90655
2025-01-17 09:24:36.667298 Epoch 5, Train Y Loss = 15.98007,  Train X Loss = 0.00000, Val Loss = 15.84263
2025-01-17 09:25:11.230236 Epoch 6, Train Y Loss = 15.57417,  Train X Loss = 0.00000, Val Loss = 15.69873
2025-01-17 09:25:45.769278 Epoch 7, Train Y Loss = 15.22659,  Train X Loss = 0.00000, Val Loss = 14.94388
2025-01-17 09:26:20.325182 Epoch 8, Train Y Loss = 14.95426,  Train X Loss = 0.00000, Val Loss = 14.63528
2025-01-17 09:26:54.922777 Epoch 9, Train Y Loss = 14.74202,  Train X Loss = 0.00000, Val Loss = 14.90546
2025-01-17 09:27:29.362223 Epoch 10, Train Y Loss = 14.51691,  Train X Loss = 0.00000, Val Loss = 15.20029
2025-01-17 09:28:03.913418 Epoch 11, Train Y Loss = 14.40360,  Train X Loss = 0.00000, Val Loss = 14.24982
2025-01-17 09:28:38.462534 Epoch 12, Train Y Loss = 14.13387,  Train X Loss = 0.00000, Val Loss = 14.09321
2025-01-17 09:29:12.951486 Epoch 13, Train Y Loss = 14.01881,  Train X Loss = 0.00000, Val Loss = 14.35793
2025-01-17 09:29:47.503069 Epoch 14, Train Y Loss = 13.81721,  Train X Loss = 0.00000, Val Loss = 14.30215
2025-01-17 09:30:22.122737 Epoch 15, Train Y Loss = 13.72460,  Train X Loss = 0.00000, Val Loss = 13.79594
2025-01-17 09:30:56.579169 Epoch 16, Train Y Loss = 13.62203,  Train X Loss = 0.00000, Val Loss = 13.77912
2025-01-17 09:31:31.175232 Epoch 17, Train Y Loss = 13.44432,  Train X Loss = 0.00000, Val Loss = 13.77755
2025-01-17 09:32:05.759332 Epoch 18, Train Y Loss = 13.40465,  Train X Loss = 0.00000, Val Loss = 13.76146
2025-01-17 09:32:40.124695 Epoch 19, Train Y Loss = 13.27274,  Train X Loss = 0.00000, Val Loss = 13.68771
2025-01-17 09:33:14.700146 Epoch 20, Train Y Loss = 13.23274,  Train X Loss = 0.00000, Val Loss = 13.77919
2025-01-17 09:33:49.214126 Epoch 21, Train Y Loss = 13.13325,  Train X Loss = 0.00000, Val Loss = 13.73073
2025-01-17 09:34:23.715433 Epoch 22, Train Y Loss = 13.08706,  Train X Loss = 0.00000, Val Loss = 13.59994
2025-01-17 09:34:58.200100 Epoch 23, Train Y Loss = 13.02309,  Train X Loss = 0.00000, Val Loss = 13.90415
2025-01-17 09:35:32.779167 Epoch 24, Train Y Loss = 13.00098,  Train X Loss = 0.00000, Val Loss = 13.59939
2025-01-17 09:36:07.288855 Epoch 25, Train Y Loss = 12.90255,  Train X Loss = 0.00000, Val Loss = 13.71609
2025-01-17 09:36:41.708056 Epoch 26, Train Y Loss = 12.84364,  Train X Loss = 0.00000, Val Loss = 13.60821
2025-01-17 09:37:16.226290 Epoch 27, Train Y Loss = 12.78598,  Train X Loss = 0.00000, Val Loss = 13.74817
2025-01-17 09:37:50.783906 Epoch 28, Train Y Loss = 12.77205,  Train X Loss = 0.00000, Val Loss = 13.54718
2025-01-17 09:38:25.214130 Epoch 29, Train Y Loss = 12.73721,  Train X Loss = 0.00000, Val Loss = 13.83277
2025-01-17 09:38:59.700783 Epoch 30, Train Y Loss = 12.73995,  Train X Loss = 0.00000, Val Loss = 13.66641
2025-01-17 09:39:34.244514 Epoch 31, Train Y Loss = 12.14915,  Train X Loss = 0.00000, Val Loss = 13.24598
2025-01-17 09:40:08.651279 Epoch 32, Train Y Loss = 12.05009,  Train X Loss = 0.00000, Val Loss = 13.25655
2025-01-17 09:40:43.184678 Epoch 33, Train Y Loss = 12.02007,  Train X Loss = 0.00000, Val Loss = 13.25744
2025-01-17 09:41:17.657926 Epoch 34, Train Y Loss = 11.99965,  Train X Loss = 0.00000, Val Loss = 13.33254
2025-01-17 09:41:52.088779 Epoch 35, Train Y Loss = 11.98101,  Train X Loss = 0.00000, Val Loss = 13.32613
2025-01-17 09:42:26.618480 Epoch 36, Train Y Loss = 11.96542,  Train X Loss = 0.00000, Val Loss = 13.35083
2025-01-17 09:43:01.211313 Epoch 37, Train Y Loss = 11.95128,  Train X Loss = 0.00000, Val Loss = 13.32672
2025-01-17 09:43:35.743750 Epoch 38, Train Y Loss = 11.93648,  Train X Loss = 0.00000, Val Loss = 13.34156
2025-01-17 09:44:10.370526 Epoch 39, Train Y Loss = 11.92389,  Train X Loss = 0.00000, Val Loss = 13.40371
2025-01-17 09:44:45.008279 Epoch 40, Train Y Loss = 11.91097,  Train X Loss = 0.00000, Val Loss = 13.38484
2025-01-17 09:45:19.544833 Epoch 41, Train Y Loss = 11.90156,  Train X Loss = 0.00000, Val Loss = 13.39062
2025-01-17 09:45:54.123788 Epoch 42, Train Y Loss = 11.88798,  Train X Loss = 0.00000, Val Loss = 13.43715
2025-01-17 09:46:28.727963 Epoch 43, Train Y Loss = 11.87787,  Train X Loss = 0.00000, Val Loss = 13.41770
2025-01-17 09:47:03.394661 Epoch 44, Train Y Loss = 11.87043,  Train X Loss = 0.00000, Val Loss = 13.39717
2025-01-17 09:47:37.906733 Epoch 45, Train Y Loss = 11.86014,  Train X Loss = 0.00000, Val Loss = 13.43822
2025-01-17 09:48:12.598635 Epoch 46, Train Y Loss = 11.85085,  Train X Loss = 0.00000, Val Loss = 13.44336
2025-01-17 09:48:47.231715 Epoch 47, Train Y Loss = 11.83918,  Train X Loss = 0.00000, Val Loss = 13.44974
2025-01-17 09:49:21.798443 Epoch 48, Train Y Loss = 11.83328,  Train X Loss = 0.00000, Val Loss = 13.48426
2025-01-17 09:49:56.468233 Epoch 49, Train Y Loss = 11.82879,  Train X Loss = 0.00000, Val Loss = 13.48263
2025-01-17 09:50:31.168741 Epoch 50, Train Y Loss = 11.81530,  Train X Loss = 0.00000, Val Loss = 13.50008
2025-01-17 09:51:05.749764 Epoch 51, Train Y Loss = 11.75124,  Train X Loss = 0.00000, Val Loss = 13.45972
2025-01-17 09:51:40.383183 Epoch 52, Train Y Loss = 11.74085,  Train X Loss = 0.00000, Val Loss = 13.46268
2025-01-17 09:52:15.078634 Epoch 53, Train Y Loss = 11.73795,  Train X Loss = 0.00000, Val Loss = 13.48233
2025-01-17 09:52:49.632454 Epoch 54, Train Y Loss = 11.73681,  Train X Loss = 0.00000, Val Loss = 13.48314
2025-01-17 09:53:24.334962 Epoch 55, Train Y Loss = 11.73456,  Train X Loss = 0.00000, Val Loss = 13.48030
2025-01-17 09:53:58.945548 Epoch 56, Train Y Loss = 11.73204,  Train X Loss = 0.00000, Val Loss = 13.47705
2025-01-17 09:54:33.567308 Epoch 57, Train Y Loss = 11.73118,  Train X Loss = 0.00000, Val Loss = 13.46216
2025-01-17 09:55:08.176612 Epoch 58, Train Y Loss = 11.72987,  Train X Loss = 0.00000, Val Loss = 13.46733
2025-01-17 09:55:42.878606 Epoch 59, Train Y Loss = 11.72768,  Train X Loss = 0.00000, Val Loss = 13.48153
2025-01-17 09:56:17.543110 Epoch 60, Train Y Loss = 11.72517,  Train X Loss = 0.00000, Val Loss = 13.46844
2025-01-17 09:56:52.134363 Epoch 61, Train Y Loss = 11.72544,  Train X Loss = 0.00000, Val Loss = 13.46030
Early stopping at epoch: 61
Best at epoch 31:
Train Loss = 12.14915
Train RMSE = 21.89269, MAE = 12.36428, MAPE = 8.21963
Val Loss = 13.24598
Val RMSE = 24.61604, MAE = 13.67377, MAPE = 10.73418
--------- Test ---------
All Steps RMSE = 23.48612, MAE = 13.51972, MAPE = 8.87512
Step 1 RMSE = 19.50272, MAE = 11.71844, MAPE = 7.70582
Step 2 RMSE = 20.62092, MAE = 12.19779, MAPE = 8.00382
Step 3 RMSE = 21.53412, MAE = 12.62159, MAPE = 8.25487
Step 4 RMSE = 22.32540, MAE = 12.96588, MAPE = 8.47291
Step 5 RMSE = 22.98549, MAE = 13.26803, MAPE = 8.66156
Step 6 RMSE = 23.58502, MAE = 13.54126, MAPE = 8.84349
Step 7 RMSE = 24.10148, MAE = 13.77858, MAPE = 8.99856
Step 8 RMSE = 24.53655, MAE = 14.00386, MAPE = 9.17577
Step 9 RMSE = 24.91029, MAE = 14.20930, MAPE = 9.30586
Step 10 RMSE = 25.25113, MAE = 14.40728, MAPE = 9.47691
Step 11 RMSE = 25.58727, MAE = 14.63260, MAPE = 9.68543
Step 12 RMSE = 25.90559, MAE = 14.89199, MAPE = 9.91649
Inference time: 3.34 s
