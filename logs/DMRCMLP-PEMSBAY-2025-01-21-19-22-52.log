PEMSBAY
--------- DMRCMLP ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        15,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 74418540,
    "gpu": [
        6
    ],
    "save": false,
    "model_args": {
        "num_nodes": 325,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        385,212
├─Linear: 1-1                                 [16, 12, 325, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 325, 48]         --
│    └─Embedding: 2-1                         [16, 12, 325, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 325, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 325, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 325, 144]        158,224
├─Predictor: 1-4                              [16, 12, 325, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 325, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 325, 144]        41,760
│    └─Linear: 2-6                            [16, 325, 12]             20,748
===============================================================================================
Total params: 1,129,504
Trainable params: 1,129,504
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.75
Forward/backward pass size (MB): 2847.94
Params size (MB): 2.98
Estimated Total Size (MB): 2851.66
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMSBAY-2025-01-21-19-22-52.pt
2025-01-21 19:26:06.907368 Epoch 1, Train Y Loss = 2.01595,  Train X Loss = 0.00000, Val Loss = 1.87600
2025-01-21 19:29:21.082935 Epoch 2, Train Y Loss = 1.65775,  Train X Loss = 0.00000, Val Loss = 1.73268
2025-01-21 19:32:35.234758 Epoch 3, Train Y Loss = 1.58738,  Train X Loss = 0.00000, Val Loss = 1.82426
2025-01-21 19:35:49.122283 Epoch 4, Train Y Loss = 1.55314,  Train X Loss = 0.00000, Val Loss = 1.66855
2025-01-21 19:39:02.895342 Epoch 5, Train Y Loss = 1.52666,  Train X Loss = 0.00000, Val Loss = 1.65955
2025-01-21 19:42:16.648070 Epoch 6, Train Y Loss = 1.50468,  Train X Loss = 0.00000, Val Loss = 1.63007
2025-01-21 19:45:30.469864 Epoch 7, Train Y Loss = 1.48659,  Train X Loss = 0.00000, Val Loss = 1.60800
2025-01-21 19:48:44.318869 Epoch 8, Train Y Loss = 1.47000,  Train X Loss = 0.00000, Val Loss = 1.62316
2025-01-21 19:51:58.197671 Epoch 9, Train Y Loss = 1.45862,  Train X Loss = 0.00000, Val Loss = 1.61287
2025-01-21 19:55:12.028404 Epoch 10, Train Y Loss = 1.44608,  Train X Loss = 0.00000, Val Loss = 1.59356
2025-01-21 19:58:25.667604 Epoch 11, Train Y Loss = 1.43503,  Train X Loss = 0.00000, Val Loss = 1.60401
2025-01-21 20:01:39.277376 Epoch 12, Train Y Loss = 1.42708,  Train X Loss = 0.00000, Val Loss = 1.59590
2025-01-21 20:04:53.030686 Epoch 13, Train Y Loss = 1.41797,  Train X Loss = 0.00000, Val Loss = 1.59902
2025-01-21 20:08:06.803445 Epoch 14, Train Y Loss = 1.40983,  Train X Loss = 0.00000, Val Loss = 1.58637
2025-01-21 20:11:20.608176 Epoch 15, Train Y Loss = 1.40226,  Train X Loss = 0.00000, Val Loss = 1.58128
2025-01-21 20:14:34.407586 Epoch 16, Train Y Loss = 1.34850,  Train X Loss = 0.00000, Val Loss = 1.55858
2025-01-21 20:17:48.106945 Epoch 17, Train Y Loss = 1.33576,  Train X Loss = 0.00000, Val Loss = 1.56606
2025-01-21 20:21:01.877533 Epoch 18, Train Y Loss = 1.32900,  Train X Loss = 0.00000, Val Loss = 1.56061
2025-01-21 20:24:15.725737 Epoch 19, Train Y Loss = 1.32354,  Train X Loss = 0.00000, Val Loss = 1.56428
2025-01-21 20:27:29.677598 Epoch 20, Train Y Loss = 1.31929,  Train X Loss = 0.00000, Val Loss = 1.56011
2025-01-21 20:30:43.677418 Epoch 21, Train Y Loss = 1.31559,  Train X Loss = 0.00000, Val Loss = 1.56413
2025-01-21 20:33:57.729737 Epoch 22, Train Y Loss = 1.31136,  Train X Loss = 0.00000, Val Loss = 1.56189
2025-01-21 20:37:11.625755 Epoch 23, Train Y Loss = 1.30760,  Train X Loss = 0.00000, Val Loss = 1.56763
2025-01-21 20:40:25.387942 Epoch 24, Train Y Loss = 1.30388,  Train X Loss = 0.00000, Val Loss = 1.56270
2025-01-21 20:43:39.265949 Epoch 25, Train Y Loss = 1.30077,  Train X Loss = 0.00000, Val Loss = 1.56478
2025-01-21 20:46:53.129418 Epoch 26, Train Y Loss = 1.29752,  Train X Loss = 0.00000, Val Loss = 1.56304
2025-01-21 20:50:06.948688 Epoch 27, Train Y Loss = 1.29447,  Train X Loss = 0.00000, Val Loss = 1.55995
2025-01-21 20:53:20.811020 Epoch 28, Train Y Loss = 1.29152,  Train X Loss = 0.00000, Val Loss = 1.55928
2025-01-21 20:56:34.693161 Epoch 29, Train Y Loss = 1.28905,  Train X Loss = 0.00000, Val Loss = 1.56743
2025-01-21 20:59:48.491819 Epoch 30, Train Y Loss = 1.28614,  Train X Loss = 0.00000, Val Loss = 1.57106
2025-01-21 21:03:02.180608 Epoch 31, Train Y Loss = 1.28352,  Train X Loss = 0.00000, Val Loss = 1.56237
2025-01-21 21:06:15.945707 Epoch 32, Train Y Loss = 1.28129,  Train X Loss = 0.00000, Val Loss = 1.56957
2025-01-21 21:09:29.845004 Epoch 33, Train Y Loss = 1.27792,  Train X Loss = 0.00000, Val Loss = 1.56819
2025-01-21 21:12:43.712365 Epoch 34, Train Y Loss = 1.27565,  Train X Loss = 0.00000, Val Loss = 1.56460
2025-01-21 21:15:57.621021 Epoch 35, Train Y Loss = 1.27307,  Train X Loss = 0.00000, Val Loss = 1.56460
2025-01-21 21:19:11.529891 Epoch 36, Train Y Loss = 1.26308,  Train X Loss = 0.00000, Val Loss = 1.56476
2025-01-21 21:22:25.505398 Epoch 37, Train Y Loss = 1.26012,  Train X Loss = 0.00000, Val Loss = 1.56624
2025-01-21 21:25:39.469894 Epoch 38, Train Y Loss = 1.25916,  Train X Loss = 0.00000, Val Loss = 1.56601
2025-01-21 21:28:53.316836 Epoch 39, Train Y Loss = 1.25854,  Train X Loss = 0.00000, Val Loss = 1.56642
2025-01-21 21:32:07.202672 Epoch 40, Train Y Loss = 1.25794,  Train X Loss = 0.00000, Val Loss = 1.56685
2025-01-21 21:35:21.178323 Epoch 41, Train Y Loss = 1.25737,  Train X Loss = 0.00000, Val Loss = 1.56560
2025-01-21 21:38:35.238291 Epoch 42, Train Y Loss = 1.25723,  Train X Loss = 0.00000, Val Loss = 1.56793
2025-01-21 21:41:49.030820 Epoch 43, Train Y Loss = 1.25656,  Train X Loss = 0.00000, Val Loss = 1.56869
2025-01-21 21:45:03.243369 Epoch 44, Train Y Loss = 1.25682,  Train X Loss = 0.00000, Val Loss = 1.56890
2025-01-21 21:48:17.206174 Epoch 45, Train Y Loss = 1.25611,  Train X Loss = 0.00000, Val Loss = 1.56849
2025-01-21 21:51:31.385793 Epoch 46, Train Y Loss = 1.25600,  Train X Loss = 0.00000, Val Loss = 1.56567
Early stopping at epoch: 46
Best at epoch 16:
Train Loss = 1.34850
Train RMSE = 2.96891, MAE = 1.31938, MAPE = 2.82528
Val Loss = 1.55858
Val RMSE = 3.63381, MAE = 1.55662, MAPE = 3.56000
--------- Test ---------
All Steps RMSE = 3.59386, MAE = 1.55862, MAPE = 3.50087
Step 1 RMSE = 1.65033, MAE = 0.86412, MAPE = 1.66936
Step 2 RMSE = 2.31587, MAE = 1.13643, MAPE = 2.31428
Step 3 RMSE = 2.82021, MAE = 1.31744, MAPE = 2.78967
Step 4 RMSE = 3.20357, MAE = 1.44846, MAPE = 3.16028
Step 5 RMSE = 3.48925, MAE = 1.54651, MAPE = 3.44666
Step 6 RMSE = 3.70712, MAE = 1.62360, MAPE = 3.67589
Step 7 RMSE = 3.87321, MAE = 1.68583, MAPE = 3.85546
Step 8 RMSE = 4.00384, MAE = 1.73702, MAPE = 4.00544
Step 9 RMSE = 4.10713, MAE = 1.78038, MAPE = 4.12695
Step 10 RMSE = 4.19349, MAE = 1.81842, MAPE = 4.22870
Step 11 RMSE = 4.27693, MAE = 1.85472, MAPE = 4.32495
Step 12 RMSE = 4.35776, MAE = 1.89044, MAPE = 4.41268
Inference time: 18.60 s
