PEMSBAY
--------- DMRCMLP ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        15,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "adaptive_mask": true,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 93048409,
    "gpu": [
        6
    ],
    "save": false,
    "model_args": {
        "num_nodes": 325,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        385,212
├─Linear: 1-1                                 [16, 12, 325, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 325, 48]         --
│    └─Embedding: 2-1                         [16, 12, 325, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 325, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 325, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 325, 144]        158,224
├─Predictor: 1-4                              [16, 12, 325, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 325, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 325, 144]        41,760
│    └─Linear: 2-6                            [16, 325, 12]             20,748
===============================================================================================
Total params: 1,129,504
Trainable params: 1,129,504
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.75
Forward/backward pass size (MB): 2847.94
Params size (MB): 2.98
Estimated Total Size (MB): 2851.66
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMSBAY-2025-01-21-11-00-33.pt
2025-01-21 11:03:55.035888 Epoch 1, Train Y Loss = 2.06333,  Train X Loss = 0.00000, Val Loss = 1.92674
2025-01-21 11:07:16.618899 Epoch 2, Train Y Loss = 1.70261,  Train X Loss = 0.00000, Val Loss = 1.75956
2025-01-21 11:10:37.607588 Epoch 3, Train Y Loss = 1.62428,  Train X Loss = 0.00000, Val Loss = 1.72609
2025-01-21 11:13:58.678725 Epoch 4, Train Y Loss = 1.58485,  Train X Loss = 0.00000, Val Loss = 1.70701
2025-01-21 11:17:19.611952 Epoch 5, Train Y Loss = 1.55509,  Train X Loss = 0.00000, Val Loss = 1.69395
2025-01-21 11:20:40.634524 Epoch 6, Train Y Loss = 1.53199,  Train X Loss = 0.00000, Val Loss = 1.68156
2025-01-21 11:24:01.365522 Epoch 7, Train Y Loss = 1.51332,  Train X Loss = 0.00000, Val Loss = 1.61809
2025-01-21 11:27:22.093925 Epoch 8, Train Y Loss = 1.49814,  Train X Loss = 0.00000, Val Loss = 1.61561
2025-01-21 11:30:43.115136 Epoch 9, Train Y Loss = 1.48446,  Train X Loss = 0.00000, Val Loss = 1.60663
2025-01-21 11:34:03.908887 Epoch 10, Train Y Loss = 1.47396,  Train X Loss = 0.00000, Val Loss = 1.61028
2025-01-21 11:37:24.635654 Epoch 11, Train Y Loss = 1.46654,  Train X Loss = 0.00000, Val Loss = 1.63800
2025-01-21 11:40:45.326132 Epoch 12, Train Y Loss = 1.45680,  Train X Loss = 0.00000, Val Loss = 1.60298
2025-01-21 11:44:05.969941 Epoch 13, Train Y Loss = 1.44893,  Train X Loss = 0.00000, Val Loss = 1.59218
2025-01-21 11:47:26.834537 Epoch 14, Train Y Loss = 1.44279,  Train X Loss = 0.00000, Val Loss = 1.59809
2025-01-21 11:50:47.772935 Epoch 15, Train Y Loss = 1.43764,  Train X Loss = 0.00000, Val Loss = 1.58507
2025-01-21 11:54:08.771170 Epoch 16, Train Y Loss = 1.38577,  Train X Loss = 0.00000, Val Loss = 1.54470
2025-01-21 11:57:29.631405 Epoch 17, Train Y Loss = 1.37486,  Train X Loss = 0.00000, Val Loss = 1.54038
2025-01-21 12:00:50.550558 Epoch 18, Train Y Loss = 1.36898,  Train X Loss = 0.00000, Val Loss = 1.53757
2025-01-21 12:04:11.833047 Epoch 19, Train Y Loss = 1.36459,  Train X Loss = 0.00000, Val Loss = 1.54189
2025-01-21 12:07:33.037066 Epoch 20, Train Y Loss = 1.36118,  Train X Loss = 0.00000, Val Loss = 1.53793
2025-01-21 12:10:54.628063 Epoch 21, Train Y Loss = 1.35848,  Train X Loss = 0.00000, Val Loss = 1.53606
2025-01-21 12:14:15.995250 Epoch 22, Train Y Loss = 1.35552,  Train X Loss = 0.00000, Val Loss = 1.54117
2025-01-21 12:17:37.414946 Epoch 23, Train Y Loss = 1.35208,  Train X Loss = 0.00000, Val Loss = 1.53681
2025-01-21 12:20:58.758605 Epoch 24, Train Y Loss = 1.34934,  Train X Loss = 0.00000, Val Loss = 1.54118
2025-01-21 12:24:20.101635 Epoch 25, Train Y Loss = 1.34676,  Train X Loss = 0.00000, Val Loss = 1.53811
2025-01-21 12:27:41.283450 Epoch 26, Train Y Loss = 1.34471,  Train X Loss = 0.00000, Val Loss = 1.53508
2025-01-21 12:31:02.398794 Epoch 27, Train Y Loss = 1.34199,  Train X Loss = 0.00000, Val Loss = 1.54339
2025-01-21 12:34:23.460436 Epoch 28, Train Y Loss = 1.33952,  Train X Loss = 0.00000, Val Loss = 1.53650
2025-01-21 12:37:44.427112 Epoch 29, Train Y Loss = 1.33744,  Train X Loss = 0.00000, Val Loss = 1.54183
2025-01-21 12:41:05.423699 Epoch 30, Train Y Loss = 1.33481,  Train X Loss = 0.00000, Val Loss = 1.53900
2025-01-21 12:44:26.399390 Epoch 31, Train Y Loss = 1.33251,  Train X Loss = 0.00000, Val Loss = 1.53759
2025-01-21 12:47:47.500530 Epoch 32, Train Y Loss = 1.33053,  Train X Loss = 0.00000, Val Loss = 1.54418
2025-01-21 12:51:08.511836 Epoch 33, Train Y Loss = 1.32801,  Train X Loss = 0.00000, Val Loss = 1.54077
2025-01-21 12:54:29.522815 Epoch 34, Train Y Loss = 1.32575,  Train X Loss = 0.00000, Val Loss = 1.54043
Change mask ratio: 0.075
2025-01-21 12:57:48.838432 Epoch 35, Train Y Loss = 1.30941,  Train X Loss = 0.00000, Val Loss = 1.54600
2025-01-21 13:01:08.122360 Epoch 36, Train Y Loss = 1.29944,  Train X Loss = 0.00000, Val Loss = 1.53736
2025-01-21 13:04:27.405275 Epoch 37, Train Y Loss = 1.29713,  Train X Loss = 0.00000, Val Loss = 1.53725
2025-01-21 13:07:46.916909 Epoch 38, Train Y Loss = 1.29736,  Train X Loss = 0.00000, Val Loss = 1.53796
2025-01-21 13:11:06.286266 Epoch 39, Train Y Loss = 1.29560,  Train X Loss = 0.00000, Val Loss = 1.53817
2025-01-21 13:14:25.655931 Epoch 40, Train Y Loss = 1.29608,  Train X Loss = 0.00000, Val Loss = 1.53855
2025-01-21 13:17:45.242803 Epoch 41, Train Y Loss = 1.29457,  Train X Loss = 0.00000, Val Loss = 1.54083
2025-01-21 13:21:04.660248 Epoch 42, Train Y Loss = 1.29378,  Train X Loss = 0.00000, Val Loss = 1.53879
Change mask ratio: 0.0375
2025-01-21 13:24:23.283266 Epoch 43, Train Y Loss = 1.28662,  Train X Loss = 0.00000, Val Loss = 1.54039
2025-01-21 13:27:42.121763 Epoch 44, Train Y Loss = 1.28493,  Train X Loss = 0.00000, Val Loss = 1.54050
2025-01-21 13:31:00.897265 Epoch 45, Train Y Loss = 1.28429,  Train X Loss = 0.00000, Val Loss = 1.54151
2025-01-21 13:34:19.574891 Epoch 46, Train Y Loss = 1.28370,  Train X Loss = 0.00000, Val Loss = 1.54242
2025-01-21 13:37:38.440241 Epoch 47, Train Y Loss = 1.28284,  Train X Loss = 0.00000, Val Loss = 1.54271
2025-01-21 13:40:57.391150 Epoch 48, Train Y Loss = 1.28233,  Train X Loss = 0.00000, Val Loss = 1.54274
2025-01-21 13:44:16.439144 Epoch 49, Train Y Loss = 1.28179,  Train X Loss = 0.00000, Val Loss = 1.54215
2025-01-21 13:47:35.363459 Epoch 50, Train Y Loss = 1.28113,  Train X Loss = 0.00000, Val Loss = 1.54146
Change mask ratio: 0.0
2025-01-21 13:50:47.888946 Epoch 51, Train Y Loss = 1.27267,  Train X Loss = 0.00000, Val Loss = 1.54716
2025-01-21 13:54:00.456786 Epoch 52, Train Y Loss = 1.27104,  Train X Loss = 0.00000, Val Loss = 1.54514
2025-01-21 13:57:13.007732 Epoch 53, Train Y Loss = 1.27016,  Train X Loss = 0.00000, Val Loss = 1.54557
2025-01-21 14:00:25.601532 Epoch 54, Train Y Loss = 1.26924,  Train X Loss = 0.00000, Val Loss = 1.54840
2025-01-21 14:03:38.258127 Epoch 55, Train Y Loss = 1.26912,  Train X Loss = 0.00000, Val Loss = 1.54801
2025-01-21 14:06:50.951457 Epoch 56, Train Y Loss = 1.26745,  Train X Loss = 0.00000, Val Loss = 1.54882
Early stopping at epoch: 56
Best at epoch 26:
Train Loss = 1.34471
Train RMSE = 2.91082, MAE = 1.30490, MAPE = 2.77429
Val Loss = 1.53508
Val RMSE = 3.58571, MAE = 1.53335, MAPE = 3.49374
--------- Test ---------
All Steps RMSE = 3.60625, MAE = 1.55351, MAPE = 3.49293
Step 1 RMSE = 1.60416, MAE = 0.86011, MAPE = 1.66348
Step 2 RMSE = 2.28397, MAE = 1.13433, MAPE = 2.31468
Step 3 RMSE = 2.80606, MAE = 1.31534, MAPE = 2.78507
Step 4 RMSE = 3.20000, MAE = 1.44493, MAPE = 3.14553
Step 5 RMSE = 3.49414, MAE = 1.54189, MAPE = 3.42530
Step 6 RMSE = 3.71991, MAE = 1.61872, MAPE = 3.65487
Step 7 RMSE = 3.89443, MAE = 1.68049, MAPE = 3.83885
Step 8 RMSE = 4.02918, MAE = 1.73109, MAPE = 3.99428
Step 9 RMSE = 4.13689, MAE = 1.77358, MAPE = 4.11744
Step 10 RMSE = 4.22614, MAE = 1.81205, MAPE = 4.22842
Step 11 RMSE = 4.30634, MAE = 1.84710, MAPE = 4.32932
Step 12 RMSE = 4.38070, MAE = 1.88255, MAPE = 4.41791
Inference time: 18.34 s
