METRLA
--------- DMRCMLP ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        25,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        0
    ],
    "save": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        283,260
├─Linear: 1-1                                 [16, 12, 207, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 207, 48]         --
│    └─Embedding: 2-1                         [16, 12, 207, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 207, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 207, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 207, 144]        158,224
├─Predictor: 1-4                              [16, 12, 207, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 207, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 207, 144]        41,760
│    └─Linear: 2-6                            [16, 207, 12]             20,748
===============================================================================================
Total params: 1,027,552
Trainable params: 1,027,552
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.48
Forward/backward pass size (MB): 1813.92
Params size (MB): 2.98
Estimated Total Size (MB): 1817.37
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-METRLA-2025-01-18-02-24-40.pt
2025-01-18 02:25:57.676782 Epoch 1, Train Y Loss = 4.03814,  Train X Loss = 0.00000, Val Loss = 3.21615
2025-01-18 02:27:14.767660 Epoch 2, Train Y Loss = 3.30341,  Train X Loss = 0.00000, Val Loss = 3.03154
2025-01-18 02:28:31.823270 Epoch 3, Train Y Loss = 3.16218,  Train X Loss = 0.00000, Val Loss = 2.94261
2025-01-18 02:29:48.751063 Epoch 4, Train Y Loss = 3.09358,  Train X Loss = 0.00000, Val Loss = 2.96799
2025-01-18 02:31:05.641183 Epoch 5, Train Y Loss = 3.04021,  Train X Loss = 0.00000, Val Loss = 2.87040
2025-01-18 02:32:22.339355 Epoch 6, Train Y Loss = 3.00139,  Train X Loss = 0.00000, Val Loss = 2.84892
2025-01-18 02:33:38.915957 Epoch 7, Train Y Loss = 2.96490,  Train X Loss = 0.00000, Val Loss = 2.84840
2025-01-18 02:34:55.524264 Epoch 8, Train Y Loss = 2.93116,  Train X Loss = 0.00000, Val Loss = 2.83325
2025-01-18 02:36:12.194362 Epoch 9, Train Y Loss = 2.90885,  Train X Loss = 0.00000, Val Loss = 2.81254
2025-01-18 02:37:28.929795 Epoch 10, Train Y Loss = 2.88856,  Train X Loss = 0.00000, Val Loss = 2.75921
2025-01-18 02:38:45.671926 Epoch 11, Train Y Loss = 2.86181,  Train X Loss = 0.00000, Val Loss = 2.75618
2025-01-18 02:40:02.381123 Epoch 12, Train Y Loss = 2.84723,  Train X Loss = 0.00000, Val Loss = 2.75380
2025-01-18 02:41:19.193098 Epoch 13, Train Y Loss = 2.83212,  Train X Loss = 0.00000, Val Loss = 2.77314
2025-01-18 02:42:36.024557 Epoch 14, Train Y Loss = 2.82123,  Train X Loss = 0.00000, Val Loss = 2.72232
2025-01-18 02:43:52.818175 Epoch 15, Train Y Loss = 2.80819,  Train X Loss = 0.00000, Val Loss = 2.76226
2025-01-18 02:45:09.624716 Epoch 16, Train Y Loss = 2.79587,  Train X Loss = 0.00000, Val Loss = 2.73211
2025-01-18 02:46:26.431899 Epoch 17, Train Y Loss = 2.78547,  Train X Loss = 0.00000, Val Loss = 2.75591
2025-01-18 02:47:43.350560 Epoch 18, Train Y Loss = 2.77642,  Train X Loss = 0.00000, Val Loss = 2.73653
2025-01-18 02:49:00.185431 Epoch 19, Train Y Loss = 2.76420,  Train X Loss = 0.00000, Val Loss = 2.77781
2025-01-18 02:50:17.095805 Epoch 20, Train Y Loss = 2.75559,  Train X Loss = 0.00000, Val Loss = 2.73845
2025-01-18 02:51:33.940908 Epoch 21, Train Y Loss = 2.74528,  Train X Loss = 0.00000, Val Loss = 2.76225
2025-01-18 02:52:50.716495 Epoch 22, Train Y Loss = 2.73402,  Train X Loss = 0.00000, Val Loss = 2.76093
2025-01-18 02:54:07.533726 Epoch 23, Train Y Loss = 2.72436,  Train X Loss = 0.00000, Val Loss = 2.78714
2025-01-18 02:55:24.201078 Epoch 24, Train Y Loss = 2.71447,  Train X Loss = 0.00000, Val Loss = 2.76585
2025-01-18 02:56:40.740995 Epoch 25, Train Y Loss = 2.70054,  Train X Loss = 0.00000, Val Loss = 2.77534
2025-01-18 02:57:57.384283 Epoch 26, Train Y Loss = 2.60951,  Train X Loss = 0.00000, Val Loss = 2.74469
2025-01-18 02:59:13.838141 Epoch 27, Train Y Loss = 2.58701,  Train X Loss = 0.00000, Val Loss = 2.75372
2025-01-18 03:00:30.358721 Epoch 28, Train Y Loss = 2.57702,  Train X Loss = 0.00000, Val Loss = 2.74991
2025-01-18 03:01:47.019543 Epoch 29, Train Y Loss = 2.56921,  Train X Loss = 0.00000, Val Loss = 2.76957
2025-01-18 03:03:03.668959 Epoch 30, Train Y Loss = 2.56350,  Train X Loss = 0.00000, Val Loss = 2.77162
2025-01-18 03:04:20.401034 Epoch 31, Train Y Loss = 2.55704,  Train X Loss = 0.00000, Val Loss = 2.77245
2025-01-18 03:05:37.212110 Epoch 32, Train Y Loss = 2.55214,  Train X Loss = 0.00000, Val Loss = 2.77565
2025-01-18 03:06:54.001669 Epoch 33, Train Y Loss = 2.54726,  Train X Loss = 0.00000, Val Loss = 2.78305
2025-01-18 03:08:10.736342 Epoch 34, Train Y Loss = 2.54241,  Train X Loss = 0.00000, Val Loss = 2.78516
2025-01-18 03:09:27.595444 Epoch 35, Train Y Loss = 2.53812,  Train X Loss = 0.00000, Val Loss = 2.79314
2025-01-18 03:10:44.454937 Epoch 36, Train Y Loss = 2.52448,  Train X Loss = 0.00000, Val Loss = 2.78566
2025-01-18 03:12:01.221649 Epoch 37, Train Y Loss = 2.52183,  Train X Loss = 0.00000, Val Loss = 2.78857
2025-01-18 03:13:18.028351 Epoch 38, Train Y Loss = 2.52110,  Train X Loss = 0.00000, Val Loss = 2.78887
2025-01-18 03:14:34.876459 Epoch 39, Train Y Loss = 2.52042,  Train X Loss = 0.00000, Val Loss = 2.78825
2025-01-18 03:15:51.787348 Epoch 40, Train Y Loss = 2.51888,  Train X Loss = 0.00000, Val Loss = 2.78633
2025-01-18 03:17:08.669165 Epoch 41, Train Y Loss = 2.51799,  Train X Loss = 0.00000, Val Loss = 2.78909
2025-01-18 03:18:25.539256 Epoch 42, Train Y Loss = 2.51772,  Train X Loss = 0.00000, Val Loss = 2.78847
2025-01-18 03:19:42.494127 Epoch 43, Train Y Loss = 2.51756,  Train X Loss = 0.00000, Val Loss = 2.78921
2025-01-18 03:20:59.341007 Epoch 44, Train Y Loss = 2.51653,  Train X Loss = 0.00000, Val Loss = 2.78994
Early stopping at epoch: 44
Best at epoch 14:
Train Loss = 2.82123
Train RMSE = 5.62117, MAE = 2.77043, MAPE = 7.41650
Val Loss = 2.72232
Val RMSE = 5.78332, MAE = 2.77609, MAPE = 7.72756
--------- Test ---------
All Steps RMSE = 6.09677, MAE = 2.98677, MAPE = 8.30683
Step 1 RMSE = 4.02651, MAE = 2.29338, MAPE = 5.58044
Step 2 RMSE = 4.80607, MAE = 2.55463, MAPE = 6.47852
Step 3 RMSE = 5.26906, MAE = 2.70957, MAPE = 7.10651
Step 4 RMSE = 5.62146, MAE = 2.82970, MAPE = 7.62543
Step 5 RMSE = 5.90646, MAE = 2.93032, MAPE = 8.06044
Step 6 RMSE = 6.15140, MAE = 3.01994, MAPE = 8.43913
Step 7 RMSE = 6.35454, MAE = 3.09523, MAPE = 8.76438
Step 8 RMSE = 6.54023, MAE = 3.16617, MAPE = 9.02314
Step 9 RMSE = 6.69752, MAE = 3.22419, MAPE = 9.32784
Step 10 RMSE = 6.83026, MAE = 3.27902, MAPE = 9.51457
Step 11 RMSE = 6.99544, MAE = 3.33693, MAPE = 9.73812
Step 12 RMSE = 7.14486, MAE = 3.40225, MAPE = 10.02365
Inference time: 7.33 s
