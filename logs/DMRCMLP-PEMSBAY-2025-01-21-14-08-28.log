PEMSBAY
--------- DMRCMLP ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        15,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 51970489,
    "gpu": [
        6
    ],
    "save": false,
    "model_args": {
        "num_nodes": 325,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        385,212
├─Linear: 1-1                                 [16, 12, 325, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 325, 48]         --
│    └─Embedding: 2-1                         [16, 12, 325, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 325, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 325, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 325, 144]        158,224
├─Predictor: 1-4                              [16, 12, 325, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 325, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 325, 144]        41,760
│    └─Linear: 2-6                            [16, 325, 12]             20,748
===============================================================================================
Total params: 1,129,504
Trainable params: 1,129,504
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.75
Forward/backward pass size (MB): 2847.94
Params size (MB): 2.98
Estimated Total Size (MB): 2851.66
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMSBAY-2025-01-21-14-08-28.pt
2025-01-21 14:11:39.942747 Epoch 1, Train Y Loss = 2.02057,  Train X Loss = 0.00000, Val Loss = 1.87145
2025-01-21 14:14:50.831100 Epoch 2, Train Y Loss = 1.66772,  Train X Loss = 0.00000, Val Loss = 1.74324
2025-01-21 14:18:01.671337 Epoch 3, Train Y Loss = 1.59467,  Train X Loss = 0.00000, Val Loss = 1.73675
2025-01-21 14:21:12.389432 Epoch 4, Train Y Loss = 1.56084,  Train X Loss = 0.00000, Val Loss = 1.67650
2025-01-21 14:24:23.083031 Epoch 5, Train Y Loss = 1.53427,  Train X Loss = 0.00000, Val Loss = 1.73438
2025-01-21 14:27:33.738199 Epoch 6, Train Y Loss = 1.51145,  Train X Loss = 0.00000, Val Loss = 1.70862
2025-01-21 14:30:44.381769 Epoch 7, Train Y Loss = 1.48924,  Train X Loss = 0.00000, Val Loss = 1.61491
2025-01-21 14:33:55.056459 Epoch 8, Train Y Loss = 1.47044,  Train X Loss = 0.00000, Val Loss = 1.62543
2025-01-21 14:37:05.736343 Epoch 9, Train Y Loss = 1.45487,  Train X Loss = 0.00000, Val Loss = 1.59625
2025-01-21 14:40:16.437451 Epoch 10, Train Y Loss = 1.44151,  Train X Loss = 0.00000, Val Loss = 1.59668
2025-01-21 14:43:27.196041 Epoch 11, Train Y Loss = 1.42885,  Train X Loss = 0.00000, Val Loss = 1.61482
2025-01-21 14:46:37.982899 Epoch 12, Train Y Loss = 1.41797,  Train X Loss = 0.00000, Val Loss = 1.59533
2025-01-21 14:49:48.670270 Epoch 13, Train Y Loss = 1.40830,  Train X Loss = 0.00000, Val Loss = 1.59646
2025-01-21 14:52:59.269525 Epoch 14, Train Y Loss = 1.40086,  Train X Loss = 0.00000, Val Loss = 1.57956
2025-01-21 14:56:09.840985 Epoch 15, Train Y Loss = 1.39358,  Train X Loss = 0.00000, Val Loss = 1.58530
2025-01-21 14:59:20.479777 Epoch 16, Train Y Loss = 1.33632,  Train X Loss = 0.00000, Val Loss = 1.54884
2025-01-21 15:02:31.110301 Epoch 17, Train Y Loss = 1.32158,  Train X Loss = 0.00000, Val Loss = 1.54946
2025-01-21 15:05:41.809636 Epoch 18, Train Y Loss = 1.31521,  Train X Loss = 0.00000, Val Loss = 1.55102
2025-01-21 15:08:52.510585 Epoch 19, Train Y Loss = 1.30849,  Train X Loss = 0.00000, Val Loss = 1.55071
2025-01-21 15:12:03.209599 Epoch 20, Train Y Loss = 1.30350,  Train X Loss = 0.00000, Val Loss = 1.55021
2025-01-21 15:15:13.803658 Epoch 21, Train Y Loss = 1.29900,  Train X Loss = 0.00000, Val Loss = 1.55223
2025-01-21 15:18:24.341754 Epoch 22, Train Y Loss = 1.29447,  Train X Loss = 0.00000, Val Loss = 1.55644
2025-01-21 15:21:35.015882 Epoch 23, Train Y Loss = 1.29061,  Train X Loss = 0.00000, Val Loss = 1.55869
2025-01-21 15:24:45.788018 Epoch 24, Train Y Loss = 1.28634,  Train X Loss = 0.00000, Val Loss = 1.56227
2025-01-21 15:27:56.583486 Epoch 25, Train Y Loss = 1.28242,  Train X Loss = 0.00000, Val Loss = 1.55477
2025-01-21 15:31:07.427940 Epoch 26, Train Y Loss = 1.27873,  Train X Loss = 0.00000, Val Loss = 1.55403
2025-01-21 15:34:18.341424 Epoch 27, Train Y Loss = 1.27520,  Train X Loss = 0.00000, Val Loss = 1.56059
2025-01-21 15:37:29.256914 Epoch 28, Train Y Loss = 1.27207,  Train X Loss = 0.00000, Val Loss = 1.55936
2025-01-21 15:40:39.963065 Epoch 29, Train Y Loss = 1.26854,  Train X Loss = 0.00000, Val Loss = 1.56427
2025-01-21 15:43:50.566024 Epoch 30, Train Y Loss = 1.26547,  Train X Loss = 0.00000, Val Loss = 1.56363
2025-01-21 15:47:01.293780 Epoch 31, Train Y Loss = 1.26205,  Train X Loss = 0.00000, Val Loss = 1.56820
2025-01-21 15:50:12.172735 Epoch 32, Train Y Loss = 1.25932,  Train X Loss = 0.00000, Val Loss = 1.56838
2025-01-21 15:53:23.134134 Epoch 33, Train Y Loss = 1.25619,  Train X Loss = 0.00000, Val Loss = 1.56738
2025-01-21 15:56:34.423137 Epoch 34, Train Y Loss = 1.25392,  Train X Loss = 0.00000, Val Loss = 1.57223
2025-01-21 15:59:45.537818 Epoch 35, Train Y Loss = 1.25128,  Train X Loss = 0.00000, Val Loss = 1.57333
2025-01-21 16:02:56.442399 Epoch 36, Train Y Loss = 1.23916,  Train X Loss = 0.00000, Val Loss = 1.56980
2025-01-21 16:06:07.184405 Epoch 37, Train Y Loss = 1.23715,  Train X Loss = 0.00000, Val Loss = 1.57121
2025-01-21 16:09:18.014697 Epoch 38, Train Y Loss = 1.23590,  Train X Loss = 0.00000, Val Loss = 1.56991
2025-01-21 16:12:29.015791 Epoch 39, Train Y Loss = 1.23510,  Train X Loss = 0.00000, Val Loss = 1.57179
2025-01-21 16:15:39.398056 Epoch 40, Train Y Loss = 1.23534,  Train X Loss = 0.00000, Val Loss = 1.57255
2025-01-21 16:18:50.350141 Epoch 41, Train Y Loss = 1.23491,  Train X Loss = 0.00000, Val Loss = 1.57282
2025-01-21 16:22:01.311490 Epoch 42, Train Y Loss = 1.23374,  Train X Loss = 0.00000, Val Loss = 1.57223
2025-01-21 16:25:12.017435 Epoch 43, Train Y Loss = 1.23301,  Train X Loss = 0.00000, Val Loss = 1.57180
2025-01-21 16:28:22.630448 Epoch 44, Train Y Loss = 1.23285,  Train X Loss = 0.00000, Val Loss = 1.57399
2025-01-21 16:31:33.454858 Epoch 45, Train Y Loss = 1.23232,  Train X Loss = 0.00000, Val Loss = 1.57408
2025-01-21 16:34:44.429507 Epoch 46, Train Y Loss = 1.23177,  Train X Loss = 0.00000, Val Loss = 1.57503
Early stopping at epoch: 46
Best at epoch 16:
Train Loss = 1.33632
Train RMSE = 2.92190, MAE = 1.30532, MAPE = 2.77998
Val Loss = 1.54884
Val RMSE = 3.60759, MAE = 1.54691, MAPE = 3.52217
--------- Test ---------
All Steps RMSE = 3.59598, MAE = 1.55721, MAPE = 3.50215
Step 1 RMSE = 1.64187, MAE = 0.86275, MAPE = 1.66541
Step 2 RMSE = 2.30592, MAE = 1.13498, MAPE = 2.30955
Step 3 RMSE = 2.81318, MAE = 1.31573, MAPE = 2.78538
Step 4 RMSE = 3.20092, MAE = 1.44652, MAPE = 3.15413
Step 5 RMSE = 3.49104, MAE = 1.54538, MAPE = 3.44151
Step 6 RMSE = 3.70932, MAE = 1.62258, MAPE = 3.67078
Step 7 RMSE = 3.88190, MAE = 1.68611, MAPE = 3.86042
Step 8 RMSE = 4.01572, MAE = 1.73725, MAPE = 4.01009
Step 9 RMSE = 4.11478, MAE = 1.77916, MAPE = 4.12828
Step 10 RMSE = 4.20146, MAE = 1.81768, MAPE = 4.23721
Step 11 RMSE = 4.27997, MAE = 1.85230, MAPE = 4.33569
Step 12 RMSE = 4.35387, MAE = 1.88609, MAPE = 4.42734
Inference time: 17.84 s
