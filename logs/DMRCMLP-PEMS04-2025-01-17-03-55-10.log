PEMS04
--------- DMRCMLP ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        55
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 34110658,
    "gpu": [
        1
    ],
    "save": false,
    "model_args": {
        "num_nodes": 307,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        390,540
├─Linear: 1-1                                 [16, 12, 307, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 307, 48]         --
│    └─Embedding: 2-1                         [16, 12, 307, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 307, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 307, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 307, 144]        158,224
├─Predictor: 1-4                              [16, 12, 307, 1]          --
│    └─Linear: 2-5                            [16, 12, 307, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 307, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 307, 144]        41,760
│    └─Linear: 2-7                            [16, 307, 12]             20,748
===============================================================================================
Total params: 1,155,712
Trainable params: 1,155,712
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.71
Forward/backward pass size (MB): 2758.11
Params size (MB): 3.06
Estimated Total Size (MB): 2761.88
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS04-2025-01-17-03-55-10.pt
2025-01-17 03:56:26.794045 Epoch 1, Train Y Loss = 28.96339,  Train X Loss = 22.50484, Val Loss = 24.38881
2025-01-17 03:57:42.497699 Epoch 2, Train Y Loss = 22.66073,  Train X Loss = 17.42101, Val Loss = 22.06151
2025-01-17 03:58:58.100830 Epoch 3, Train Y Loss = 21.23594,  Train X Loss = 16.97426, Val Loss = 21.39480
2025-01-17 04:00:13.723975 Epoch 4, Train Y Loss = 20.46166,  Train X Loss = 16.72250, Val Loss = 21.03447
2025-01-17 04:01:29.325673 Epoch 5, Train Y Loss = 19.77899,  Train X Loss = 16.53225, Val Loss = 20.60308
2025-01-17 04:02:44.937967 Epoch 6, Train Y Loss = 19.26588,  Train X Loss = 16.36916, Val Loss = 19.45324
2025-01-17 04:04:00.521675 Epoch 7, Train Y Loss = 18.94535,  Train X Loss = 16.24119, Val Loss = 19.41845
2025-01-17 04:05:16.225920 Epoch 8, Train Y Loss = 18.66360,  Train X Loss = 16.16835, Val Loss = 18.76217
2025-01-17 04:06:31.688605 Epoch 9, Train Y Loss = 18.40728,  Train X Loss = 15.97278, Val Loss = 18.82848
2025-01-17 04:07:47.170990 Epoch 10, Train Y Loss = 18.32840,  Train X Loss = 15.94234, Val Loss = 19.17253
2025-01-17 04:09:02.950502 Epoch 11, Train Y Loss = 18.15628,  Train X Loss = 15.75131, Val Loss = 18.93929
2025-01-17 04:10:18.730851 Epoch 12, Train Y Loss = 17.99664,  Train X Loss = 15.68113, Val Loss = 18.61601
2025-01-17 04:11:34.617948 Epoch 13, Train Y Loss = 17.83491,  Train X Loss = 15.57973, Val Loss = 18.78296
2025-01-17 04:12:50.429433 Epoch 14, Train Y Loss = 17.73583,  Train X Loss = 15.48484, Val Loss = 18.60059
2025-01-17 04:14:06.339398 Epoch 15, Train Y Loss = 17.62928,  Train X Loss = 15.36727, Val Loss = 18.37843
2025-01-17 04:15:22.024807 Epoch 16, Train Y Loss = 17.49163,  Train X Loss = 15.31338, Val Loss = 18.22802
2025-01-17 04:16:37.748207 Epoch 17, Train Y Loss = 17.46655,  Train X Loss = 15.28248, Val Loss = 18.08986
2025-01-17 04:17:53.402994 Epoch 18, Train Y Loss = 17.35837,  Train X Loss = 15.22266, Val Loss = 18.38885
2025-01-17 04:19:09.218413 Epoch 19, Train Y Loss = 17.28120,  Train X Loss = 15.18638, Val Loss = 17.94741
2025-01-17 04:20:25.133409 Epoch 20, Train Y Loss = 17.24638,  Train X Loss = 15.16713, Val Loss = 17.94441
2025-01-17 04:21:40.973229 Epoch 21, Train Y Loss = 16.60741,  Train X Loss = 14.83014, Val Loss = 17.59993
2025-01-17 04:22:56.899332 Epoch 22, Train Y Loss = 16.51254,  Train X Loss = 14.76877, Val Loss = 17.57118
2025-01-17 04:24:12.876512 Epoch 23, Train Y Loss = 16.47011,  Train X Loss = 14.75702, Val Loss = 17.50290
2025-01-17 04:25:29.097309 Epoch 24, Train Y Loss = 16.44758,  Train X Loss = 14.72754, Val Loss = 17.50987
2025-01-17 04:26:45.147428 Epoch 25, Train Y Loss = 16.42047,  Train X Loss = 14.74623, Val Loss = 17.57240
2025-01-17 04:28:01.259399 Epoch 26, Train Y Loss = 16.40097,  Train X Loss = 14.72188, Val Loss = 17.50484
2025-01-17 04:29:17.249939 Epoch 27, Train Y Loss = 16.37466,  Train X Loss = 14.71417, Val Loss = 17.54264
2025-01-17 04:30:33.071762 Epoch 28, Train Y Loss = 16.33967,  Train X Loss = 14.69721, Val Loss = 17.53861
2025-01-17 04:31:48.964614 Epoch 29, Train Y Loss = 16.32720,  Train X Loss = 14.69288, Val Loss = 17.51034
2025-01-17 04:33:04.850665 Epoch 30, Train Y Loss = 16.31088,  Train X Loss = 14.68094, Val Loss = 17.58849
2025-01-17 04:34:20.773495 Epoch 31, Train Y Loss = 16.28280,  Train X Loss = 14.68032, Val Loss = 17.51277
2025-01-17 04:35:36.576396 Epoch 32, Train Y Loss = 16.26926,  Train X Loss = 14.65689, Val Loss = 17.51283
2025-01-17 04:36:52.371079 Epoch 33, Train Y Loss = 16.25291,  Train X Loss = 14.64954, Val Loss = 17.53830
2025-01-17 04:38:08.206241 Epoch 34, Train Y Loss = 16.23450,  Train X Loss = 14.65043, Val Loss = 17.47938
2025-01-17 04:39:23.949175 Epoch 35, Train Y Loss = 16.21804,  Train X Loss = 14.64902, Val Loss = 17.46300
2025-01-17 04:40:39.772236 Epoch 36, Train Y Loss = 16.14034,  Train X Loss = 14.59468, Val Loss = 17.43817
2025-01-17 04:41:55.535718 Epoch 37, Train Y Loss = 16.13508,  Train X Loss = 14.59624, Val Loss = 17.43268
2025-01-17 04:43:11.354186 Epoch 38, Train Y Loss = 16.13074,  Train X Loss = 14.60656, Val Loss = 17.42079
2025-01-17 04:44:27.061545 Epoch 39, Train Y Loss = 16.12764,  Train X Loss = 14.59273, Val Loss = 17.42604
2025-01-17 04:45:42.812625 Epoch 40, Train Y Loss = 16.12216,  Train X Loss = 14.58742, Val Loss = 17.42535
2025-01-17 04:46:58.595761 Epoch 41, Train Y Loss = 16.12004,  Train X Loss = 14.58532, Val Loss = 17.43046
2025-01-17 04:48:14.351064 Epoch 42, Train Y Loss = 16.11727,  Train X Loss = 14.58438, Val Loss = 17.41316
2025-01-17 04:49:30.158111 Epoch 43, Train Y Loss = 16.11370,  Train X Loss = 14.58041, Val Loss = 17.42776
2025-01-17 04:50:45.873138 Epoch 44, Train Y Loss = 16.11481,  Train X Loss = 14.58689, Val Loss = 17.42947
2025-01-17 04:52:01.708096 Epoch 45, Train Y Loss = 16.10901,  Train X Loss = 14.59215, Val Loss = 17.42574
2025-01-17 04:53:17.526554 Epoch 46, Train Y Loss = 16.10421,  Train X Loss = 14.57839, Val Loss = 17.43414
2025-01-17 04:54:33.382701 Epoch 47, Train Y Loss = 16.10259,  Train X Loss = 14.57791, Val Loss = 17.42894
2025-01-17 04:55:49.265537 Epoch 48, Train Y Loss = 16.10974,  Train X Loss = 14.57869, Val Loss = 17.41638
2025-01-17 04:57:05.068876 Epoch 49, Train Y Loss = 16.10403,  Train X Loss = 14.58131, Val Loss = 17.44339
2025-01-17 04:58:20.995758 Epoch 50, Train Y Loss = 16.09849,  Train X Loss = 14.57883, Val Loss = 17.41456
2025-01-17 04:59:36.808604 Epoch 51, Train Y Loss = 16.09456,  Train X Loss = 14.57613, Val Loss = 17.41768
2025-01-17 05:00:52.712675 Epoch 52, Train Y Loss = 16.09341,  Train X Loss = 14.56810, Val Loss = 17.41699
2025-01-17 05:02:08.533805 Epoch 53, Train Y Loss = 16.09158,  Train X Loss = 14.58175, Val Loss = 17.43172
2025-01-17 05:03:24.368642 Epoch 54, Train Y Loss = 16.09562,  Train X Loss = 14.59536, Val Loss = 17.42336
2025-01-17 05:04:40.220140 Epoch 55, Train Y Loss = 16.08698,  Train X Loss = 14.57978, Val Loss = 17.42141
2025-01-17 05:05:55.978514 Epoch 56, Train Y Loss = 16.08943,  Train X Loss = 14.58572, Val Loss = 17.42347
2025-01-17 05:07:11.766934 Epoch 57, Train Y Loss = 16.08419,  Train X Loss = 14.57053, Val Loss = 17.42527
2025-01-17 05:08:27.470247 Epoch 58, Train Y Loss = 16.07853,  Train X Loss = 14.57724, Val Loss = 17.41628
2025-01-17 05:09:43.436626 Epoch 59, Train Y Loss = 16.07824,  Train X Loss = 14.57281, Val Loss = 17.42267
2025-01-17 05:10:59.112045 Epoch 60, Train Y Loss = 16.07853,  Train X Loss = 14.59142, Val Loss = 17.42049
2025-01-17 05:12:14.731907 Epoch 61, Train Y Loss = 16.08435,  Train X Loss = 14.57588, Val Loss = 17.41877
2025-01-17 05:13:30.450955 Epoch 62, Train Y Loss = 16.07910,  Train X Loss = 14.56173, Val Loss = 17.42430
2025-01-17 05:14:46.062553 Epoch 63, Train Y Loss = 16.07447,  Train X Loss = 14.57009, Val Loss = 17.42140
2025-01-17 05:16:01.713919 Epoch 64, Train Y Loss = 16.07954,  Train X Loss = 14.56625, Val Loss = 17.42459
2025-01-17 05:17:17.220834 Epoch 65, Train Y Loss = 16.07697,  Train X Loss = 14.57454, Val Loss = 17.41912
2025-01-17 05:18:32.715567 Epoch 66, Train Y Loss = 16.08163,  Train X Loss = 14.56712, Val Loss = 17.42441
2025-01-17 05:19:48.135987 Epoch 67, Train Y Loss = 16.08021,  Train X Loss = 14.56912, Val Loss = 17.42238
2025-01-17 05:21:03.484432 Epoch 68, Train Y Loss = 16.07942,  Train X Loss = 14.56791, Val Loss = 17.42358
2025-01-17 05:22:18.933853 Epoch 69, Train Y Loss = 16.07353,  Train X Loss = 14.55954, Val Loss = 17.42514
2025-01-17 05:23:34.418156 Epoch 70, Train Y Loss = 16.07232,  Train X Loss = 14.57003, Val Loss = 17.42397
2025-01-17 05:24:50.041018 Epoch 71, Train Y Loss = 16.07455,  Train X Loss = 14.57247, Val Loss = 17.42566
2025-01-17 05:26:05.747465 Epoch 72, Train Y Loss = 16.07449,  Train X Loss = 14.57951, Val Loss = 17.42457
Early stopping at epoch: 72
Best at epoch 42:
Train Loss = 16.11727
Train RMSE = 27.75746, MAE = 16.57663, MAPE = 11.78417
Val Loss = 17.41316
Val RMSE = 30.53025, MAE = 18.10384, MAPE = 11.66194
--------- Test ---------
All Steps RMSE = 30.57903, MAE = 18.18295, MAPE = 11.95047
Step 1 RMSE = 26.68663, MAE = 16.33823, MAPE = 10.79439
Step 2 RMSE = 27.91070, MAE = 16.92719, MAPE = 11.21507
Step 3 RMSE = 28.90759, MAE = 17.38577, MAPE = 11.49945
Step 4 RMSE = 29.69005, MAE = 17.73354, MAPE = 11.69634
Step 5 RMSE = 30.32214, MAE = 18.01570, MAPE = 11.85453
Step 6 RMSE = 30.81521, MAE = 18.24454, MAPE = 11.97217
Step 7 RMSE = 31.21716, MAE = 18.44438, MAPE = 12.09341
Step 8 RMSE = 31.55790, MAE = 18.62707, MAPE = 12.20058
Step 9 RMSE = 31.89770, MAE = 18.82812, MAPE = 12.32678
Step 10 RMSE = 32.15466, MAE = 19.01548, MAPE = 12.45858
Step 11 RMSE = 32.41973, MAE = 19.20911, MAPE = 12.57022
Step 12 RMSE = 32.72173, MAE = 19.42608, MAPE = 12.72406
Inference time: 5.99 s
