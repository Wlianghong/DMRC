PEMS03
--------- DMRCMLP ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        50
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": true,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 34110658,
    "gpu": [
        3
    ],
    "save": false,
    "model_args": {
        "num_nodes": 358,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        434,604
├─Linear: 1-1                                 [16, 12, 358, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 358, 48]         --
│    └─Embedding: 2-1                         [16, 12, 358, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 358, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 358, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 358, 144]        158,224
├─Predictor: 1-4                              [16, 12, 358, 1]          --
│    └─Linear: 2-5                            [16, 12, 358, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 358, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 358, 144]        41,760
│    └─Linear: 2-7                            [16, 358, 12]             20,748
===============================================================================================
Total params: 1,199,776
Trainable params: 1,199,776
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.82
Forward/backward pass size (MB): 3216.29
Params size (MB): 3.06
Estimated Total Size (MB): 3220.18
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS03-2025-01-18-00-39-12.pt
2025-01-18 00:41:17.744419 Epoch 1, Train Y Loss = 21.41374,  Train X Loss = 0.00000, Val Loss = 16.63423
2025-01-18 00:43:23.854677 Epoch 2, Train Y Loss = 16.66244,  Train X Loss = 0.00000, Val Loss = 16.46166
2025-01-18 00:45:29.038811 Epoch 3, Train Y Loss = 15.63978,  Train X Loss = 0.00000, Val Loss = 15.47829
2025-01-18 00:47:34.620633 Epoch 4, Train Y Loss = 15.00943,  Train X Loss = 0.00000, Val Loss = 14.48152
2025-01-18 00:49:39.735678 Epoch 5, Train Y Loss = 14.55286,  Train X Loss = 0.00000, Val Loss = 15.57455
2025-01-18 00:51:44.688208 Epoch 6, Train Y Loss = 14.36047,  Train X Loss = 0.00000, Val Loss = 14.10413
2025-01-18 00:53:50.320398 Epoch 7, Train Y Loss = 13.99886,  Train X Loss = 0.00000, Val Loss = 14.41361
2025-01-18 00:55:56.986639 Epoch 8, Train Y Loss = 13.74293,  Train X Loss = 0.00000, Val Loss = 14.04803
2025-01-18 00:58:03.582598 Epoch 9, Train Y Loss = 13.61702,  Train X Loss = 0.00000, Val Loss = 14.65422
2025-01-18 01:00:10.279635 Epoch 10, Train Y Loss = 13.50589,  Train X Loss = 0.00000, Val Loss = 14.04211
2025-01-18 01:02:16.366589 Epoch 11, Train Y Loss = 13.28821,  Train X Loss = 0.00000, Val Loss = 13.78425
2025-01-18 01:04:21.919575 Epoch 12, Train Y Loss = 13.22616,  Train X Loss = 0.00000, Val Loss = 14.04586
2025-01-18 01:06:27.041598 Epoch 13, Train Y Loss = 13.11818,  Train X Loss = 0.00000, Val Loss = 13.65523
2025-01-18 01:08:33.169498 Epoch 14, Train Y Loss = 12.99602,  Train X Loss = 0.00000, Val Loss = 14.05206
2025-01-18 01:10:38.801759 Epoch 15, Train Y Loss = 12.94350,  Train X Loss = 0.00000, Val Loss = 13.51053
2025-01-18 01:12:44.498600 Epoch 16, Train Y Loss = 12.86631,  Train X Loss = 0.00000, Val Loss = 13.83178
2025-01-18 01:14:50.172268 Epoch 17, Train Y Loss = 12.78323,  Train X Loss = 0.00000, Val Loss = 13.54652
2025-01-18 01:16:55.708292 Epoch 18, Train Y Loss = 12.71589,  Train X Loss = 0.00000, Val Loss = 13.51916
2025-01-18 01:19:01.592704 Epoch 19, Train Y Loss = 12.73422,  Train X Loss = 0.00000, Val Loss = 13.42248
2025-01-18 01:21:06.755418 Epoch 20, Train Y Loss = 12.60421,  Train X Loss = 0.00000, Val Loss = 13.58546
2025-01-18 01:23:12.946539 Epoch 21, Train Y Loss = 12.12409,  Train X Loss = 0.00000, Val Loss = 13.13050
2025-01-18 01:25:18.465971 Epoch 22, Train Y Loss = 12.05266,  Train X Loss = 0.00000, Val Loss = 13.19737
2025-01-18 01:27:24.589697 Epoch 23, Train Y Loss = 12.02814,  Train X Loss = 0.00000, Val Loss = 13.17702
2025-01-18 01:29:30.476133 Epoch 24, Train Y Loss = 12.00563,  Train X Loss = 0.00000, Val Loss = 13.21580
2025-01-18 01:31:36.598369 Epoch 25, Train Y Loss = 11.98680,  Train X Loss = 0.00000, Val Loss = 13.20073
2025-01-18 01:33:42.277771 Epoch 26, Train Y Loss = 11.96705,  Train X Loss = 0.00000, Val Loss = 13.26238
2025-01-18 01:35:48.125567 Epoch 27, Train Y Loss = 11.95096,  Train X Loss = 0.00000, Val Loss = 13.23917
2025-01-18 01:37:53.825586 Epoch 28, Train Y Loss = 11.93494,  Train X Loss = 0.00000, Val Loss = 13.20125
2025-01-18 01:39:59.616662 Epoch 29, Train Y Loss = 11.92142,  Train X Loss = 0.00000, Val Loss = 13.19093
Change mask ratio: 0.075
2025-01-18 01:42:03.403233 Epoch 30, Train Y Loss = 11.86570,  Train X Loss = 0.00000, Val Loss = 13.11136
2025-01-18 01:44:06.852083 Epoch 31, Train Y Loss = 11.84944,  Train X Loss = 0.00000, Val Loss = 13.11933
2025-01-18 01:46:10.150126 Epoch 32, Train Y Loss = 11.83818,  Train X Loss = 0.00000, Val Loss = 13.27353
2025-01-18 01:48:12.856404 Epoch 33, Train Y Loss = 11.82234,  Train X Loss = 0.00000, Val Loss = 13.12098
2025-01-18 01:50:16.022831 Epoch 34, Train Y Loss = 11.81080,  Train X Loss = 0.00000, Val Loss = 13.18061
2025-01-18 01:52:19.615258 Epoch 35, Train Y Loss = 11.79743,  Train X Loss = 0.00000, Val Loss = 13.13839
2025-01-18 01:54:23.815067 Epoch 36, Train Y Loss = 11.73237,  Train X Loss = 0.00000, Val Loss = 13.13391
2025-01-18 01:56:29.251656 Epoch 37, Train Y Loss = 11.72363,  Train X Loss = 0.00000, Val Loss = 13.11148
2025-01-18 01:58:33.710008 Epoch 38, Train Y Loss = 11.72108,  Train X Loss = 0.00000, Val Loss = 13.12585
Change mask ratio: 0.0375
2025-01-18 02:00:36.014798 Epoch 39, Train Y Loss = 11.69501,  Train X Loss = 0.00000, Val Loss = 13.07721
2025-01-18 02:02:38.755122 Epoch 40, Train Y Loss = 11.69186,  Train X Loss = 0.00000, Val Loss = 13.06236
2025-01-18 02:04:41.431200 Epoch 41, Train Y Loss = 11.68993,  Train X Loss = 0.00000, Val Loss = 13.08618
2025-01-18 02:06:44.127282 Epoch 42, Train Y Loss = 11.68676,  Train X Loss = 0.00000, Val Loss = 13.06814
2025-01-18 02:08:47.069483 Epoch 43, Train Y Loss = 11.68451,  Train X Loss = 0.00000, Val Loss = 13.10739
2025-01-18 02:10:49.960758 Epoch 44, Train Y Loss = 11.68314,  Train X Loss = 0.00000, Val Loss = 13.09247
2025-01-18 02:12:52.662118 Epoch 45, Train Y Loss = 11.68004,  Train X Loss = 0.00000, Val Loss = 13.08718
2025-01-18 02:14:55.114862 Epoch 46, Train Y Loss = 11.67902,  Train X Loss = 0.00000, Val Loss = 13.07757
2025-01-18 02:16:57.580362 Epoch 47, Train Y Loss = 11.67711,  Train X Loss = 0.00000, Val Loss = 13.11314
2025-01-18 02:18:59.986520 Epoch 48, Train Y Loss = 11.67496,  Train X Loss = 0.00000, Val Loss = 13.11695
Change mask ratio: 0.0
2025-01-18 02:20:47.588850 Epoch 49, Train Y Loss = 11.65622,  Train X Loss = 0.00000, Val Loss = 13.02444
2025-01-18 02:22:35.029427 Epoch 50, Train Y Loss = 11.64947,  Train X Loss = 0.00000, Val Loss = 13.01438
2025-01-18 02:24:22.456473 Epoch 51, Train Y Loss = 11.64025,  Train X Loss = 0.00000, Val Loss = 13.02394
2025-01-18 02:26:09.523695 Epoch 52, Train Y Loss = 11.63983,  Train X Loss = 0.00000, Val Loss = 13.01878
2025-01-18 02:27:56.978887 Epoch 53, Train Y Loss = 11.63936,  Train X Loss = 0.00000, Val Loss = 13.02110
2025-01-18 02:29:44.416210 Epoch 54, Train Y Loss = 11.63820,  Train X Loss = 0.00000, Val Loss = 13.02186
2025-01-18 02:31:31.805527 Epoch 55, Train Y Loss = 11.63848,  Train X Loss = 0.00000, Val Loss = 13.01553
2025-01-18 02:33:19.161257 Epoch 56, Train Y Loss = 11.63740,  Train X Loss = 0.00000, Val Loss = 13.01808
2025-01-18 02:35:06.777098 Epoch 57, Train Y Loss = 11.63752,  Train X Loss = 0.00000, Val Loss = 13.02417
2025-01-18 02:36:54.279723 Epoch 58, Train Y Loss = 11.63694,  Train X Loss = 0.00000, Val Loss = 13.02525
Change mask ratio: 0.0
2025-01-18 02:38:41.959875 Epoch 59, Train Y Loss = 11.63743,  Train X Loss = 0.00000, Val Loss = 13.01790
2025-01-18 02:40:29.548647 Epoch 60, Train Y Loss = 11.63719,  Train X Loss = 0.00000, Val Loss = 13.02077
2025-01-18 02:42:17.000459 Epoch 61, Train Y Loss = 11.63593,  Train X Loss = 0.00000, Val Loss = 13.01688
2025-01-18 02:44:04.131288 Epoch 62, Train Y Loss = 11.63616,  Train X Loss = 0.00000, Val Loss = 13.01572
2025-01-18 02:45:51.764037 Epoch 63, Train Y Loss = 11.63555,  Train X Loss = 0.00000, Val Loss = 13.02101
2025-01-18 02:47:39.178032 Epoch 64, Train Y Loss = 11.63474,  Train X Loss = 0.00000, Val Loss = 13.02160
2025-01-18 02:49:26.832873 Epoch 65, Train Y Loss = 11.63535,  Train X Loss = 0.00000, Val Loss = 13.02143
2025-01-18 02:51:14.319957 Epoch 66, Train Y Loss = 11.63521,  Train X Loss = 0.00000, Val Loss = 13.02019
Change mask ratio: 0.0
2025-01-18 02:53:02.247530 Epoch 67, Train Y Loss = 11.63430,  Train X Loss = 0.00000, Val Loss = 13.02012
2025-01-18 02:54:50.256952 Epoch 68, Train Y Loss = 11.63389,  Train X Loss = 0.00000, Val Loss = 13.02319
2025-01-18 02:56:38.455434 Epoch 69, Train Y Loss = 11.63454,  Train X Loss = 0.00000, Val Loss = 13.01690
2025-01-18 02:58:26.780232 Epoch 70, Train Y Loss = 11.63289,  Train X Loss = 0.00000, Val Loss = 13.02024
Early stopping at epoch: 70
Best at epoch 50:
Train Loss = 11.64947
Train RMSE = 19.98546, MAE = 12.04133, MAPE = 11.12507
Val Loss = 13.01438
Val RMSE = 22.09166, MAE = 13.53693, MAPE = 12.69974
--------- Test ---------
All Steps RMSE = 26.58119, MAE = 15.46641, MAPE = 15.32001
Step 1 RMSE = 20.25665, MAE = 12.65482, MAPE = 13.04503
Step 2 RMSE = 22.26022, MAE = 13.46553, MAPE = 13.76558
Step 3 RMSE = 23.81815, MAE = 14.13741, MAPE = 14.29999
Step 4 RMSE = 25.06975, MAE = 14.69362, MAPE = 14.68524
Step 5 RMSE = 26.02499, MAE = 15.14800, MAPE = 15.03039
Step 6 RMSE = 26.78986, MAE = 15.53771, MAPE = 15.33506
Step 7 RMSE = 27.47303, MAE = 15.89560, MAPE = 15.61590
Step 8 RMSE = 28.05488, MAE = 16.22409, MAPE = 15.89432
Step 9 RMSE = 28.58207, MAE = 16.52606, MAPE = 16.16028
Step 10 RMSE = 29.08974, MAE = 16.82449, MAPE = 16.41961
Step 11 RMSE = 29.55532, MAE = 17.09746, MAPE = 16.65332
Step 12 RMSE = 30.05935, MAE = 17.39211, MAPE = 16.93516
Inference time: 10.97 s
