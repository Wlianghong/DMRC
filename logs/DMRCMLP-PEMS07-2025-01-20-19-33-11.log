PEMS07
--------- DMRCMLP ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.001,
    "milestones": [
        20,
        40,
        55
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 25,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 6,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 34110658,
    "gpu": [
        4,
        5
    ],
    "save": false,
    "model_args": {
        "num_nodes": 883,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        888,204
├─Linear: 1-1                                 [16, 12, 883, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 883, 48]         --
│    └─Embedding: 2-1                         [16, 12, 883, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 883, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 883, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 883, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 883, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 883, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 883, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 883, 144]        158,224
├─Predictor: 1-4                              [16, 12, 883, 1]          --
│    └─Linear: 2-5                            [16, 12, 883, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 883, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 883, 144]        41,760
│    └─Linear: 2-7                            [16, 883, 12]             20,748
===============================================================================================
Total params: 1,653,376
Trainable params: 1,653,376
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 2.03
Forward/backward pass size (MB): 7932.93
Params size (MB): 3.06
Estimated Total Size (MB): 7938.02
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS07-2025-01-20-19-33-11.pt
2025-01-20 19:36:44.787163 Epoch 1, Train Y Loss = 30.16992,  Train X Loss = 0.00000, Val Loss = 24.86556
2025-01-20 19:40:17.899425 Epoch 2, Train Y Loss = 23.54235,  Train X Loss = 0.00000, Val Loss = 22.42663
2025-01-20 19:43:48.697043 Epoch 3, Train Y Loss = 22.32284,  Train X Loss = 0.00000, Val Loss = 21.61912
2025-01-20 19:47:20.321015 Epoch 4, Train Y Loss = 21.39010,  Train X Loss = 0.00000, Val Loss = 20.88154
2025-01-20 19:50:53.586009 Epoch 5, Train Y Loss = 20.95219,  Train X Loss = 0.00000, Val Loss = 20.67312
2025-01-20 19:54:26.308586 Epoch 6, Train Y Loss = 20.39827,  Train X Loss = 0.00000, Val Loss = 20.04857
2025-01-20 19:57:58.655253 Epoch 7, Train Y Loss = 20.00173,  Train X Loss = 0.00000, Val Loss = 20.31130
2025-01-20 20:01:31.669951 Epoch 8, Train Y Loss = 19.72767,  Train X Loss = 0.00000, Val Loss = 19.74303
2025-01-20 20:05:04.144738 Epoch 9, Train Y Loss = 19.46900,  Train X Loss = 0.00000, Val Loss = 19.89739
2025-01-20 20:08:37.256305 Epoch 10, Train Y Loss = 19.19595,  Train X Loss = 0.00000, Val Loss = 19.33264
2025-01-20 20:12:07.980706 Epoch 11, Train Y Loss = 19.03473,  Train X Loss = 0.00000, Val Loss = 19.77170
2025-01-20 20:15:38.349452 Epoch 12, Train Y Loss = 18.84196,  Train X Loss = 0.00000, Val Loss = 19.53726
2025-01-20 20:19:08.715427 Epoch 13, Train Y Loss = 18.68945,  Train X Loss = 0.00000, Val Loss = 19.25869
2025-01-20 20:22:39.486181 Epoch 14, Train Y Loss = 18.57572,  Train X Loss = 0.00000, Val Loss = 19.44216
2025-01-20 20:26:10.886235 Epoch 15, Train Y Loss = 18.49224,  Train X Loss = 0.00000, Val Loss = 18.88852
2025-01-20 20:29:42.112801 Epoch 16, Train Y Loss = 18.35015,  Train X Loss = 0.00000, Val Loss = 19.03304
2025-01-20 20:33:14.544424 Epoch 17, Train Y Loss = 18.29470,  Train X Loss = 0.00000, Val Loss = 19.71963
2025-01-20 20:36:46.833398 Epoch 18, Train Y Loss = 18.25222,  Train X Loss = 0.00000, Val Loss = 18.66437
2025-01-20 20:40:19.081429 Epoch 19, Train Y Loss = 18.08923,  Train X Loss = 0.00000, Val Loss = 18.83642
2025-01-20 20:43:50.856740 Epoch 20, Train Y Loss = 18.05796,  Train X Loss = 0.00000, Val Loss = 18.83027
2025-01-20 20:47:22.200948 Epoch 21, Train Y Loss = 17.32085,  Train X Loss = 0.00000, Val Loss = 18.20402
2025-01-20 20:50:54.069316 Epoch 22, Train Y Loss = 17.21565,  Train X Loss = 0.00000, Val Loss = 18.25660
2025-01-20 20:54:26.021386 Epoch 23, Train Y Loss = 17.17358,  Train X Loss = 0.00000, Val Loss = 18.25235
2025-01-20 20:57:56.775286 Epoch 24, Train Y Loss = 17.13847,  Train X Loss = 0.00000, Val Loss = 18.26056
2025-01-20 21:01:28.712511 Epoch 25, Train Y Loss = 17.10570,  Train X Loss = 0.00000, Val Loss = 18.20789
2025-01-20 21:05:00.382247 Epoch 26, Train Y Loss = 17.07653,  Train X Loss = 0.00000, Val Loss = 18.28664
2025-01-20 21:08:32.651525 Epoch 27, Train Y Loss = 17.04886,  Train X Loss = 0.00000, Val Loss = 18.14032
2025-01-20 21:12:04.540191 Epoch 28, Train Y Loss = 17.02359,  Train X Loss = 0.00000, Val Loss = 18.30603
2025-01-20 21:15:36.752039 Epoch 29, Train Y Loss = 16.99887,  Train X Loss = 0.00000, Val Loss = 18.29954
2025-01-20 21:19:09.732181 Epoch 30, Train Y Loss = 16.97809,  Train X Loss = 0.00000, Val Loss = 18.20495
2025-01-20 21:22:41.279704 Epoch 31, Train Y Loss = 16.95648,  Train X Loss = 0.00000, Val Loss = 18.25679
2025-01-20 21:26:14.176691 Epoch 32, Train Y Loss = 16.93114,  Train X Loss = 0.00000, Val Loss = 18.28211
2025-01-20 21:29:46.124242 Epoch 33, Train Y Loss = 16.91312,  Train X Loss = 0.00000, Val Loss = 18.32086
2025-01-20 21:33:18.600799 Epoch 34, Train Y Loss = 16.88871,  Train X Loss = 0.00000, Val Loss = 18.38544
2025-01-20 21:36:49.990329 Epoch 35, Train Y Loss = 16.87177,  Train X Loss = 0.00000, Val Loss = 18.31782
2025-01-20 21:40:21.182476 Epoch 36, Train Y Loss = 16.84890,  Train X Loss = 0.00000, Val Loss = 18.29977
2025-01-20 21:43:52.309960 Epoch 37, Train Y Loss = 16.83117,  Train X Loss = 0.00000, Val Loss = 18.30269
2025-01-20 21:47:23.990283 Epoch 38, Train Y Loss = 16.80725,  Train X Loss = 0.00000, Val Loss = 18.34405
2025-01-20 21:50:55.525905 Epoch 39, Train Y Loss = 16.78936,  Train X Loss = 0.00000, Val Loss = 18.31506
2025-01-20 21:54:26.879957 Epoch 40, Train Y Loss = 16.77306,  Train X Loss = 0.00000, Val Loss = 18.25902
2025-01-20 21:57:58.431731 Epoch 41, Train Y Loss = 16.66505,  Train X Loss = 0.00000, Val Loss = 18.29865
2025-01-20 22:01:30.164002 Epoch 42, Train Y Loss = 16.65157,  Train X Loss = 0.00000, Val Loss = 18.30698
2025-01-20 22:05:01.668460 Epoch 43, Train Y Loss = 16.64760,  Train X Loss = 0.00000, Val Loss = 18.30667
2025-01-20 22:08:32.877306 Epoch 44, Train Y Loss = 16.64236,  Train X Loss = 0.00000, Val Loss = 18.29139
2025-01-20 22:12:04.285515 Epoch 45, Train Y Loss = 16.63706,  Train X Loss = 0.00000, Val Loss = 18.32389
2025-01-20 22:15:37.180420 Epoch 46, Train Y Loss = 16.63476,  Train X Loss = 0.00000, Val Loss = 18.28423
2025-01-20 22:19:09.791607 Epoch 47, Train Y Loss = 16.63040,  Train X Loss = 0.00000, Val Loss = 18.31887
2025-01-20 22:22:42.347664 Epoch 48, Train Y Loss = 16.62667,  Train X Loss = 0.00000, Val Loss = 18.30299
2025-01-20 22:26:14.465522 Epoch 49, Train Y Loss = 16.62313,  Train X Loss = 0.00000, Val Loss = 18.32714
2025-01-20 22:29:45.665137 Epoch 50, Train Y Loss = 16.61981,  Train X Loss = 0.00000, Val Loss = 18.32419
2025-01-20 22:33:17.367854 Epoch 51, Train Y Loss = 16.61578,  Train X Loss = 0.00000, Val Loss = 18.32321
2025-01-20 22:36:49.132377 Epoch 52, Train Y Loss = 16.61403,  Train X Loss = 0.00000, Val Loss = 18.31950
Early stopping at epoch: 52
Best at epoch 27:
Train Loss = 17.04886
Train RMSE = 30.04435, MAE = 17.36798, MAPE = 7.63184
Val Loss = 18.14032
Val RMSE = 32.10836, MAE = 18.66002, MAPE = 8.15531
--------- Test ---------
All Steps RMSE = 32.57682, MAE = 19.08216, MAPE = 8.01567
Step 1 RMSE = 26.86641, MAE = 16.34558, MAPE = 6.89679
Step 2 RMSE = 28.86857, MAE = 17.21501, MAPE = 7.20215
Step 3 RMSE = 30.17237, MAE = 17.84415, MAPE = 7.45993
Step 4 RMSE = 31.16781, MAE = 18.34155, MAPE = 7.64639
Step 5 RMSE = 31.98625, MAE = 18.75982, MAPE = 7.84076
Step 6 RMSE = 32.70843, MAE = 19.13959, MAPE = 7.98740
Step 7 RMSE = 33.35628, MAE = 19.48635, MAPE = 8.12904
Step 8 RMSE = 33.91749, MAE = 19.80125, MAPE = 8.29840
Step 9 RMSE = 34.40610, MAE = 20.07168, MAPE = 8.48970
Step 10 RMSE = 34.89838, MAE = 20.36186, MAPE = 8.62552
Step 11 RMSE = 35.38783, MAE = 20.64347, MAPE = 8.71366
Step 12 RMSE = 35.88680, MAE = 20.97297, MAPE = 8.89735
Inference time: 28.09 s
