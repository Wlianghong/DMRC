METRLA
--------- DMRCMLP ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        25,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        0
    ],
    "save": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        283,260
├─Linear: 1-1                                 [16, 12, 207, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 207, 48]         --
│    └─Embedding: 2-1                         [16, 12, 207, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 207, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 207, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 207, 144]        158,224
├─Predictor: 1-4                              [16, 12, 207, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 207, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 207, 144]        41,760
│    └─Linear: 2-6                            [16, 207, 12]             20,748
===============================================================================================
Total params: 1,027,552
Trainable params: 1,027,552
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.48
Forward/backward pass size (MB): 1813.92
Params size (MB): 2.98
Estimated Total Size (MB): 1817.37
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-METRLA-2025-01-17-10-21-09.pt
2025-01-17 10:22:54.150235 Epoch 1, Train Y Loss = 4.11408,  Train X Loss = 2.65981, Val Loss = 3.27742
2025-01-17 10:24:26.640594 Epoch 2, Train Y Loss = 3.42537,  Train X Loss = 2.27012, Val Loss = 3.18813
2025-01-17 10:26:11.535422 Epoch 3, Train Y Loss = 3.27008,  Train X Loss = 2.21746, Val Loss = 3.00071
2025-01-17 10:27:58.133618 Epoch 4, Train Y Loss = 3.15476,  Train X Loss = 2.19201, Val Loss = 2.97612
2025-01-17 10:29:31.380153 Epoch 5, Train Y Loss = 3.08429,  Train X Loss = 2.16962, Val Loss = 2.89306
2025-01-17 10:31:16.751374 Epoch 6, Train Y Loss = 3.04533,  Train X Loss = 2.05359, Val Loss = 2.86943
2025-01-17 10:33:01.646895 Epoch 7, Train Y Loss = 2.99318,  Train X Loss = 1.97802, Val Loss = 2.87123
2025-01-17 10:34:36.047623 Epoch 8, Train Y Loss = 2.96731,  Train X Loss = 1.95390, Val Loss = 2.87319
2025-01-17 10:36:22.064918 Epoch 9, Train Y Loss = 2.94474,  Train X Loss = 1.94171, Val Loss = 2.80060
2025-01-17 10:38:02.585365 Epoch 10, Train Y Loss = 2.92988,  Train X Loss = 1.93179, Val Loss = 2.78456
2025-01-17 10:39:40.616017 Epoch 11, Train Y Loss = 2.91514,  Train X Loss = 1.92133, Val Loss = 2.78430
2025-01-17 10:41:14.011390 Epoch 12, Train Y Loss = 2.90548,  Train X Loss = 1.91351, Val Loss = 2.76532
2025-01-17 10:42:58.775951 Epoch 13, Train Y Loss = 2.89369,  Train X Loss = 1.90494, Val Loss = 2.75230
2025-01-17 10:44:31.408203 Epoch 14, Train Y Loss = 2.88822,  Train X Loss = 1.90331, Val Loss = 2.73913
2025-01-17 10:46:16.934307 Epoch 15, Train Y Loss = 2.88079,  Train X Loss = 1.89728, Val Loss = 2.75960
2025-01-17 10:48:03.364908 Epoch 16, Train Y Loss = 2.87353,  Train X Loss = 1.89247, Val Loss = 2.77963
2025-01-17 10:49:39.508678 Epoch 17, Train Y Loss = 2.86633,  Train X Loss = 1.88826, Val Loss = 2.74580
2025-01-17 10:51:25.791905 Epoch 18, Train Y Loss = 2.85871,  Train X Loss = 1.88230, Val Loss = 2.75385
2025-01-17 10:53:06.365538 Epoch 19, Train Y Loss = 2.85341,  Train X Loss = 1.88200, Val Loss = 2.75919
2025-01-17 10:54:45.217505 Epoch 20, Train Y Loss = 2.85099,  Train X Loss = 1.87830, Val Loss = 2.74034
2025-01-17 10:56:31.368121 Epoch 21, Train Y Loss = 2.84441,  Train X Loss = 1.87297, Val Loss = 2.73579
2025-01-17 10:58:08.798588 Epoch 22, Train Y Loss = 2.83976,  Train X Loss = 1.87150, Val Loss = 2.73999
2025-01-17 10:59:52.450235 Epoch 23, Train Y Loss = 2.83615,  Train X Loss = 1.87081, Val Loss = 2.74477
2025-01-17 11:01:37.807248 Epoch 24, Train Y Loss = 2.83176,  Train X Loss = 1.86652, Val Loss = 2.71008
2025-01-17 11:03:12.226086 Epoch 25, Train Y Loss = 2.82739,  Train X Loss = 1.86635, Val Loss = 2.71815
2025-01-17 11:04:55.416801 Epoch 26, Train Y Loss = 2.74918,  Train X Loss = 1.82699, Val Loss = 2.67264
2025-01-17 11:06:39.582682 Epoch 27, Train Y Loss = 2.73850,  Train X Loss = 1.82031, Val Loss = 2.67037
2025-01-17 11:08:11.008999 Epoch 28, Train Y Loss = 2.73289,  Train X Loss = 1.81863, Val Loss = 2.67029
2025-01-17 11:09:44.728116 Epoch 29, Train Y Loss = 2.72812,  Train X Loss = 1.81668, Val Loss = 2.66491
2025-01-17 11:11:29.708800 Epoch 30, Train Y Loss = 2.72631,  Train X Loss = 1.81454, Val Loss = 2.67046
2025-01-17 11:13:14.542345 Epoch 31, Train Y Loss = 2.72226,  Train X Loss = 1.81499, Val Loss = 2.66726
2025-01-17 11:14:47.921524 Epoch 32, Train Y Loss = 2.72012,  Train X Loss = 1.81283, Val Loss = 2.66971
2025-01-17 11:16:32.508958 Epoch 33, Train Y Loss = 2.71814,  Train X Loss = 1.81291, Val Loss = 2.67308
2025-01-17 11:18:18.639236 Epoch 34, Train Y Loss = 2.71664,  Train X Loss = 1.81135, Val Loss = 2.66672
2025-01-17 11:19:52.585732 Epoch 35, Train Y Loss = 2.71463,  Train X Loss = 1.81184, Val Loss = 2.67152
2025-01-17 11:21:36.483561 Epoch 36, Train Y Loss = 2.70286,  Train X Loss = 1.80750, Val Loss = 2.66123
2025-01-17 11:23:21.722144 Epoch 37, Train Y Loss = 2.70031,  Train X Loss = 1.80668, Val Loss = 2.66310
2025-01-17 11:24:56.675696 Epoch 38, Train Y Loss = 2.70085,  Train X Loss = 1.80661, Val Loss = 2.66111
2025-01-17 11:26:39.799738 Epoch 39, Train Y Loss = 2.70075,  Train X Loss = 1.80569, Val Loss = 2.66181
2025-01-17 11:28:25.665575 Epoch 40, Train Y Loss = 2.69949,  Train X Loss = 1.80620, Val Loss = 2.66269
2025-01-17 11:29:59.977061 Epoch 41, Train Y Loss = 2.69854,  Train X Loss = 1.80467, Val Loss = 2.66037
2025-01-17 11:31:45.785683 Epoch 42, Train Y Loss = 2.69807,  Train X Loss = 1.80568, Val Loss = 2.66022
2025-01-17 11:33:31.481777 Epoch 43, Train Y Loss = 2.69863,  Train X Loss = 1.80538, Val Loss = 2.65974
2025-01-17 11:35:02.994176 Epoch 44, Train Y Loss = 2.69780,  Train X Loss = 1.80431, Val Loss = 2.66016
2025-01-17 11:36:35.234619 Epoch 45, Train Y Loss = 2.69695,  Train X Loss = 1.80550, Val Loss = 2.66055
2025-01-17 11:38:21.491604 Epoch 46, Train Y Loss = 2.69662,  Train X Loss = 1.80416, Val Loss = 2.66066
2025-01-17 11:40:06.316120 Epoch 47, Train Y Loss = 2.69664,  Train X Loss = 1.80607, Val Loss = 2.65891
2025-01-17 11:41:40.393231 Epoch 48, Train Y Loss = 2.69718,  Train X Loss = 1.80562, Val Loss = 2.66002
2025-01-17 11:43:26.575682 Epoch 49, Train Y Loss = 2.69583,  Train X Loss = 1.80561, Val Loss = 2.66126
2025-01-17 11:45:11.673496 Epoch 50, Train Y Loss = 2.69537,  Train X Loss = 1.80240, Val Loss = 2.66096
2025-01-17 11:46:46.206616 Epoch 51, Train Y Loss = 2.69522,  Train X Loss = 1.80412, Val Loss = 2.65809
2025-01-17 11:48:31.460522 Epoch 52, Train Y Loss = 2.69511,  Train X Loss = 1.80572, Val Loss = 2.66080
2025-01-17 11:50:16.958851 Epoch 53, Train Y Loss = 2.69529,  Train X Loss = 1.80426, Val Loss = 2.66091
2025-01-17 11:51:51.916571 Epoch 54, Train Y Loss = 2.69486,  Train X Loss = 1.80307, Val Loss = 2.65821
2025-01-17 11:53:37.761259 Epoch 55, Train Y Loss = 2.69487,  Train X Loss = 1.80354, Val Loss = 2.65851
2025-01-17 11:55:22.999138 Epoch 56, Train Y Loss = 2.69504,  Train X Loss = 1.80452, Val Loss = 2.66013
2025-01-17 11:56:57.114071 Epoch 57, Train Y Loss = 2.69384,  Train X Loss = 1.80521, Val Loss = 2.65784
2025-01-17 11:58:42.175054 Epoch 58, Train Y Loss = 2.69414,  Train X Loss = 1.80277, Val Loss = 2.66118
2025-01-17 12:00:27.320707 Epoch 59, Train Y Loss = 2.69311,  Train X Loss = 1.80411, Val Loss = 2.66065
2025-01-17 12:02:00.644844 Epoch 60, Train Y Loss = 2.69316,  Train X Loss = 1.80253, Val Loss = 2.65869
2025-01-17 12:03:33.413573 Epoch 61, Train Y Loss = 2.69378,  Train X Loss = 1.80467, Val Loss = 2.66212
2025-01-17 12:05:18.483885 Epoch 62, Train Y Loss = 2.69170,  Train X Loss = 1.80372, Val Loss = 2.65997
2025-01-17 12:07:01.658865 Epoch 63, Train Y Loss = 2.69128,  Train X Loss = 1.80249, Val Loss = 2.66002
2025-01-17 12:08:37.099175 Epoch 64, Train Y Loss = 2.69131,  Train X Loss = 1.80164, Val Loss = 2.65877
2025-01-17 12:10:22.535786 Epoch 65, Train Y Loss = 2.69186,  Train X Loss = 1.80338, Val Loss = 2.66064
2025-01-17 12:12:06.939222 Epoch 66, Train Y Loss = 2.69022,  Train X Loss = 1.80247, Val Loss = 2.65859
2025-01-17 12:13:41.026382 Epoch 67, Train Y Loss = 2.69042,  Train X Loss = 1.80076, Val Loss = 2.66137
2025-01-17 12:15:25.940749 Epoch 68, Train Y Loss = 2.69016,  Train X Loss = 1.80214, Val Loss = 2.66055
2025-01-17 12:17:11.013575 Epoch 69, Train Y Loss = 2.69120,  Train X Loss = 1.80178, Val Loss = 2.66086
2025-01-17 12:18:43.918580 Epoch 70, Train Y Loss = 2.68971,  Train X Loss = 1.80276, Val Loss = 2.65830
2025-01-17 12:20:29.668392 Epoch 71, Train Y Loss = 2.68969,  Train X Loss = 1.80260, Val Loss = 2.65829
2025-01-17 12:22:14.629791 Epoch 72, Train Y Loss = 2.68826,  Train X Loss = 1.80340, Val Loss = 2.66065
2025-01-17 12:23:50.213664 Epoch 73, Train Y Loss = 2.68880,  Train X Loss = 1.80261, Val Loss = 2.65768
2025-01-17 12:25:35.514171 Epoch 74, Train Y Loss = 2.68743,  Train X Loss = 1.80071, Val Loss = 2.65988
2025-01-17 12:27:19.391299 Epoch 75, Train Y Loss = 2.68769,  Train X Loss = 1.80166, Val Loss = 2.66022
2025-01-17 12:28:52.064719 Epoch 76, Train Y Loss = 2.68871,  Train X Loss = 1.80299, Val Loss = 2.66051
2025-01-17 12:30:24.727614 Epoch 77, Train Y Loss = 2.68804,  Train X Loss = 1.80218, Val Loss = 2.65867
2025-01-17 12:32:09.584476 Epoch 78, Train Y Loss = 2.68797,  Train X Loss = 1.80078, Val Loss = 2.65922
2025-01-17 12:33:52.551911 Epoch 79, Train Y Loss = 2.68774,  Train X Loss = 1.80201, Val Loss = 2.65897
2025-01-17 12:35:27.023900 Epoch 80, Train Y Loss = 2.68765,  Train X Loss = 1.80408, Val Loss = 2.66024
2025-01-17 12:37:11.720935 Epoch 81, Train Y Loss = 2.68668,  Train X Loss = 1.79966, Val Loss = 2.65928
2025-01-17 12:38:55.885497 Epoch 82, Train Y Loss = 2.68534,  Train X Loss = 1.80015, Val Loss = 2.66014
2025-01-17 12:40:28.806536 Epoch 83, Train Y Loss = 2.68675,  Train X Loss = 1.79961, Val Loss = 2.65737
2025-01-17 12:42:13.469139 Epoch 84, Train Y Loss = 2.68499,  Train X Loss = 1.80122, Val Loss = 2.65954
2025-01-17 12:43:58.989786 Epoch 85, Train Y Loss = 2.68609,  Train X Loss = 1.80098, Val Loss = 2.66102
2025-01-17 12:45:33.609837 Epoch 86, Train Y Loss = 2.68503,  Train X Loss = 1.80198, Val Loss = 2.66049
2025-01-17 12:47:18.534391 Epoch 87, Train Y Loss = 2.68533,  Train X Loss = 1.80182, Val Loss = 2.65937
2025-01-17 12:49:03.980509 Epoch 88, Train Y Loss = 2.68394,  Train X Loss = 1.79891, Val Loss = 2.66006
2025-01-17 12:50:37.135946 Epoch 89, Train Y Loss = 2.68427,  Train X Loss = 1.79836, Val Loss = 2.66008
2025-01-17 12:52:22.482225 Epoch 90, Train Y Loss = 2.68407,  Train X Loss = 1.80050, Val Loss = 2.65965
2025-01-17 12:54:07.411068 Epoch 91, Train Y Loss = 2.68415,  Train X Loss = 1.80239, Val Loss = 2.65896
2025-01-17 12:55:38.669032 Epoch 92, Train Y Loss = 2.68329,  Train X Loss = 1.79980, Val Loss = 2.65696
2025-01-17 12:57:11.156328 Epoch 93, Train Y Loss = 2.68369,  Train X Loss = 1.79969, Val Loss = 2.65807
2025-01-17 12:58:55.231725 Epoch 94, Train Y Loss = 2.68265,  Train X Loss = 1.79867, Val Loss = 2.65950
2025-01-17 13:00:37.185943 Epoch 95, Train Y Loss = 2.68299,  Train X Loss = 1.79971, Val Loss = 2.66055
2025-01-17 13:02:11.882280 Epoch 96, Train Y Loss = 2.68218,  Train X Loss = 1.79995, Val Loss = 2.65941
2025-01-17 13:03:56.966749 Epoch 97, Train Y Loss = 2.68128,  Train X Loss = 1.79933, Val Loss = 2.65814
2025-01-17 13:05:42.577503 Epoch 98, Train Y Loss = 2.68059,  Train X Loss = 1.79949, Val Loss = 2.65809
2025-01-17 13:07:15.979198 Epoch 99, Train Y Loss = 2.68111,  Train X Loss = 1.79871, Val Loss = 2.65975
2025-01-17 13:09:00.986575 Epoch 100, Train Y Loss = 2.68097,  Train X Loss = 1.80007, Val Loss = 2.65917
Early stopping at epoch: 100
Best at epoch 92:
Train Loss = 2.68329
Train RMSE = 5.29547, MAE = 2.63582, MAPE = 6.89413
Val Loss = 2.65696
Val RMSE = 5.59587, MAE = 2.70987, MAPE = 7.36396
--------- Test ---------
All Steps RMSE = 5.92985, MAE = 2.91038, MAPE = 7.93981
Step 1 RMSE = 3.71120, MAE = 2.13924, MAPE = 5.03841
Step 2 RMSE = 4.50318, MAE = 2.44055, MAPE = 6.04850
Step 3 RMSE = 5.02073, MAE = 2.62454, MAPE = 6.72655
Step 4 RMSE = 5.41052, MAE = 2.76042, MAPE = 7.27344
Step 5 RMSE = 5.72589, MAE = 2.86811, MAPE = 7.72554
Step 6 RMSE = 5.99307, MAE = 2.95870, MAPE = 8.10676
Step 7 RMSE = 6.22178, MAE = 3.03688, MAPE = 8.42934
Step 8 RMSE = 6.41548, MAE = 3.10478, MAPE = 8.71200
Step 9 RMSE = 6.58500, MAE = 3.16719, MAPE = 8.97193
Step 10 RMSE = 6.73535, MAE = 3.22334, MAPE = 9.20397
Step 11 RMSE = 6.86913, MAE = 3.27409, MAPE = 9.41577
Step 12 RMSE = 6.99593, MAE = 3.32677, MAPE = 9.62568
Inference time: 7.42 s
