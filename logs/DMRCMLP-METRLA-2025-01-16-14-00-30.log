METRLA
--------- DMRCMLP ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        25,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": true,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 51970489,
    "gpu": [
        0
    ],
    "save": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        283,260
├─Linear: 1-1                                 [16, 12, 207, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 207, 48]         --
│    └─Embedding: 2-1                         [16, 12, 207, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 207, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 207, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 207, 144]        158,224
├─Predictor: 1-4                              [16, 12, 207, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 207, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 207, 144]        41,760
│    └─Linear: 2-6                            [16, 207, 12]             20,748
===============================================================================================
Total params: 1,027,552
Trainable params: 1,027,552
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.48
Forward/backward pass size (MB): 1813.92
Params size (MB): 2.98
Estimated Total Size (MB): 1817.37
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-METRLA-2025-01-16-14-00-30.pt
2025-01-16 14:02:06.100481 Epoch 1, Train Y Loss = 4.12071,  Train X Loss = 2.64824, Val Loss = 3.32680
2025-01-16 14:03:50.513423 Epoch 2, Train Y Loss = 3.42536,  Train X Loss = 2.26357, Val Loss = 3.13732
2025-01-16 14:05:35.794276 Epoch 3, Train Y Loss = 3.25867,  Train X Loss = 2.22089, Val Loss = 2.95512
2025-01-16 14:07:09.139981 Epoch 4, Train Y Loss = 3.14872,  Train X Loss = 2.19202, Val Loss = 2.93973
2025-01-16 14:08:54.409089 Epoch 5, Train Y Loss = 3.09162,  Train X Loss = 2.09331, Val Loss = 2.93160
2025-01-16 14:10:28.438039 Epoch 6, Train Y Loss = 3.03759,  Train X Loss = 2.00015, Val Loss = 2.86441
2025-01-16 14:12:04.412828 Epoch 7, Train Y Loss = 2.99537,  Train X Loss = 1.96704, Val Loss = 2.81179
2025-01-16 14:13:48.091346 Epoch 8, Train Y Loss = 2.96779,  Train X Loss = 1.94884, Val Loss = 2.82639
2025-01-16 14:15:34.098047 Epoch 9, Train Y Loss = 2.94415,  Train X Loss = 1.93522, Val Loss = 2.80348
2025-01-16 14:17:08.425785 Epoch 10, Train Y Loss = 2.92599,  Train X Loss = 1.92232, Val Loss = 2.77010
2025-01-16 14:18:55.053814 Epoch 11, Train Y Loss = 2.91196,  Train X Loss = 1.91533, Val Loss = 2.78295
2025-01-16 14:20:40.383712 Epoch 12, Train Y Loss = 2.89736,  Train X Loss = 1.90844, Val Loss = 2.74618
2025-01-16 14:22:15.853516 Epoch 13, Train Y Loss = 2.88902,  Train X Loss = 1.90416, Val Loss = 2.75772
2025-01-16 14:24:01.720302 Epoch 14, Train Y Loss = 2.87953,  Train X Loss = 1.89597, Val Loss = 2.73823
2025-01-16 14:25:40.552171 Epoch 15, Train Y Loss = 2.87220,  Train X Loss = 1.89311, Val Loss = 2.76560
2025-01-16 14:27:20.958092 Epoch 16, Train Y Loss = 2.86620,  Train X Loss = 1.88860, Val Loss = 2.72082
2025-01-16 14:29:05.980143 Epoch 17, Train Y Loss = 2.85988,  Train X Loss = 1.88446, Val Loss = 2.75556
2025-01-16 14:30:39.658494 Epoch 18, Train Y Loss = 2.85142,  Train X Loss = 1.87770, Val Loss = 2.73668
2025-01-16 14:32:24.850833 Epoch 19, Train Y Loss = 2.84835,  Train X Loss = 1.87718, Val Loss = 2.73276
2025-01-16 14:34:10.902242 Epoch 20, Train Y Loss = 2.84147,  Train X Loss = 1.87290, Val Loss = 2.72371
2025-01-16 14:35:43.570284 Epoch 21, Train Y Loss = 2.83759,  Train X Loss = 1.87073, Val Loss = 2.73554
2025-01-16 14:37:29.093648 Epoch 22, Train Y Loss = 2.83190,  Train X Loss = 1.86477, Val Loss = 2.73649
2025-01-16 14:39:01.485973 Epoch 23, Train Y Loss = 2.82695,  Train X Loss = 1.86472, Val Loss = 2.75946
2025-01-16 14:40:36.718136 Epoch 24, Train Y Loss = 2.82633,  Train X Loss = 1.86241, Val Loss = 2.73322
Change mask ratio: 0.075
2025-01-16 14:42:20.461431 Epoch 25, Train Y Loss = 2.81160,  Train X Loss = 0.91912, Val Loss = 2.72661
2025-01-16 14:44:05.908811 Epoch 26, Train Y Loss = 2.72875,  Train X Loss = 0.90036, Val Loss = 2.65542
2025-01-16 14:45:37.758268 Epoch 27, Train Y Loss = 2.71457,  Train X Loss = 0.89757, Val Loss = 2.66294
2025-01-16 14:47:22.938775 Epoch 28, Train Y Loss = 2.70821,  Train X Loss = 0.89734, Val Loss = 2.65768
2025-01-16 14:49:04.917373 Epoch 29, Train Y Loss = 2.70374,  Train X Loss = 0.89675, Val Loss = 2.65165
2025-01-16 14:50:40.718501 Epoch 30, Train Y Loss = 2.69985,  Train X Loss = 0.89622, Val Loss = 2.66032
2025-01-16 14:52:25.375488 Epoch 31, Train Y Loss = 2.69574,  Train X Loss = 0.89472, Val Loss = 2.65980
2025-01-16 14:53:59.088525 Epoch 32, Train Y Loss = 2.69430,  Train X Loss = 0.89488, Val Loss = 2.66146
2025-01-16 14:55:43.236672 Epoch 33, Train Y Loss = 2.68991,  Train X Loss = 0.89539, Val Loss = 2.66178
2025-01-16 14:57:28.374450 Epoch 34, Train Y Loss = 2.68856,  Train X Loss = 0.89580, Val Loss = 2.65346
2025-01-16 14:59:01.459788 Epoch 35, Train Y Loss = 2.68515,  Train X Loss = 0.89533, Val Loss = 2.65364
2025-01-16 15:00:45.995602 Epoch 36, Train Y Loss = 2.67234,  Train X Loss = 0.89345, Val Loss = 2.65207
2025-01-16 15:02:26.125606 Epoch 37, Train Y Loss = 2.67043,  Train X Loss = 0.89355, Val Loss = 2.65260
Change mask ratio: 0.0375
2025-01-16 15:04:02.583864 Epoch 38, Train Y Loss = 2.66109,  Train X Loss = 0.44041, Val Loss = 2.65025
2025-01-16 15:05:46.842923 Epoch 39, Train Y Loss = 2.66049,  Train X Loss = 0.44154, Val Loss = 2.65100
2025-01-16 15:07:17.904633 Epoch 40, Train Y Loss = 2.65907,  Train X Loss = 0.44059, Val Loss = 2.65424
2025-01-16 15:08:49.107017 Epoch 41, Train Y Loss = 2.65949,  Train X Loss = 0.44154, Val Loss = 2.65100
2025-01-16 15:10:33.982289 Epoch 42, Train Y Loss = 2.65870,  Train X Loss = 0.44277, Val Loss = 2.65090
2025-01-16 15:12:13.644387 Epoch 43, Train Y Loss = 2.65709,  Train X Loss = 0.44141, Val Loss = 2.65259
2025-01-16 15:13:47.971601 Epoch 44, Train Y Loss = 2.65715,  Train X Loss = 0.44168, Val Loss = 2.65266
2025-01-16 15:15:31.984734 Epoch 45, Train Y Loss = 2.65774,  Train X Loss = 0.44183, Val Loss = 2.65016
2025-01-16 15:17:05.911368 Epoch 46, Train Y Loss = 2.65596,  Train X Loss = 0.44204, Val Loss = 2.65162
2025-01-16 15:18:47.715453 Epoch 47, Train Y Loss = 2.65528,  Train X Loss = 0.44210, Val Loss = 2.65187
2025-01-16 15:20:31.637454 Epoch 48, Train Y Loss = 2.65520,  Train X Loss = 0.44327, Val Loss = 2.65137
2025-01-16 15:22:03.043103 Epoch 49, Train Y Loss = 2.65394,  Train X Loss = 0.44291, Val Loss = 2.65308
2025-01-16 15:23:48.034967 Epoch 50, Train Y Loss = 2.65517,  Train X Loss = 0.44291, Val Loss = 2.65315
2025-01-16 15:25:30.716795 Epoch 51, Train Y Loss = 2.65324,  Train X Loss = 0.44265, Val Loss = 2.65203
2025-01-16 15:27:03.102241 Epoch 52, Train Y Loss = 2.65329,  Train X Loss = 0.44290, Val Loss = 2.65077
2025-01-16 15:28:46.841943 Epoch 53, Train Y Loss = 2.65235,  Train X Loss = 0.44272, Val Loss = 2.65154
Change mask ratio: 0.0
2025-01-16 15:30:08.170682 Epoch 54, Train Y Loss = 2.64372,  Train X Loss = 0.00000, Val Loss = 2.65196
2025-01-16 15:31:47.112538 Epoch 55, Train Y Loss = 2.64249,  Train X Loss = 0.00000, Val Loss = 2.65234
2025-01-16 15:33:08.106606 Epoch 56, Train Y Loss = 2.64135,  Train X Loss = 0.00000, Val Loss = 2.65183
2025-01-16 15:34:47.678908 Epoch 57, Train Y Loss = 2.64070,  Train X Loss = 0.00000, Val Loss = 2.65064
2025-01-16 15:36:09.778936 Epoch 58, Train Y Loss = 2.64013,  Train X Loss = 0.00000, Val Loss = 2.65042
2025-01-16 15:37:31.521411 Epoch 59, Train Y Loss = 2.63909,  Train X Loss = 0.00000, Val Loss = 2.65051
2025-01-16 15:39:08.430650 Epoch 60, Train Y Loss = 2.63795,  Train X Loss = 0.00000, Val Loss = 2.65328
2025-01-16 15:40:33.571088 Epoch 61, Train Y Loss = 2.63798,  Train X Loss = 0.00000, Val Loss = 2.65272
Change mask ratio: 0.0
2025-01-16 15:42:07.247694 Epoch 62, Train Y Loss = 2.63668,  Train X Loss = 0.00000, Val Loss = 2.65222
2025-01-16 15:43:34.206934 Epoch 63, Train Y Loss = 2.63685,  Train X Loss = 0.00000, Val Loss = 2.65115
2025-01-16 15:45:06.364573 Epoch 64, Train Y Loss = 2.63532,  Train X Loss = 0.00000, Val Loss = 2.65289
2025-01-16 15:46:34.107879 Epoch 65, Train Y Loss = 2.63516,  Train X Loss = 0.00000, Val Loss = 2.65181
2025-01-16 15:48:04.574060 Epoch 66, Train Y Loss = 2.63451,  Train X Loss = 0.00000, Val Loss = 2.65227
2025-01-16 15:49:33.778293 Epoch 67, Train Y Loss = 2.63303,  Train X Loss = 0.00000, Val Loss = 2.65298
2025-01-16 15:51:03.245136 Epoch 68, Train Y Loss = 2.63267,  Train X Loss = 0.00000, Val Loss = 2.65348
2025-01-16 15:52:35.226521 Epoch 69, Train Y Loss = 2.63197,  Train X Loss = 0.00000, Val Loss = 2.65156
Change mask ratio: 0.0
2025-01-16 15:54:02.054623 Epoch 70, Train Y Loss = 2.63118,  Train X Loss = 0.00000, Val Loss = 2.65247
2025-01-16 15:55:35.444293 Epoch 71, Train Y Loss = 2.63112,  Train X Loss = 0.00000, Val Loss = 2.65212
2025-01-16 15:57:01.190708 Epoch 72, Train Y Loss = 2.63025,  Train X Loss = 0.00000, Val Loss = 2.65281
2025-01-16 15:58:36.543506 Epoch 73, Train Y Loss = 2.62908,  Train X Loss = 0.00000, Val Loss = 2.65443
2025-01-16 16:00:00.155275 Epoch 74, Train Y Loss = 2.62824,  Train X Loss = 0.00000, Val Loss = 2.65390
2025-01-16 16:01:36.914767 Epoch 75, Train Y Loss = 2.62822,  Train X Loss = 0.00000, Val Loss = 2.65571
Early stopping at epoch: 75
Best at epoch 45:
Train Loss = 2.65774
Train RMSE = 5.24296, MAE = 2.61680, MAPE = 6.83543
Val Loss = 2.65016
Val RMSE = 5.58115, MAE = 2.70050, MAPE = 7.36531
--------- Test ---------
All Steps RMSE = 5.88376, MAE = 2.89306, MAPE = 7.85192
Step 1 RMSE = 3.70708, MAE = 2.14490, MAPE = 5.02989
Step 2 RMSE = 4.46535, MAE = 2.42550, MAPE = 5.98143
Step 3 RMSE = 4.97145, MAE = 2.60467, MAPE = 6.64356
Step 4 RMSE = 5.35488, MAE = 2.73667, MAPE = 7.15815
Step 5 RMSE = 5.66684, MAE = 2.84473, MAPE = 7.60289
Step 6 RMSE = 5.93624, MAE = 2.93512, MAPE = 7.97078
Step 7 RMSE = 6.16770, MAE = 3.01430, MAPE = 8.29988
Step 8 RMSE = 6.36387, MAE = 3.08489, MAPE = 8.60727
Step 9 RMSE = 6.53521, MAE = 3.14964, MAPE = 8.88287
Step 10 RMSE = 6.68982, MAE = 3.20628, MAPE = 9.12627
Step 11 RMSE = 6.82611, MAE = 3.25752, MAPE = 9.34819
Step 12 RMSE = 6.95726, MAE = 3.31251, MAPE = 9.57210
Inference time: 7.39 s
