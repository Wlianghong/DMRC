PEMS03
--------- DMRCMLP ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        50
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        3
    ],
    "save": false,
    "model_args": {
        "num_nodes": 358,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        434,604
├─Linear: 1-1                                 [16, 12, 358, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 358, 48]         --
│    └─Embedding: 2-1                         [16, 12, 358, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 358, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 358, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 358, 144]        158,224
├─Predictor: 1-4                              [16, 12, 358, 1]          --
│    └─Linear: 2-5                            [16, 12, 358, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 358, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 358, 144]        41,760
│    └─Linear: 2-7                            [16, 358, 12]             20,748
===============================================================================================
Total params: 1,199,776
Trainable params: 1,199,776
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.82
Forward/backward pass size (MB): 3216.29
Params size (MB): 3.06
Estimated Total Size (MB): 3220.18
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS03-2025-01-17-16-43-21.pt
2025-01-17 16:45:37.324699 Epoch 1, Train Y Loss = 21.58378,  Train X Loss = 16.44038, Val Loss = 17.02898
2025-01-17 16:47:52.174216 Epoch 2, Train Y Loss = 16.88283,  Train X Loss = 13.06357, Val Loss = 17.02174
2025-01-17 16:50:07.039752 Epoch 3, Train Y Loss = 15.66986,  Train X Loss = 12.60802, Val Loss = 14.97939
2025-01-17 16:52:21.866488 Epoch 4, Train Y Loss = 15.06730,  Train X Loss = 11.22178, Val Loss = 15.29309
2025-01-17 16:54:36.989028 Epoch 5, Train Y Loss = 14.72379,  Train X Loss = 9.38471, Val Loss = 14.48290
2025-01-17 16:56:52.286549 Epoch 6, Train Y Loss = 14.26136,  Train X Loss = 8.85281, Val Loss = 14.18554
2025-01-17 16:59:07.403067 Epoch 7, Train Y Loss = 14.09767,  Train X Loss = 8.65140, Val Loss = 14.27498
2025-01-17 17:01:22.240140 Epoch 8, Train Y Loss = 13.79893,  Train X Loss = 8.43675, Val Loss = 13.94774
2025-01-17 17:03:35.759666 Epoch 9, Train Y Loss = 13.74913,  Train X Loss = 8.30018, Val Loss = 14.24477
2025-01-17 17:05:51.643070 Epoch 10, Train Y Loss = 13.49291,  Train X Loss = 8.20130, Val Loss = 13.78064
2025-01-17 17:08:09.264625 Epoch 11, Train Y Loss = 13.33341,  Train X Loss = 8.05593, Val Loss = 13.85872
2025-01-17 17:10:26.424083 Epoch 12, Train Y Loss = 13.24175,  Train X Loss = 8.03937, Val Loss = 13.35818
2025-01-17 17:12:43.702897 Epoch 13, Train Y Loss = 13.16188,  Train X Loss = 7.91593, Val Loss = 13.49461
2025-01-17 17:15:01.162646 Epoch 14, Train Y Loss = 13.05608,  Train X Loss = 7.89303, Val Loss = 13.32318
2025-01-17 17:17:18.938428 Epoch 15, Train Y Loss = 13.01720,  Train X Loss = 7.87036, Val Loss = 13.51231
2025-01-17 17:19:35.765132 Epoch 16, Train Y Loss = 12.91548,  Train X Loss = 7.80078, Val Loss = 13.61801
2025-01-17 17:21:53.926952 Epoch 17, Train Y Loss = 12.87205,  Train X Loss = 7.75236, Val Loss = 13.64695
2025-01-17 17:24:11.828864 Epoch 18, Train Y Loss = 12.81892,  Train X Loss = 7.71862, Val Loss = 13.28981
2025-01-17 17:26:28.993976 Epoch 19, Train Y Loss = 12.77095,  Train X Loss = 7.70844, Val Loss = 13.40221
2025-01-17 17:28:45.996567 Epoch 20, Train Y Loss = 12.72569,  Train X Loss = 7.67492, Val Loss = 13.23859
2025-01-17 17:31:02.563392 Epoch 21, Train Y Loss = 12.18841,  Train X Loss = 7.37939, Val Loss = 12.87736
2025-01-17 17:33:20.533497 Epoch 22, Train Y Loss = 12.12502,  Train X Loss = 7.34323, Val Loss = 12.89740
2025-01-17 17:35:37.246278 Epoch 23, Train Y Loss = 12.10283,  Train X Loss = 7.32817, Val Loss = 12.94990
2025-01-17 17:37:54.307885 Epoch 24, Train Y Loss = 12.08402,  Train X Loss = 7.31803, Val Loss = 12.85949
2025-01-17 17:40:11.884362 Epoch 25, Train Y Loss = 12.06806,  Train X Loss = 7.30931, Val Loss = 12.87710
2025-01-17 17:42:28.641035 Epoch 26, Train Y Loss = 12.05210,  Train X Loss = 7.30173, Val Loss = 12.88190
2025-01-17 17:44:45.858195 Epoch 27, Train Y Loss = 12.04281,  Train X Loss = 7.29552, Val Loss = 12.82634
2025-01-17 17:47:03.798847 Epoch 28, Train Y Loss = 12.02882,  Train X Loss = 7.29006, Val Loss = 12.86717
2025-01-17 17:49:20.945040 Epoch 29, Train Y Loss = 12.01986,  Train X Loss = 7.27838, Val Loss = 12.86489
2025-01-17 17:51:37.916799 Epoch 30, Train Y Loss = 12.00812,  Train X Loss = 7.27543, Val Loss = 12.84644
2025-01-17 17:53:55.899479 Epoch 31, Train Y Loss = 11.99952,  Train X Loss = 7.27062, Val Loss = 12.86167
2025-01-17 17:56:12.820628 Epoch 32, Train Y Loss = 11.99002,  Train X Loss = 7.27065, Val Loss = 12.83268
2025-01-17 17:58:30.993578 Epoch 33, Train Y Loss = 11.98276,  Train X Loss = 7.26755, Val Loss = 12.82375
2025-01-17 18:00:49.771557 Epoch 34, Train Y Loss = 11.97381,  Train X Loss = 7.25337, Val Loss = 12.86123
2025-01-17 18:03:08.058256 Epoch 35, Train Y Loss = 11.96502,  Train X Loss = 7.25277, Val Loss = 12.91113
2025-01-17 18:05:26.500592 Epoch 36, Train Y Loss = 11.89685,  Train X Loss = 7.22482, Val Loss = 12.80928
2025-01-17 18:07:44.516017 Epoch 37, Train Y Loss = 11.88897,  Train X Loss = 7.21485, Val Loss = 12.81240
2025-01-17 18:10:02.472119 Epoch 38, Train Y Loss = 11.88783,  Train X Loss = 7.21594, Val Loss = 12.79988
2025-01-17 18:12:20.083115 Epoch 39, Train Y Loss = 11.88561,  Train X Loss = 7.21571, Val Loss = 12.80721
2025-01-17 18:14:37.239340 Epoch 40, Train Y Loss = 11.88388,  Train X Loss = 7.21067, Val Loss = 12.82600
2025-01-17 18:16:55.630397 Epoch 41, Train Y Loss = 11.88100,  Train X Loss = 7.20956, Val Loss = 12.80276
2025-01-17 18:19:13.680176 Epoch 42, Train Y Loss = 11.88048,  Train X Loss = 7.20984, Val Loss = 12.81544
2025-01-17 18:21:31.718941 Epoch 43, Train Y Loss = 11.87814,  Train X Loss = 7.20885, Val Loss = 12.81806
2025-01-17 18:23:50.139688 Epoch 44, Train Y Loss = 11.87747,  Train X Loss = 7.21154, Val Loss = 12.81490
2025-01-17 18:26:08.638900 Epoch 45, Train Y Loss = 11.87579,  Train X Loss = 7.21015, Val Loss = 12.79835
2025-01-17 18:28:26.367531 Epoch 46, Train Y Loss = 11.87427,  Train X Loss = 7.20795, Val Loss = 12.81097
2025-01-17 18:30:44.732622 Epoch 47, Train Y Loss = 11.87467,  Train X Loss = 7.20559, Val Loss = 12.82013
2025-01-17 18:33:03.371613 Epoch 48, Train Y Loss = 11.87196,  Train X Loss = 7.20879, Val Loss = 12.81311
2025-01-17 18:35:21.839378 Epoch 49, Train Y Loss = 11.87117,  Train X Loss = 7.20476, Val Loss = 12.80594
2025-01-17 18:37:40.193955 Epoch 50, Train Y Loss = 11.87138,  Train X Loss = 7.20810, Val Loss = 12.78983
2025-01-17 18:39:57.297447 Epoch 51, Train Y Loss = 11.86196,  Train X Loss = 7.20240, Val Loss = 12.80445
2025-01-17 18:42:15.440540 Epoch 52, Train Y Loss = 11.86143,  Train X Loss = 7.20247, Val Loss = 12.81616
2025-01-17 18:44:33.374250 Epoch 53, Train Y Loss = 11.85982,  Train X Loss = 7.20138, Val Loss = 12.80574
2025-01-17 18:46:51.426911 Epoch 54, Train Y Loss = 11.85939,  Train X Loss = 7.20117, Val Loss = 12.81200
2025-01-17 18:49:08.529776 Epoch 55, Train Y Loss = 11.86072,  Train X Loss = 7.20000, Val Loss = 12.80623
2025-01-17 18:51:25.834964 Epoch 56, Train Y Loss = 11.85969,  Train X Loss = 7.19952, Val Loss = 12.80632
2025-01-17 18:53:43.020670 Epoch 57, Train Y Loss = 11.85921,  Train X Loss = 7.19725, Val Loss = 12.80736
2025-01-17 18:55:59.808072 Epoch 58, Train Y Loss = 11.86041,  Train X Loss = 7.20423, Val Loss = 12.81445
2025-01-17 18:58:17.538391 Epoch 59, Train Y Loss = 11.86045,  Train X Loss = 7.20333, Val Loss = 12.80757
2025-01-17 19:00:36.304560 Epoch 60, Train Y Loss = 11.86017,  Train X Loss = 7.19858, Val Loss = 12.80714
2025-01-17 19:02:54.628569 Epoch 61, Train Y Loss = 11.85937,  Train X Loss = 7.19655, Val Loss = 12.81569
2025-01-17 19:05:12.609941 Epoch 62, Train Y Loss = 11.85949,  Train X Loss = 7.20180, Val Loss = 12.81672
2025-01-17 19:07:30.341625 Epoch 63, Train Y Loss = 11.85875,  Train X Loss = 7.20358, Val Loss = 12.81164
2025-01-17 19:09:48.198268 Epoch 64, Train Y Loss = 11.85885,  Train X Loss = 7.19886, Val Loss = 12.80987
2025-01-17 19:12:05.982954 Epoch 65, Train Y Loss = 11.85968,  Train X Loss = 7.19891, Val Loss = 12.81196
2025-01-17 19:14:24.160233 Epoch 66, Train Y Loss = 11.85918,  Train X Loss = 7.19896, Val Loss = 12.80473
2025-01-17 19:16:41.683972 Epoch 67, Train Y Loss = 11.85863,  Train X Loss = 7.19577, Val Loss = 12.80885
2025-01-17 19:18:59.732650 Epoch 68, Train Y Loss = 11.85857,  Train X Loss = 7.20185, Val Loss = 12.81143
2025-01-17 19:21:17.005959 Epoch 69, Train Y Loss = 11.85832,  Train X Loss = 7.19690, Val Loss = 12.81164
2025-01-17 19:23:34.108478 Epoch 70, Train Y Loss = 11.85966,  Train X Loss = 7.19982, Val Loss = 12.81145
Early stopping at epoch: 70
Best at epoch 50:
Train Loss = 11.87138
Train RMSE = 20.28084, MAE = 12.27653, MAPE = 11.36704
Val Loss = 12.78983
Val RMSE = 21.57828, MAE = 13.31419, MAPE = 12.66648
--------- Test ---------
All Steps RMSE = 25.68509, MAE = 15.01726, MAPE = 15.20548
Step 1 RMSE = 19.27172, MAE = 12.11875, MAPE = 12.75957
Step 2 RMSE = 21.37189, MAE = 13.01618, MAPE = 13.57465
Step 3 RMSE = 22.87986, MAE = 13.67277, MAPE = 14.04933
Step 4 RMSE = 24.09725, MAE = 14.21143, MAPE = 14.46638
Step 5 RMSE = 25.05114, MAE = 14.66359, MAPE = 14.83881
Step 6 RMSE = 25.83947, MAE = 15.06621, MAPE = 15.23644
Step 7 RMSE = 26.55489, MAE = 15.44597, MAPE = 15.52678
Step 8 RMSE = 27.17631, MAE = 15.79210, MAPE = 15.85110
Step 9 RMSE = 27.72166, MAE = 16.10265, MAPE = 16.09009
Step 10 RMSE = 28.24329, MAE = 16.40937, MAPE = 16.41551
Step 11 RMSE = 28.74819, MAE = 16.70699, MAPE = 16.65459
Step 12 RMSE = 29.20238, MAE = 17.00102, MAPE = 17.00227
Inference time: 11.10 s
