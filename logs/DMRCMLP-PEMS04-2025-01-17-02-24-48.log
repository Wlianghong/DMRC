PEMS04
--------- DMRCMLP ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        55
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 51970489,
    "gpu": [
        1
    ],
    "save": false,
    "model_args": {
        "num_nodes": 307,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        390,540
├─Linear: 1-1                                 [16, 12, 307, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 307, 48]         --
│    └─Embedding: 2-1                         [16, 12, 307, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 307, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 307, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 307, 144]        158,224
├─Predictor: 1-4                              [16, 12, 307, 1]          --
│    └─Linear: 2-5                            [16, 12, 307, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 307, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 307, 144]        41,760
│    └─Linear: 2-7                            [16, 307, 12]             20,748
===============================================================================================
Total params: 1,155,712
Trainable params: 1,155,712
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.71
Forward/backward pass size (MB): 2758.11
Params size (MB): 3.06
Estimated Total Size (MB): 2761.88
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS04-2025-01-17-02-24-48.pt
2025-01-17 02:26:05.276347 Epoch 1, Train Y Loss = 29.03859,  Train X Loss = 22.14181, Val Loss = 24.69605
2025-01-17 02:27:21.993439 Epoch 2, Train Y Loss = 22.75549,  Train X Loss = 17.58432, Val Loss = 22.28889
2025-01-17 02:28:38.589047 Epoch 3, Train Y Loss = 21.42731,  Train X Loss = 17.00383, Val Loss = 21.52814
2025-01-17 02:29:55.176197 Epoch 4, Train Y Loss = 20.41236,  Train X Loss = 16.58609, Val Loss = 20.15045
2025-01-17 02:31:11.637853 Epoch 5, Train Y Loss = 19.81745,  Train X Loss = 16.48659, Val Loss = 20.33236
2025-01-17 02:32:27.421868 Epoch 6, Train Y Loss = 19.41157,  Train X Loss = 16.35266, Val Loss = 19.99095
2025-01-17 02:33:43.137662 Epoch 7, Train Y Loss = 18.97375,  Train X Loss = 16.20458, Val Loss = 19.37725
2025-01-17 02:34:58.934137 Epoch 8, Train Y Loss = 18.65601,  Train X Loss = 16.01218, Val Loss = 18.97787
2025-01-17 02:36:14.652551 Epoch 9, Train Y Loss = 18.49870,  Train X Loss = 15.96162, Val Loss = 19.38176
2025-01-17 02:37:30.403329 Epoch 10, Train Y Loss = 18.30970,  Train X Loss = 15.87220, Val Loss = 19.56434
2025-01-17 02:38:46.226901 Epoch 11, Train Y Loss = 18.24473,  Train X Loss = 15.75389, Val Loss = 18.72342
2025-01-17 02:40:02.032246 Epoch 12, Train Y Loss = 17.95741,  Train X Loss = 15.62724, Val Loss = 18.86817
2025-01-17 02:41:17.840103 Epoch 13, Train Y Loss = 17.83171,  Train X Loss = 15.59935, Val Loss = 19.45634
2025-01-17 02:42:33.447195 Epoch 14, Train Y Loss = 17.82246,  Train X Loss = 15.54724, Val Loss = 19.17227
2025-01-17 02:43:49.250662 Epoch 15, Train Y Loss = 17.64890,  Train X Loss = 15.40519, Val Loss = 18.67236
2025-01-17 02:45:04.998332 Epoch 16, Train Y Loss = 17.56406,  Train X Loss = 15.37694, Val Loss = 18.73244
2025-01-17 02:46:20.806159 Epoch 17, Train Y Loss = 17.42303,  Train X Loss = 15.30418, Val Loss = 18.30275
2025-01-17 02:47:36.539604 Epoch 18, Train Y Loss = 17.44622,  Train X Loss = 15.31706, Val Loss = 18.48803
2025-01-17 02:48:52.287576 Epoch 19, Train Y Loss = 17.30988,  Train X Loss = 15.24812, Val Loss = 18.20573
2025-01-17 02:50:08.114390 Epoch 20, Train Y Loss = 17.29721,  Train X Loss = 15.22431, Val Loss = 18.64257
2025-01-17 02:51:23.860665 Epoch 21, Train Y Loss = 16.66787,  Train X Loss = 14.84396, Val Loss = 17.60787
2025-01-17 02:52:39.726334 Epoch 22, Train Y Loss = 16.56602,  Train X Loss = 14.78821, Val Loss = 17.57889
2025-01-17 02:53:55.565719 Epoch 23, Train Y Loss = 16.52989,  Train X Loss = 14.77118, Val Loss = 17.60975
2025-01-17 02:55:11.494786 Epoch 24, Train Y Loss = 16.50744,  Train X Loss = 14.72414, Val Loss = 17.69568
2025-01-17 02:56:27.314055 Epoch 25, Train Y Loss = 16.47877,  Train X Loss = 14.73010, Val Loss = 17.61532
2025-01-17 02:57:43.211359 Epoch 26, Train Y Loss = 16.45937,  Train X Loss = 14.71355, Val Loss = 17.56253
2025-01-17 02:58:59.090692 Epoch 27, Train Y Loss = 16.43647,  Train X Loss = 14.69547, Val Loss = 17.69965
2025-01-17 03:00:14.910990 Epoch 28, Train Y Loss = 16.42568,  Train X Loss = 14.70181, Val Loss = 17.67698
2025-01-17 03:01:30.789668 Epoch 29, Train Y Loss = 16.40311,  Train X Loss = 14.67599, Val Loss = 17.58374
2025-01-17 03:02:46.592765 Epoch 30, Train Y Loss = 16.38016,  Train X Loss = 14.67478, Val Loss = 17.61533
2025-01-17 03:04:02.506648 Epoch 31, Train Y Loss = 16.36246,  Train X Loss = 14.65011, Val Loss = 17.51200
2025-01-17 03:05:18.321281 Epoch 32, Train Y Loss = 16.34594,  Train X Loss = 14.63703, Val Loss = 17.61808
2025-01-17 03:06:34.181102 Epoch 33, Train Y Loss = 16.32922,  Train X Loss = 14.63645, Val Loss = 17.53954
2025-01-17 03:07:50.011891 Epoch 34, Train Y Loss = 16.30985,  Train X Loss = 14.63120, Val Loss = 17.50617
2025-01-17 03:09:05.875540 Epoch 35, Train Y Loss = 16.28668,  Train X Loss = 14.61360, Val Loss = 17.52354
2025-01-17 03:10:21.774524 Epoch 36, Train Y Loss = 16.22310,  Train X Loss = 14.59375, Val Loss = 17.47565
2025-01-17 03:11:37.557354 Epoch 37, Train Y Loss = 16.21011,  Train X Loss = 14.58099, Val Loss = 17.47796
2025-01-17 03:12:53.384586 Epoch 38, Train Y Loss = 16.20408,  Train X Loss = 14.57984, Val Loss = 17.49415
2025-01-17 03:14:09.099886 Epoch 39, Train Y Loss = 16.19953,  Train X Loss = 14.58513, Val Loss = 17.48187
2025-01-17 03:15:24.920803 Epoch 40, Train Y Loss = 16.19705,  Train X Loss = 14.58485, Val Loss = 17.50522
2025-01-17 03:16:40.634666 Epoch 41, Train Y Loss = 16.19331,  Train X Loss = 14.57615, Val Loss = 17.46854
2025-01-17 03:17:56.435372 Epoch 42, Train Y Loss = 16.18892,  Train X Loss = 14.56190, Val Loss = 17.48884
2025-01-17 03:19:12.143483 Epoch 43, Train Y Loss = 16.18642,  Train X Loss = 14.58925, Val Loss = 17.47810
2025-01-17 03:20:28.055518 Epoch 44, Train Y Loss = 16.18351,  Train X Loss = 14.58286, Val Loss = 17.49579
2025-01-17 03:21:43.977399 Epoch 45, Train Y Loss = 16.18224,  Train X Loss = 14.56718, Val Loss = 17.49240
2025-01-17 03:22:59.779054 Epoch 46, Train Y Loss = 16.18295,  Train X Loss = 14.57076, Val Loss = 17.47087
2025-01-17 03:24:15.729674 Epoch 47, Train Y Loss = 16.17720,  Train X Loss = 14.55829, Val Loss = 17.50260
2025-01-17 03:25:31.584848 Epoch 48, Train Y Loss = 16.17682,  Train X Loss = 14.56079, Val Loss = 17.48980
2025-01-17 03:26:47.523042 Epoch 49, Train Y Loss = 16.17274,  Train X Loss = 14.56366, Val Loss = 17.49407
2025-01-17 03:28:03.494012 Epoch 50, Train Y Loss = 16.17383,  Train X Loss = 14.55245, Val Loss = 17.48824
2025-01-17 03:29:19.621273 Epoch 51, Train Y Loss = 16.17113,  Train X Loss = 14.57556, Val Loss = 17.48456
2025-01-17 03:30:35.551284 Epoch 52, Train Y Loss = 16.16241,  Train X Loss = 14.56516, Val Loss = 17.47198
2025-01-17 03:31:51.406558 Epoch 53, Train Y Loss = 16.16201,  Train X Loss = 14.55041, Val Loss = 17.49399
2025-01-17 03:33:07.343561 Epoch 54, Train Y Loss = 16.16071,  Train X Loss = 14.55020, Val Loss = 17.48943
2025-01-17 03:34:23.226735 Epoch 55, Train Y Loss = 16.16148,  Train X Loss = 14.54934, Val Loss = 17.48826
2025-01-17 03:35:39.164456 Epoch 56, Train Y Loss = 16.14639,  Train X Loss = 14.55893, Val Loss = 17.48755
2025-01-17 03:36:55.030356 Epoch 57, Train Y Loss = 16.14867,  Train X Loss = 14.54323, Val Loss = 17.48564
2025-01-17 03:38:10.965525 Epoch 58, Train Y Loss = 16.14852,  Train X Loss = 14.55338, Val Loss = 17.49309
2025-01-17 03:39:26.824994 Epoch 59, Train Y Loss = 16.15096,  Train X Loss = 14.57220, Val Loss = 17.48810
2025-01-17 03:40:42.723712 Epoch 60, Train Y Loss = 16.14614,  Train X Loss = 14.54775, Val Loss = 17.49120
2025-01-17 03:41:58.631618 Epoch 61, Train Y Loss = 16.14744,  Train X Loss = 14.54719, Val Loss = 17.48840
2025-01-17 03:43:14.427516 Epoch 62, Train Y Loss = 16.14827,  Train X Loss = 14.55015, Val Loss = 17.49217
2025-01-17 03:44:30.296222 Epoch 63, Train Y Loss = 16.15008,  Train X Loss = 14.55086, Val Loss = 17.48707
2025-01-17 03:45:46.050221 Epoch 64, Train Y Loss = 16.14855,  Train X Loss = 14.55020, Val Loss = 17.49169
2025-01-17 03:47:01.876889 Epoch 65, Train Y Loss = 16.15205,  Train X Loss = 14.55053, Val Loss = 17.48944
2025-01-17 03:48:17.608993 Epoch 66, Train Y Loss = 16.14972,  Train X Loss = 14.55612, Val Loss = 17.47997
2025-01-17 03:49:33.415754 Epoch 67, Train Y Loss = 16.14560,  Train X Loss = 14.55816, Val Loss = 17.48541
2025-01-17 03:50:49.097426 Epoch 68, Train Y Loss = 16.15044,  Train X Loss = 14.54171, Val Loss = 17.48397
2025-01-17 03:52:04.857018 Epoch 69, Train Y Loss = 16.13919,  Train X Loss = 14.53119, Val Loss = 17.48742
2025-01-17 03:53:20.760169 Epoch 70, Train Y Loss = 16.14617,  Train X Loss = 14.54535, Val Loss = 17.48507
2025-01-17 03:54:36.551119 Epoch 71, Train Y Loss = 16.14651,  Train X Loss = 14.53712, Val Loss = 17.48599
Early stopping at epoch: 71
Best at epoch 41:
Train Loss = 16.19331
Train RMSE = 27.85113, MAE = 16.64597, MAPE = 11.80920
Val Loss = 17.46854
Val RMSE = 30.64051, MAE = 18.15718, MAPE = 11.70501
--------- Test ---------
All Steps RMSE = 31.01123, MAE = 18.32393, MAPE = 12.10489
Step 1 RMSE = 26.72100, MAE = 16.36282, MAPE = 10.82238
Step 2 RMSE = 28.00757, MAE = 16.96805, MAPE = 11.28073
Step 3 RMSE = 29.09714, MAE = 17.45154, MAPE = 11.60351
Step 4 RMSE = 29.97200, MAE = 17.82016, MAPE = 11.82387
Step 5 RMSE = 30.71882, MAE = 18.13030, MAPE = 11.98824
Step 6 RMSE = 31.23591, MAE = 18.36732, MAPE = 12.12168
Step 7 RMSE = 31.76833, MAE = 18.61683, MAPE = 12.27961
Step 8 RMSE = 32.14865, MAE = 18.81382, MAPE = 12.39302
Step 9 RMSE = 32.52235, MAE = 19.03410, MAPE = 12.53738
Step 10 RMSE = 32.78970, MAE = 19.21628, MAPE = 12.66348
Step 11 RMSE = 33.05157, MAE = 19.44398, MAPE = 12.80289
Step 12 RMSE = 33.30987, MAE = 19.66164, MAPE = 12.94158
Inference time: 6.01 s
