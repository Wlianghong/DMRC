METRLA
--------- DMRCMLP ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        25,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": true,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 93048409,
    "gpu": [
        0
    ],
    "save": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        283,260
├─Linear: 1-1                                 [16, 12, 207, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 207, 48]         --
│    └─Embedding: 2-1                         [16, 12, 207, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 207, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 207, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 207, 144]        158,224
├─Predictor: 1-4                              [16, 12, 207, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 207, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 207, 144]        41,760
│    └─Linear: 2-6                            [16, 207, 12]             20,748
===============================================================================================
Total params: 1,027,552
Trainable params: 1,027,552
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.48
Forward/backward pass size (MB): 1813.92
Params size (MB): 2.98
Estimated Total Size (MB): 1817.37
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-METRLA-2025-01-17-21-53-01.pt
2025-01-17 21:54:23.341591 Epoch 1, Train Y Loss = 4.11974,  Train X Loss = 0.00000, Val Loss = 3.27288
2025-01-17 21:55:45.754047 Epoch 2, Train Y Loss = 3.40804,  Train X Loss = 0.00000, Val Loss = 3.10352
2025-01-17 21:57:08.314917 Epoch 3, Train Y Loss = 3.27405,  Train X Loss = 0.00000, Val Loss = 3.05353
2025-01-17 21:58:30.811744 Epoch 4, Train Y Loss = 3.15269,  Train X Loss = 0.00000, Val Loss = 3.02953
2025-01-17 21:59:53.226413 Epoch 5, Train Y Loss = 3.08643,  Train X Loss = 0.00000, Val Loss = 2.91031
2025-01-17 22:01:15.670051 Epoch 6, Train Y Loss = 3.04965,  Train X Loss = 0.00000, Val Loss = 2.86062
2025-01-17 22:02:37.912448 Epoch 7, Train Y Loss = 3.02203,  Train X Loss = 0.00000, Val Loss = 2.91962
2025-01-17 22:04:00.347320 Epoch 8, Train Y Loss = 2.99891,  Train X Loss = 0.00000, Val Loss = 2.88643
2025-01-17 22:05:22.615360 Epoch 9, Train Y Loss = 2.98550,  Train X Loss = 0.00000, Val Loss = 2.88338
2025-01-17 22:06:44.807984 Epoch 10, Train Y Loss = 2.95792,  Train X Loss = 0.00000, Val Loss = 2.81757
2025-01-17 22:08:06.978736 Epoch 11, Train Y Loss = 2.94229,  Train X Loss = 0.00000, Val Loss = 2.82730
2025-01-17 22:09:29.356925 Epoch 12, Train Y Loss = 2.92372,  Train X Loss = 0.00000, Val Loss = 2.81140
2025-01-17 22:10:51.506798 Epoch 13, Train Y Loss = 2.90443,  Train X Loss = 0.00000, Val Loss = 2.77711
2025-01-17 22:12:13.794550 Epoch 14, Train Y Loss = 2.89335,  Train X Loss = 0.00000, Val Loss = 2.76773
2025-01-17 22:13:35.806802 Epoch 15, Train Y Loss = 2.87773,  Train X Loss = 0.00000, Val Loss = 2.80171
2025-01-17 22:14:57.840301 Epoch 16, Train Y Loss = 2.87113,  Train X Loss = 0.00000, Val Loss = 2.78681
2025-01-17 22:16:19.788843 Epoch 17, Train Y Loss = 2.86178,  Train X Loss = 0.00000, Val Loss = 2.75176
2025-01-17 22:17:41.978077 Epoch 18, Train Y Loss = 2.84933,  Train X Loss = 0.00000, Val Loss = 2.78546
2025-01-17 22:19:04.065369 Epoch 19, Train Y Loss = 2.84759,  Train X Loss = 0.00000, Val Loss = 2.77804
2025-01-17 22:20:25.791433 Epoch 20, Train Y Loss = 2.84053,  Train X Loss = 0.00000, Val Loss = 2.76962
2025-01-17 22:21:47.489492 Epoch 21, Train Y Loss = 2.83277,  Train X Loss = 0.00000, Val Loss = 2.73667
2025-01-17 22:23:09.145886 Epoch 22, Train Y Loss = 2.82523,  Train X Loss = 0.00000, Val Loss = 2.76633
2025-01-17 22:24:30.874805 Epoch 23, Train Y Loss = 2.82031,  Train X Loss = 0.00000, Val Loss = 2.76765
2025-01-17 22:25:52.596108 Epoch 24, Train Y Loss = 2.81515,  Train X Loss = 0.00000, Val Loss = 2.75094
2025-01-17 22:27:14.445120 Epoch 25, Train Y Loss = 2.80970,  Train X Loss = 0.00000, Val Loss = 2.77140
2025-01-17 22:28:36.206684 Epoch 26, Train Y Loss = 2.73642,  Train X Loss = 0.00000, Val Loss = 2.72159
2025-01-17 22:29:57.965409 Epoch 27, Train Y Loss = 2.72045,  Train X Loss = 0.00000, Val Loss = 2.72024
2025-01-17 22:31:19.768214 Epoch 28, Train Y Loss = 2.71413,  Train X Loss = 0.00000, Val Loss = 2.72543
2025-01-17 22:32:41.563363 Epoch 29, Train Y Loss = 2.70897,  Train X Loss = 0.00000, Val Loss = 2.72637
2025-01-17 22:34:03.191003 Epoch 30, Train Y Loss = 2.70565,  Train X Loss = 0.00000, Val Loss = 2.73405
2025-01-17 22:35:24.810496 Epoch 31, Train Y Loss = 2.70229,  Train X Loss = 0.00000, Val Loss = 2.72142
2025-01-17 22:36:46.402284 Epoch 32, Train Y Loss = 2.69997,  Train X Loss = 0.00000, Val Loss = 2.72697
2025-01-17 22:38:07.981417 Epoch 33, Train Y Loss = 2.69597,  Train X Loss = 0.00000, Val Loss = 2.72113
2025-01-17 22:39:29.576645 Epoch 34, Train Y Loss = 2.69374,  Train X Loss = 0.00000, Val Loss = 2.73010
2025-01-17 22:40:51.219408 Epoch 35, Train Y Loss = 2.69109,  Train X Loss = 0.00000, Val Loss = 2.72744
Change mask ratio: 0.075
2025-01-17 22:42:12.045861 Epoch 36, Train Y Loss = 2.65907,  Train X Loss = 0.00000, Val Loss = 2.72327
2025-01-17 22:43:32.915482 Epoch 37, Train Y Loss = 2.65622,  Train X Loss = 0.00000, Val Loss = 2.72184
2025-01-17 22:44:53.734647 Epoch 38, Train Y Loss = 2.65559,  Train X Loss = 0.00000, Val Loss = 2.72138
2025-01-17 22:46:14.787956 Epoch 39, Train Y Loss = 2.65451,  Train X Loss = 0.00000, Val Loss = 2.72458
2025-01-17 22:47:35.770745 Epoch 40, Train Y Loss = 2.65330,  Train X Loss = 0.00000, Val Loss = 2.72458
2025-01-17 22:48:56.862490 Epoch 41, Train Y Loss = 2.65317,  Train X Loss = 0.00000, Val Loss = 2.72393
2025-01-17 22:50:17.883487 Epoch 42, Train Y Loss = 2.65224,  Train X Loss = 0.00000, Val Loss = 2.72227
2025-01-17 22:51:39.033581 Epoch 43, Train Y Loss = 2.65155,  Train X Loss = 0.00000, Val Loss = 2.72165
Change mask ratio: 0.0375
2025-01-17 22:52:59.727617 Epoch 44, Train Y Loss = 2.64017,  Train X Loss = 0.00000, Val Loss = 2.72372
2025-01-17 22:54:20.388368 Epoch 45, Train Y Loss = 2.64021,  Train X Loss = 0.00000, Val Loss = 2.72286
2025-01-17 22:55:40.926111 Epoch 46, Train Y Loss = 2.63913,  Train X Loss = 0.00000, Val Loss = 2.72400
2025-01-17 22:57:01.497550 Epoch 47, Train Y Loss = 2.63883,  Train X Loss = 0.00000, Val Loss = 2.72377
2025-01-17 22:58:21.943389 Epoch 48, Train Y Loss = 2.63741,  Train X Loss = 0.00000, Val Loss = 2.72396
2025-01-17 22:59:42.291814 Epoch 49, Train Y Loss = 2.63645,  Train X Loss = 0.00000, Val Loss = 2.72420
2025-01-17 23:01:02.770565 Epoch 50, Train Y Loss = 2.63632,  Train X Loss = 0.00000, Val Loss = 2.72258
2025-01-17 23:02:23.250613 Epoch 51, Train Y Loss = 2.63536,  Train X Loss = 0.00000, Val Loss = 2.72348
Change mask ratio: 0.0
2025-01-17 23:03:39.801529 Epoch 52, Train Y Loss = 2.62419,  Train X Loss = 0.00000, Val Loss = 2.72632
2025-01-17 23:04:56.388988 Epoch 53, Train Y Loss = 2.62321,  Train X Loss = 0.00000, Val Loss = 2.72652
2025-01-17 23:06:13.074582 Epoch 54, Train Y Loss = 2.62144,  Train X Loss = 0.00000, Val Loss = 2.72670
2025-01-17 23:07:29.798273 Epoch 55, Train Y Loss = 2.62101,  Train X Loss = 0.00000, Val Loss = 2.72713
2025-01-17 23:08:46.495182 Epoch 56, Train Y Loss = 2.62005,  Train X Loss = 0.00000, Val Loss = 2.72606
2025-01-17 23:10:03.195313 Epoch 57, Train Y Loss = 2.61868,  Train X Loss = 0.00000, Val Loss = 2.72702
Early stopping at epoch: 57
Best at epoch 27:
Train Loss = 2.72045
Train RMSE = 5.35506, MAE = 2.66059, MAPE = 7.00283
Val Loss = 2.72024
Val RMSE = 5.78010, MAE = 2.77462, MAPE = 7.69034
--------- Test ---------
All Steps RMSE = 6.03564, MAE = 2.95363, MAPE = 8.06371
Step 1 RMSE = 3.94673, MAE = 2.26847, MAPE = 5.49190
Step 2 RMSE = 4.67923, MAE = 2.51748, MAPE = 6.34343
Step 3 RMSE = 5.14759, MAE = 2.67456, MAPE = 6.93256
Step 4 RMSE = 5.51484, MAE = 2.79844, MAPE = 7.42445
Step 5 RMSE = 5.81287, MAE = 2.90010, MAPE = 7.83670
Step 6 RMSE = 6.07731, MAE = 2.98912, MAPE = 8.18692
Step 7 RMSE = 6.31441, MAE = 3.06546, MAPE = 8.50296
Step 8 RMSE = 6.51756, MAE = 3.13351, MAPE = 8.77461
Step 9 RMSE = 6.68178, MAE = 3.19563, MAPE = 9.02287
Step 10 RMSE = 6.82596, MAE = 3.25168, MAPE = 9.23690
Step 11 RMSE = 6.95706, MAE = 3.29969, MAPE = 9.40930
Step 12 RMSE = 7.07472, MAE = 3.34950, MAPE = 9.60210
Inference time: 7.34 s
