METRLA
--------- DMRCMLP ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        25,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 34110658,
    "gpu": [
        0
    ],
    "save": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        283,260
├─Linear: 1-1                                 [16, 12, 207, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 207, 48]         --
│    └─Embedding: 2-1                         [16, 12, 207, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 207, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 207, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 207, 144]        158,224
├─Predictor: 1-4                              [16, 12, 207, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 207, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 207, 144]        41,760
│    └─Linear: 2-6                            [16, 207, 12]             20,748
===============================================================================================
Total params: 1,027,552
Trainable params: 1,027,552
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.48
Forward/backward pass size (MB): 1813.92
Params size (MB): 2.98
Estimated Total Size (MB): 1817.37
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-METRLA-2025-01-17-05-35-32.pt
2025-01-17 05:37:10.279996 Epoch 1, Train Y Loss = 4.10477,  Train X Loss = 2.63979, Val Loss = 3.25649
2025-01-17 05:38:51.987858 Epoch 2, Train Y Loss = 3.40395,  Train X Loss = 2.26121, Val Loss = 3.09873
2025-01-17 05:40:37.404835 Epoch 3, Train Y Loss = 3.23704,  Train X Loss = 2.21166, Val Loss = 2.95527
2025-01-17 05:42:16.939051 Epoch 4, Train Y Loss = 3.14115,  Train X Loss = 2.17218, Val Loss = 2.91905
2025-01-17 05:43:56.753042 Epoch 5, Train Y Loss = 3.07486,  Train X Loss = 2.04254, Val Loss = 2.86471
2025-01-17 05:45:42.231140 Epoch 6, Train Y Loss = 3.01961,  Train X Loss = 1.98727, Val Loss = 2.84050
2025-01-17 05:47:24.923472 Epoch 7, Train Y Loss = 2.98529,  Train X Loss = 1.96090, Val Loss = 2.81792
2025-01-17 05:49:01.894776 Epoch 8, Train Y Loss = 2.96003,  Train X Loss = 1.94823, Val Loss = 2.79945
2025-01-17 05:50:47.091402 Epoch 9, Train Y Loss = 2.94073,  Train X Loss = 1.93478, Val Loss = 2.80895
2025-01-17 05:52:31.323111 Epoch 10, Train Y Loss = 2.92415,  Train X Loss = 1.92566, Val Loss = 2.79129
2025-01-17 05:54:05.779982 Epoch 11, Train Y Loss = 2.91197,  Train X Loss = 1.91568, Val Loss = 2.85237
2025-01-17 05:55:50.730572 Epoch 12, Train Y Loss = 2.90151,  Train X Loss = 1.90642, Val Loss = 2.77332
2025-01-17 05:57:36.787560 Epoch 13, Train Y Loss = 2.89285,  Train X Loss = 1.90218, Val Loss = 2.78850
2025-01-17 05:59:10.143624 Epoch 14, Train Y Loss = 2.88448,  Train X Loss = 1.89783, Val Loss = 2.74229
2025-01-17 06:00:56.022644 Epoch 15, Train Y Loss = 2.87532,  Train X Loss = 1.88977, Val Loss = 2.76528
2025-01-17 06:02:28.952088 Epoch 16, Train Y Loss = 2.86705,  Train X Loss = 1.88568, Val Loss = 2.73807
2025-01-17 06:04:09.876834 Epoch 17, Train Y Loss = 2.86172,  Train X Loss = 1.88197, Val Loss = 2.75862
2025-01-17 06:05:49.173594 Epoch 18, Train Y Loss = 2.85394,  Train X Loss = 1.87689, Val Loss = 2.76136
2025-01-17 06:07:35.793593 Epoch 19, Train Y Loss = 2.84861,  Train X Loss = 1.87217, Val Loss = 2.74135
2025-01-17 06:09:16.002841 Epoch 20, Train Y Loss = 2.84361,  Train X Loss = 1.86924, Val Loss = 2.72974
2025-01-17 06:10:57.425286 Epoch 21, Train Y Loss = 2.83885,  Train X Loss = 1.86700, Val Loss = 2.73406
2025-01-17 06:12:43.505324 Epoch 22, Train Y Loss = 2.83504,  Train X Loss = 1.86476, Val Loss = 2.73825
2025-01-17 06:14:22.049430 Epoch 23, Train Y Loss = 2.82897,  Train X Loss = 1.86063, Val Loss = 2.72565
2025-01-17 06:16:04.290198 Epoch 24, Train Y Loss = 2.82587,  Train X Loss = 1.85970, Val Loss = 2.74697
2025-01-17 06:17:50.558704 Epoch 25, Train Y Loss = 2.82090,  Train X Loss = 1.85427, Val Loss = 2.72971
2025-01-17 06:19:25.620783 Epoch 26, Train Y Loss = 2.74436,  Train X Loss = 1.81660, Val Loss = 2.66856
2025-01-17 06:21:09.444594 Epoch 27, Train Y Loss = 2.73104,  Train X Loss = 1.80915, Val Loss = 2.66143
2025-01-17 06:22:55.341450 Epoch 28, Train Y Loss = 2.72547,  Train X Loss = 1.80672, Val Loss = 2.66677
2025-01-17 06:24:30.299443 Epoch 29, Train Y Loss = 2.72122,  Train X Loss = 1.80450, Val Loss = 2.65861
2025-01-17 06:26:16.260827 Epoch 30, Train Y Loss = 2.71767,  Train X Loss = 1.80393, Val Loss = 2.65956
2025-01-17 06:28:02.232498 Epoch 31, Train Y Loss = 2.71571,  Train X Loss = 1.80181, Val Loss = 2.66127
2025-01-17 06:29:35.528946 Epoch 32, Train Y Loss = 2.71273,  Train X Loss = 1.80214, Val Loss = 2.67237
2025-01-17 06:31:09.104473 Epoch 33, Train Y Loss = 2.71072,  Train X Loss = 1.80254, Val Loss = 2.66433
2025-01-17 06:32:55.397502 Epoch 34, Train Y Loss = 2.70898,  Train X Loss = 1.79972, Val Loss = 2.66394
2025-01-17 06:34:40.884676 Epoch 35, Train Y Loss = 2.70707,  Train X Loss = 1.79940, Val Loss = 2.66624
2025-01-17 06:36:16.098968 Epoch 36, Train Y Loss = 2.69368,  Train X Loss = 1.79637, Val Loss = 2.65551
2025-01-17 06:38:02.445975 Epoch 37, Train Y Loss = 2.69293,  Train X Loss = 1.79501, Val Loss = 2.65555
2025-01-17 06:39:44.746523 Epoch 38, Train Y Loss = 2.69112,  Train X Loss = 1.79395, Val Loss = 2.65439
2025-01-17 06:41:22.137850 Epoch 39, Train Y Loss = 2.69088,  Train X Loss = 1.79358, Val Loss = 2.65640
2025-01-17 06:43:08.066784 Epoch 40, Train Y Loss = 2.69266,  Train X Loss = 1.79357, Val Loss = 2.65347
2025-01-17 06:44:50.320896 Epoch 41, Train Y Loss = 2.69021,  Train X Loss = 1.79233, Val Loss = 2.65462
2025-01-17 06:46:28.680322 Epoch 42, Train Y Loss = 2.69092,  Train X Loss = 1.79485, Val Loss = 2.65788
2025-01-17 06:48:14.639715 Epoch 43, Train Y Loss = 2.68871,  Train X Loss = 1.79290, Val Loss = 2.65646
2025-01-17 06:49:56.150691 Epoch 44, Train Y Loss = 2.68929,  Train X Loss = 1.79257, Val Loss = 2.65566
2025-01-17 06:51:35.292543 Epoch 45, Train Y Loss = 2.68969,  Train X Loss = 1.79280, Val Loss = 2.65508
2025-01-17 06:53:20.980134 Epoch 46, Train Y Loss = 2.68977,  Train X Loss = 1.79254, Val Loss = 2.65623
2025-01-17 06:55:00.310066 Epoch 47, Train Y Loss = 2.68907,  Train X Loss = 1.79309, Val Loss = 2.65633
2025-01-17 06:56:41.885352 Epoch 48, Train Y Loss = 2.68822,  Train X Loss = 1.79352, Val Loss = 2.65691
2025-01-17 06:58:15.030185 Epoch 49, Train Y Loss = 2.68805,  Train X Loss = 1.79154, Val Loss = 2.65495
2025-01-17 07:00:02.088598 Epoch 50, Train Y Loss = 2.68813,  Train X Loss = 1.79222, Val Loss = 2.65519
2025-01-17 07:01:35.659048 Epoch 51, Train Y Loss = 2.68750,  Train X Loss = 1.79161, Val Loss = 2.65576
2025-01-17 07:03:21.351232 Epoch 52, Train Y Loss = 2.68664,  Train X Loss = 1.79158, Val Loss = 2.65659
2025-01-17 07:05:07.514722 Epoch 53, Train Y Loss = 2.68657,  Train X Loss = 1.79331, Val Loss = 2.65619
2025-01-17 07:06:41.419939 Epoch 54, Train Y Loss = 2.68658,  Train X Loss = 1.79116, Val Loss = 2.65615
2025-01-17 07:08:26.980020 Epoch 55, Train Y Loss = 2.68621,  Train X Loss = 1.79098, Val Loss = 2.65643
2025-01-17 07:10:13.057071 Epoch 56, Train Y Loss = 2.68516,  Train X Loss = 1.79201, Val Loss = 2.65416
2025-01-17 07:11:46.867961 Epoch 57, Train Y Loss = 2.68567,  Train X Loss = 1.79209, Val Loss = 2.65652
2025-01-17 07:13:33.584609 Epoch 58, Train Y Loss = 2.68478,  Train X Loss = 1.79177, Val Loss = 2.65501
2025-01-17 07:15:20.158912 Epoch 59, Train Y Loss = 2.68527,  Train X Loss = 1.79120, Val Loss = 2.65465
2025-01-17 07:16:54.246737 Epoch 60, Train Y Loss = 2.68365,  Train X Loss = 1.79075, Val Loss = 2.65363
2025-01-17 07:18:41.387288 Epoch 61, Train Y Loss = 2.68512,  Train X Loss = 1.79203, Val Loss = 2.65506
2025-01-17 07:20:27.547471 Epoch 62, Train Y Loss = 2.68330,  Train X Loss = 1.79130, Val Loss = 2.65390
2025-01-17 07:22:01.044514 Epoch 63, Train Y Loss = 2.68409,  Train X Loss = 1.79098, Val Loss = 2.65511
2025-01-17 07:23:47.205554 Epoch 64, Train Y Loss = 2.68258,  Train X Loss = 1.78956, Val Loss = 2.65404
2025-01-17 07:25:20.859253 Epoch 65, Train Y Loss = 2.68420,  Train X Loss = 1.79205, Val Loss = 2.65548
2025-01-17 07:27:06.849232 Epoch 66, Train Y Loss = 2.68268,  Train X Loss = 1.79075, Val Loss = 2.65331
2025-01-17 07:28:41.935967 Epoch 67, Train Y Loss = 2.68245,  Train X Loss = 1.79134, Val Loss = 2.65524
2025-01-17 07:30:28.357040 Epoch 68, Train Y Loss = 2.68222,  Train X Loss = 1.79038, Val Loss = 2.65592
2025-01-17 07:32:12.303989 Epoch 69, Train Y Loss = 2.68270,  Train X Loss = 1.79005, Val Loss = 2.65613
2025-01-17 07:33:49.581683 Epoch 70, Train Y Loss = 2.68131,  Train X Loss = 1.78917, Val Loss = 2.65778
2025-01-17 07:35:36.924881 Epoch 71, Train Y Loss = 2.68105,  Train X Loss = 1.79016, Val Loss = 2.65589
2025-01-17 07:37:17.599179 Epoch 72, Train Y Loss = 2.68119,  Train X Loss = 1.78937, Val Loss = 2.65745
2025-01-17 07:38:58.899230 Epoch 73, Train Y Loss = 2.68102,  Train X Loss = 1.79086, Val Loss = 2.65749
2025-01-17 07:40:45.578326 Epoch 74, Train Y Loss = 2.68031,  Train X Loss = 1.79047, Val Loss = 2.65618
2025-01-17 07:42:23.576184 Epoch 75, Train Y Loss = 2.67950,  Train X Loss = 1.79002, Val Loss = 2.65380
2025-01-17 07:44:05.763139 Epoch 76, Train Y Loss = 2.68000,  Train X Loss = 1.79039, Val Loss = 2.65795
2025-01-17 07:45:52.713893 Epoch 77, Train Y Loss = 2.67899,  Train X Loss = 1.78946, Val Loss = 2.65808
2025-01-17 07:47:28.298794 Epoch 78, Train Y Loss = 2.67962,  Train X Loss = 1.78955, Val Loss = 2.65641
2025-01-17 07:49:13.624735 Epoch 79, Train Y Loss = 2.67923,  Train X Loss = 1.79023, Val Loss = 2.65633
2025-01-17 07:50:59.474119 Epoch 80, Train Y Loss = 2.67879,  Train X Loss = 1.78927, Val Loss = 2.65764
2025-01-17 07:52:32.844694 Epoch 81, Train Y Loss = 2.67828,  Train X Loss = 1.78895, Val Loss = 2.65706
2025-01-17 07:54:06.330089 Epoch 82, Train Y Loss = 2.67822,  Train X Loss = 1.78911, Val Loss = 2.66136
2025-01-17 07:55:52.458292 Epoch 83, Train Y Loss = 2.67643,  Train X Loss = 1.78682, Val Loss = 2.65883
2025-01-17 07:57:39.320507 Epoch 84, Train Y Loss = 2.67664,  Train X Loss = 1.78794, Val Loss = 2.65845
2025-01-17 07:59:12.536140 Epoch 85, Train Y Loss = 2.67658,  Train X Loss = 1.78708, Val Loss = 2.65770
2025-01-17 08:00:58.729545 Epoch 86, Train Y Loss = 2.67626,  Train X Loss = 1.78772, Val Loss = 2.65586
2025-01-17 08:02:45.926293 Epoch 87, Train Y Loss = 2.67617,  Train X Loss = 1.78831, Val Loss = 2.65580
2025-01-17 08:04:20.913480 Epoch 88, Train Y Loss = 2.67613,  Train X Loss = 1.78717, Val Loss = 2.65664
2025-01-17 08:06:07.423704 Epoch 89, Train Y Loss = 2.67561,  Train X Loss = 1.78875, Val Loss = 2.66010
2025-01-17 08:07:51.088407 Epoch 90, Train Y Loss = 2.67628,  Train X Loss = 1.78758, Val Loss = 2.65831
2025-01-17 08:09:28.771492 Epoch 91, Train Y Loss = 2.67398,  Train X Loss = 1.78657, Val Loss = 2.66039
2025-01-17 08:11:15.726495 Epoch 92, Train Y Loss = 2.67470,  Train X Loss = 1.78819, Val Loss = 2.65930
2025-01-17 08:12:55.881491 Epoch 93, Train Y Loss = 2.67423,  Train X Loss = 1.78711, Val Loss = 2.65863
2025-01-17 08:14:39.089982 Epoch 94, Train Y Loss = 2.67412,  Train X Loss = 1.78965, Val Loss = 2.65854
2025-01-17 08:16:25.857731 Epoch 95, Train Y Loss = 2.67385,  Train X Loss = 1.78599, Val Loss = 2.65995
2025-01-17 08:17:59.835358 Epoch 96, Train Y Loss = 2.67359,  Train X Loss = 1.78675, Val Loss = 2.65803
Early stopping at epoch: 96
Best at epoch 66:
Train Loss = 2.68268
Train RMSE = 5.30365, MAE = 2.63472, MAPE = 6.87176
Val Loss = 2.65331
Val RMSE = 5.60017, MAE = 2.70538, MAPE = 7.33396
--------- Test ---------
All Steps RMSE = 5.89325, MAE = 2.89379, MAPE = 7.83848
Step 1 RMSE = 3.69116, MAE = 2.12702, MAPE = 4.99001
Step 2 RMSE = 4.47471, MAE = 2.42944, MAPE = 5.98391
Step 3 RMSE = 4.98687, MAE = 2.61396, MAPE = 6.67726
Step 4 RMSE = 5.37439, MAE = 2.74591, MAPE = 7.19924
Step 5 RMSE = 5.68269, MAE = 2.85049, MAPE = 7.62673
Step 6 RMSE = 5.95096, MAE = 2.94057, MAPE = 7.99269
Step 7 RMSE = 6.18225, MAE = 3.01838, MAPE = 8.31211
Step 8 RMSE = 6.37858, MAE = 3.08545, MAPE = 8.58930
Step 9 RMSE = 6.54567, MAE = 3.14797, MAPE = 8.84657
Step 10 RMSE = 6.69579, MAE = 3.20381, MAPE = 9.07141
Step 11 RMSE = 6.82960, MAE = 3.25478, MAPE = 9.28263
Step 12 RMSE = 6.95912, MAE = 3.30782, MAPE = 9.49018
Inference time: 10.72 s
