METRLA
--------- DMRCMLP ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        25,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 93048409,
    "gpu": [
        0
    ],
    "save": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        283,260
├─Linear: 1-1                                 [16, 12, 207, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 207, 48]         --
│    └─Embedding: 2-1                         [16, 12, 207, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 207, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 207, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 207, 144]        158,224
├─Predictor: 1-4                              [16, 12, 207, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 207, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 207, 144]        41,760
│    └─Linear: 2-6                            [16, 207, 12]             20,748
===============================================================================================
Total params: 1,027,552
Trainable params: 1,027,552
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.48
Forward/backward pass size (MB): 1813.92
Params size (MB): 2.98
Estimated Total Size (MB): 1817.37
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-METRLA-2025-01-18-03-21-38.pt
2025-01-18 03:22:56.007410 Epoch 1, Train Y Loss = 4.07441,  Train X Loss = 0.00000, Val Loss = 3.27730
2025-01-18 03:24:13.239067 Epoch 2, Train Y Loss = 3.34593,  Train X Loss = 0.00000, Val Loss = 3.05743
2025-01-18 03:25:30.408341 Epoch 3, Train Y Loss = 3.18961,  Train X Loss = 0.00000, Val Loss = 3.07153
2025-01-18 03:26:47.530052 Epoch 4, Train Y Loss = 3.11091,  Train X Loss = 0.00000, Val Loss = 3.03661
2025-01-18 03:28:04.779325 Epoch 5, Train Y Loss = 3.06212,  Train X Loss = 0.00000, Val Loss = 2.87149
2025-01-18 03:29:21.988685 Epoch 6, Train Y Loss = 3.02346,  Train X Loss = 0.00000, Val Loss = 2.86796
2025-01-18 03:30:39.254563 Epoch 7, Train Y Loss = 2.99388,  Train X Loss = 0.00000, Val Loss = 2.87631
2025-01-18 03:31:56.465026 Epoch 8, Train Y Loss = 2.96632,  Train X Loss = 0.00000, Val Loss = 2.86708
2025-01-18 03:33:13.848970 Epoch 9, Train Y Loss = 2.94111,  Train X Loss = 0.00000, Val Loss = 2.85724
2025-01-18 03:34:31.203098 Epoch 10, Train Y Loss = 2.90989,  Train X Loss = 0.00000, Val Loss = 2.79212
2025-01-18 03:35:48.519677 Epoch 11, Train Y Loss = 2.88432,  Train X Loss = 0.00000, Val Loss = 2.78744
2025-01-18 03:37:05.868443 Epoch 12, Train Y Loss = 2.86271,  Train X Loss = 0.00000, Val Loss = 2.79189
2025-01-18 03:38:23.245534 Epoch 13, Train Y Loss = 2.83752,  Train X Loss = 0.00000, Val Loss = 2.75644
2025-01-18 03:39:40.549141 Epoch 14, Train Y Loss = 2.82650,  Train X Loss = 0.00000, Val Loss = 2.73002
2025-01-18 03:40:57.933690 Epoch 15, Train Y Loss = 2.80737,  Train X Loss = 0.00000, Val Loss = 2.75098
2025-01-18 03:42:15.346209 Epoch 16, Train Y Loss = 2.79335,  Train X Loss = 0.00000, Val Loss = 2.73141
2025-01-18 03:43:32.691191 Epoch 17, Train Y Loss = 2.77803,  Train X Loss = 0.00000, Val Loss = 2.73230
2025-01-18 03:44:50.026804 Epoch 18, Train Y Loss = 2.76325,  Train X Loss = 0.00000, Val Loss = 2.76444
2025-01-18 03:46:07.473582 Epoch 19, Train Y Loss = 2.74911,  Train X Loss = 0.00000, Val Loss = 2.77294
2025-01-18 03:47:24.862081 Epoch 20, Train Y Loss = 2.73474,  Train X Loss = 0.00000, Val Loss = 2.77738
2025-01-18 03:48:42.161132 Epoch 21, Train Y Loss = 2.71933,  Train X Loss = 0.00000, Val Loss = 2.78111
2025-01-18 03:49:59.630655 Epoch 22, Train Y Loss = 2.70434,  Train X Loss = 0.00000, Val Loss = 2.78614
2025-01-18 03:51:16.937329 Epoch 23, Train Y Loss = 2.69225,  Train X Loss = 0.00000, Val Loss = 2.82446
2025-01-18 03:52:34.078952 Epoch 24, Train Y Loss = 2.68018,  Train X Loss = 0.00000, Val Loss = 2.79145
2025-01-18 03:53:51.142880 Epoch 25, Train Y Loss = 2.67166,  Train X Loss = 0.00000, Val Loss = 2.85523
2025-01-18 03:55:08.127214 Epoch 26, Train Y Loss = 2.57569,  Train X Loss = 0.00000, Val Loss = 2.79233
2025-01-18 03:56:24.953506 Epoch 27, Train Y Loss = 2.55019,  Train X Loss = 0.00000, Val Loss = 2.79470
2025-01-18 03:57:41.901933 Epoch 28, Train Y Loss = 2.53827,  Train X Loss = 0.00000, Val Loss = 2.80529
2025-01-18 03:58:58.885883 Epoch 29, Train Y Loss = 2.53012,  Train X Loss = 0.00000, Val Loss = 2.80671
2025-01-18 04:00:15.988820 Epoch 30, Train Y Loss = 2.52279,  Train X Loss = 0.00000, Val Loss = 2.81264
2025-01-18 04:01:33.206110 Epoch 31, Train Y Loss = 2.51699,  Train X Loss = 0.00000, Val Loss = 2.81705
2025-01-18 04:02:50.398420 Epoch 32, Train Y Loss = 2.51236,  Train X Loss = 0.00000, Val Loss = 2.82830
2025-01-18 04:04:07.607110 Epoch 33, Train Y Loss = 2.50652,  Train X Loss = 0.00000, Val Loss = 2.81781
2025-01-18 04:05:24.807804 Epoch 34, Train Y Loss = 2.50164,  Train X Loss = 0.00000, Val Loss = 2.82829
2025-01-18 04:06:42.070453 Epoch 35, Train Y Loss = 2.49739,  Train X Loss = 0.00000, Val Loss = 2.83410
2025-01-18 04:07:59.361665 Epoch 36, Train Y Loss = 2.48281,  Train X Loss = 0.00000, Val Loss = 2.83887
2025-01-18 04:09:16.661061 Epoch 37, Train Y Loss = 2.48020,  Train X Loss = 0.00000, Val Loss = 2.84034
2025-01-18 04:10:33.914826 Epoch 38, Train Y Loss = 2.47881,  Train X Loss = 0.00000, Val Loss = 2.84055
2025-01-18 04:11:51.278049 Epoch 39, Train Y Loss = 2.47858,  Train X Loss = 0.00000, Val Loss = 2.84270
2025-01-18 04:13:08.575776 Epoch 40, Train Y Loss = 2.47714,  Train X Loss = 0.00000, Val Loss = 2.84699
2025-01-18 04:14:25.925776 Epoch 41, Train Y Loss = 2.47610,  Train X Loss = 0.00000, Val Loss = 2.84342
2025-01-18 04:15:43.306324 Epoch 42, Train Y Loss = 2.47585,  Train X Loss = 0.00000, Val Loss = 2.84302
2025-01-18 04:17:00.466752 Epoch 43, Train Y Loss = 2.47429,  Train X Loss = 0.00000, Val Loss = 2.84676
2025-01-18 04:18:17.580696 Epoch 44, Train Y Loss = 2.47446,  Train X Loss = 0.00000, Val Loss = 2.84949
Early stopping at epoch: 44
Best at epoch 14:
Train Loss = 2.82650
Train RMSE = 5.61667, MAE = 2.78013, MAPE = 7.36003
Val Loss = 2.73002
Val RMSE = 5.77081, MAE = 2.78465, MAPE = 7.66933
--------- Test ---------
All Steps RMSE = 6.09189, MAE = 3.00300, MAPE = 8.21139
Step 1 RMSE = 4.03900, MAE = 2.30699, MAPE = 5.56674
Step 2 RMSE = 4.79957, MAE = 2.55956, MAPE = 6.44398
Step 3 RMSE = 5.25639, MAE = 2.71781, MAPE = 7.04500
Step 4 RMSE = 5.61104, MAE = 2.83778, MAPE = 7.54746
Step 5 RMSE = 5.92022, MAE = 2.94502, MAPE = 7.94004
Step 6 RMSE = 6.16703, MAE = 3.03331, MAPE = 8.29539
Step 7 RMSE = 6.38911, MAE = 3.11883, MAPE = 8.60710
Step 8 RMSE = 6.54373, MAE = 3.18072, MAPE = 8.89369
Step 9 RMSE = 6.70033, MAE = 3.24825, MAPE = 9.19702
Step 10 RMSE = 6.83305, MAE = 3.30490, MAPE = 9.47632
Step 11 RMSE = 6.95272, MAE = 3.35946, MAPE = 9.64120
Step 12 RMSE = 7.08695, MAE = 3.42339, MAPE = 9.88291
Inference time: 7.42 s
