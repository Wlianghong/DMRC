METRLA
--------- DMRCMLP ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        25,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": true,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        0
    ],
    "save": false,
    "model_args": {
        "num_nodes": 207,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        283,260
├─Linear: 1-1                                 [16, 12, 207, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 207, 48]         --
│    └─Embedding: 2-1                         [16, 12, 207, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 207, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 207, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 207, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 207, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 207, 144]        158,224
├─Predictor: 1-4                              [16, 12, 207, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 207, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 207, 144]        41,760
│    └─Linear: 2-6                            [16, 207, 12]             20,748
===============================================================================================
Total params: 1,027,552
Trainable params: 1,027,552
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.48
Forward/backward pass size (MB): 1813.92
Params size (MB): 2.98
Estimated Total Size (MB): 1817.37
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-METRLA-2025-01-17-20-36-25.pt
2025-01-17 20:37:48.981590 Epoch 1, Train Y Loss = 4.09736,  Train X Loss = 0.00000, Val Loss = 3.30836
2025-01-17 20:39:12.155681 Epoch 2, Train Y Loss = 3.41786,  Train X Loss = 0.00000, Val Loss = 3.17443
2025-01-17 20:40:35.548601 Epoch 3, Train Y Loss = 3.26759,  Train X Loss = 0.00000, Val Loss = 2.99516
2025-01-17 20:41:58.722824 Epoch 4, Train Y Loss = 3.14043,  Train X Loss = 0.00000, Val Loss = 2.93618
2025-01-17 20:43:21.994094 Epoch 5, Train Y Loss = 3.07751,  Train X Loss = 0.00000, Val Loss = 2.91759
2025-01-17 20:44:45.157711 Epoch 6, Train Y Loss = 3.04122,  Train X Loss = 0.00000, Val Loss = 2.89560
2025-01-17 20:46:08.428448 Epoch 7, Train Y Loss = 3.01497,  Train X Loss = 0.00000, Val Loss = 2.87920
2025-01-17 20:47:31.654654 Epoch 8, Train Y Loss = 2.98712,  Train X Loss = 0.00000, Val Loss = 2.90373
2025-01-17 20:48:54.604531 Epoch 9, Train Y Loss = 2.96296,  Train X Loss = 0.00000, Val Loss = 2.84150
2025-01-17 20:50:17.682116 Epoch 10, Train Y Loss = 2.94261,  Train X Loss = 0.00000, Val Loss = 2.81325
2025-01-17 20:51:40.597257 Epoch 11, Train Y Loss = 2.92294,  Train X Loss = 0.00000, Val Loss = 2.82932
2025-01-17 20:53:03.427404 Epoch 12, Train Y Loss = 2.90878,  Train X Loss = 0.00000, Val Loss = 2.79228
2025-01-17 20:54:26.156526 Epoch 13, Train Y Loss = 2.89468,  Train X Loss = 0.00000, Val Loss = 2.78526
2025-01-17 20:55:48.991678 Epoch 14, Train Y Loss = 2.88862,  Train X Loss = 0.00000, Val Loss = 2.76336
2025-01-17 20:57:11.943381 Epoch 15, Train Y Loss = 2.87400,  Train X Loss = 0.00000, Val Loss = 2.80254
2025-01-17 20:58:35.016634 Epoch 16, Train Y Loss = 2.86626,  Train X Loss = 0.00000, Val Loss = 2.80790
2025-01-17 20:59:57.922250 Epoch 17, Train Y Loss = 2.85862,  Train X Loss = 0.00000, Val Loss = 2.77413
2025-01-17 21:01:21.072493 Epoch 18, Train Y Loss = 2.85508,  Train X Loss = 0.00000, Val Loss = 2.78941
2025-01-17 21:02:44.103346 Epoch 19, Train Y Loss = 2.84399,  Train X Loss = 0.00000, Val Loss = 2.77548
2025-01-17 21:04:07.225898 Epoch 20, Train Y Loss = 2.84476,  Train X Loss = 0.00000, Val Loss = 2.77656
2025-01-17 21:05:30.324540 Epoch 21, Train Y Loss = 2.83109,  Train X Loss = 0.00000, Val Loss = 2.78882
2025-01-17 21:06:53.445700 Epoch 22, Train Y Loss = 2.82963,  Train X Loss = 0.00000, Val Loss = 2.77357
Change mask ratio: 0.075
2025-01-17 21:08:15.778246 Epoch 23, Train Y Loss = 2.80830,  Train X Loss = 0.00000, Val Loss = 2.77949
2025-01-17 21:09:37.967512 Epoch 24, Train Y Loss = 2.80163,  Train X Loss = 0.00000, Val Loss = 2.75618
2025-01-17 21:11:00.003246 Epoch 25, Train Y Loss = 2.79425,  Train X Loss = 0.00000, Val Loss = 2.76139
2025-01-17 21:12:22.207928 Epoch 26, Train Y Loss = 2.71452,  Train X Loss = 0.00000, Val Loss = 2.71264
2025-01-17 21:13:44.001974 Epoch 27, Train Y Loss = 2.70025,  Train X Loss = 0.00000, Val Loss = 2.71958
2025-01-17 21:15:06.032048 Epoch 28, Train Y Loss = 2.69317,  Train X Loss = 0.00000, Val Loss = 2.71979
2025-01-17 21:16:28.267363 Epoch 29, Train Y Loss = 2.68763,  Train X Loss = 0.00000, Val Loss = 2.71544
2025-01-17 21:17:50.310821 Epoch 30, Train Y Loss = 2.68438,  Train X Loss = 0.00000, Val Loss = 2.72271
2025-01-17 21:19:12.561584 Epoch 31, Train Y Loss = 2.68032,  Train X Loss = 0.00000, Val Loss = 2.71887
2025-01-17 21:20:34.722425 Epoch 32, Train Y Loss = 2.67543,  Train X Loss = 0.00000, Val Loss = 2.72648
2025-01-17 21:21:56.976025 Epoch 33, Train Y Loss = 2.67263,  Train X Loss = 0.00000, Val Loss = 2.72594
2025-01-17 21:23:19.192085 Epoch 34, Train Y Loss = 2.66923,  Train X Loss = 0.00000, Val Loss = 2.72680
Change mask ratio: 0.0375
2025-01-17 21:24:41.211558 Epoch 35, Train Y Loss = 2.65179,  Train X Loss = 0.00000, Val Loss = 2.72979
2025-01-17 21:26:03.056293 Epoch 36, Train Y Loss = 2.63946,  Train X Loss = 0.00000, Val Loss = 2.72326
2025-01-17 21:27:24.985306 Epoch 37, Train Y Loss = 2.63803,  Train X Loss = 0.00000, Val Loss = 2.72404
2025-01-17 21:28:46.725945 Epoch 38, Train Y Loss = 2.63639,  Train X Loss = 0.00000, Val Loss = 2.72274
2025-01-17 21:30:08.336515 Epoch 39, Train Y Loss = 2.63616,  Train X Loss = 0.00000, Val Loss = 2.72213
2025-01-17 21:31:30.114898 Epoch 40, Train Y Loss = 2.63476,  Train X Loss = 0.00000, Val Loss = 2.72256
2025-01-17 21:32:51.447001 Epoch 41, Train Y Loss = 2.63374,  Train X Loss = 0.00000, Val Loss = 2.72373
2025-01-17 21:34:13.214635 Epoch 42, Train Y Loss = 2.63402,  Train X Loss = 0.00000, Val Loss = 2.72323
Change mask ratio: 0.0
2025-01-17 21:35:30.792536 Epoch 43, Train Y Loss = 2.61933,  Train X Loss = 0.00000, Val Loss = 2.72152
2025-01-17 21:36:48.364483 Epoch 44, Train Y Loss = 2.61798,  Train X Loss = 0.00000, Val Loss = 2.72292
2025-01-17 21:38:06.107213 Epoch 45, Train Y Loss = 2.61706,  Train X Loss = 0.00000, Val Loss = 2.72356
2025-01-17 21:39:23.835567 Epoch 46, Train Y Loss = 2.61541,  Train X Loss = 0.00000, Val Loss = 2.72298
2025-01-17 21:40:41.561177 Epoch 47, Train Y Loss = 2.61456,  Train X Loss = 0.00000, Val Loss = 2.72223
2025-01-17 21:41:59.361454 Epoch 48, Train Y Loss = 2.61512,  Train X Loss = 0.00000, Val Loss = 2.72259
2025-01-17 21:43:17.193074 Epoch 49, Train Y Loss = 2.61347,  Train X Loss = 0.00000, Val Loss = 2.72341
2025-01-17 21:44:34.888201 Epoch 50, Train Y Loss = 2.61193,  Train X Loss = 0.00000, Val Loss = 2.72570
Change mask ratio: 0.0
2025-01-17 21:45:52.551485 Epoch 51, Train Y Loss = 2.61165,  Train X Loss = 0.00000, Val Loss = 2.72276
2025-01-17 21:47:10.174424 Epoch 52, Train Y Loss = 2.61124,  Train X Loss = 0.00000, Val Loss = 2.72591
2025-01-17 21:48:27.693970 Epoch 53, Train Y Loss = 2.61101,  Train X Loss = 0.00000, Val Loss = 2.72577
2025-01-17 21:49:45.233934 Epoch 54, Train Y Loss = 2.61000,  Train X Loss = 0.00000, Val Loss = 2.72587
2025-01-17 21:51:02.764480 Epoch 55, Train Y Loss = 2.60914,  Train X Loss = 0.00000, Val Loss = 2.72486
2025-01-17 21:52:20.390324 Epoch 56, Train Y Loss = 2.60886,  Train X Loss = 0.00000, Val Loss = 2.72589
Early stopping at epoch: 56
Best at epoch 26:
Train Loss = 2.71452
Train RMSE = 5.33712, MAE = 2.65509, MAPE = 7.05073
Val Loss = 2.71264
Val RMSE = 5.73923, MAE = 2.76431, MAPE = 7.68437
--------- Test ---------
All Steps RMSE = 6.03920, MAE = 2.95119, MAPE = 8.19435
Step 1 RMSE = 3.95359, MAE = 2.26683, MAPE = 5.55689
Step 2 RMSE = 4.67930, MAE = 2.51259, MAPE = 6.40898
Step 3 RMSE = 5.14757, MAE = 2.67116, MAPE = 7.02010
Step 4 RMSE = 5.51158, MAE = 2.79089, MAPE = 7.50030
Step 5 RMSE = 5.81349, MAE = 2.89380, MAPE = 7.92949
Step 6 RMSE = 6.07916, MAE = 2.98578, MAPE = 8.32522
Step 7 RMSE = 6.31902, MAE = 3.06499, MAPE = 8.64215
Step 8 RMSE = 6.52037, MAE = 3.13369, MAPE = 8.92001
Step 9 RMSE = 6.68599, MAE = 3.19549, MAPE = 9.17275
Step 10 RMSE = 6.83466, MAE = 3.25048, MAPE = 9.41226
Step 11 RMSE = 6.96427, MAE = 3.29912, MAPE = 9.62508
Step 12 RMSE = 7.08161, MAE = 3.34947, MAPE = 9.81901
Inference time: 7.56 s
