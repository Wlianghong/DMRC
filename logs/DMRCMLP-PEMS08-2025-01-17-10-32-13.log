PEMS08
--------- DMRCMLP ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0015,
    "milestones": [
        30,
        50,
        70
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 74418540,
    "gpu": [
        2
    ],
    "save": true,
    "model_args": {
        "num_nodes": 170,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        272,172
├─Linear: 1-1                                 [16, 12, 170, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 170, 48]         --
│    └─Embedding: 2-1                         [16, 12, 170, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 170, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 170, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 170, 144]        158,224
├─Predictor: 1-4                              [16, 12, 170, 1]          --
│    └─Linear: 2-5                            [16, 12, 170, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 170, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 170, 144]        41,760
│    └─Linear: 2-7                            [16, 170, 12]             20,748
===============================================================================================
Total params: 1,037,344
Trainable params: 1,037,344
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.39
Forward/backward pass size (MB): 1527.29
Params size (MB): 3.06
Estimated Total Size (MB): 1530.74
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS08-2025-01-17-10-32-13.pt
2025-01-17 10:32:48.393770 Epoch 1, Train Y Loss = 23.55096,  Train X Loss = 0.00000, Val Loss = 18.15116
2025-01-17 10:33:22.894863 Epoch 2, Train Y Loss = 17.93641,  Train X Loss = 0.00000, Val Loss = 17.07396
2025-01-17 10:33:57.436438 Epoch 3, Train Y Loss = 16.91448,  Train X Loss = 0.00000, Val Loss = 16.23276
2025-01-17 10:34:32.010714 Epoch 4, Train Y Loss = 16.26148,  Train X Loss = 0.00000, Val Loss = 16.50881
2025-01-17 10:35:06.429774 Epoch 5, Train Y Loss = 15.88755,  Train X Loss = 0.00000, Val Loss = 15.75743
2025-01-17 10:35:40.939526 Epoch 6, Train Y Loss = 15.52904,  Train X Loss = 0.00000, Val Loss = 15.24568
2025-01-17 10:36:15.414855 Epoch 7, Train Y Loss = 15.29827,  Train X Loss = 0.00000, Val Loss = 15.06852
2025-01-17 10:36:49.976113 Epoch 8, Train Y Loss = 15.05626,  Train X Loss = 0.00000, Val Loss = 14.95900
2025-01-17 10:37:24.381539 Epoch 9, Train Y Loss = 14.92175,  Train X Loss = 0.00000, Val Loss = 14.75224
2025-01-17 10:37:58.937314 Epoch 10, Train Y Loss = 14.75247,  Train X Loss = 0.00000, Val Loss = 14.96033
2025-01-17 10:38:33.464396 Epoch 11, Train Y Loss = 14.57481,  Train X Loss = 0.00000, Val Loss = 14.56707
2025-01-17 10:39:08.029420 Epoch 12, Train Y Loss = 14.38317,  Train X Loss = 0.00000, Val Loss = 14.25977
2025-01-17 10:39:42.451843 Epoch 13, Train Y Loss = 14.19365,  Train X Loss = 0.00000, Val Loss = 14.41516
2025-01-17 10:40:16.994462 Epoch 14, Train Y Loss = 14.06597,  Train X Loss = 0.00000, Val Loss = 14.26657
2025-01-17 10:40:51.507793 Epoch 15, Train Y Loss = 13.83962,  Train X Loss = 0.00000, Val Loss = 13.99832
2025-01-17 10:41:26.067549 Epoch 16, Train Y Loss = 13.75586,  Train X Loss = 0.00000, Val Loss = 13.85899
2025-01-17 10:42:00.468883 Epoch 17, Train Y Loss = 13.63884,  Train X Loss = 0.00000, Val Loss = 14.26854
2025-01-17 10:42:34.998080 Epoch 18, Train Y Loss = 13.49229,  Train X Loss = 0.00000, Val Loss = 13.84282
2025-01-17 10:43:09.456701 Epoch 19, Train Y Loss = 13.44068,  Train X Loss = 0.00000, Val Loss = 13.67287
2025-01-17 10:43:43.917537 Epoch 20, Train Y Loss = 13.31972,  Train X Loss = 0.00000, Val Loss = 13.76997
2025-01-17 10:44:18.200697 Epoch 21, Train Y Loss = 13.32190,  Train X Loss = 0.00000, Val Loss = 13.65036
2025-01-17 10:44:52.549439 Epoch 22, Train Y Loss = 13.15529,  Train X Loss = 0.00000, Val Loss = 13.60044
2025-01-17 10:45:26.991670 Epoch 23, Train Y Loss = 13.11091,  Train X Loss = 0.00000, Val Loss = 13.66557
2025-01-17 10:46:01.391383 Epoch 24, Train Y Loss = 13.05263,  Train X Loss = 0.00000, Val Loss = 13.52072
2025-01-17 10:46:35.716673 Epoch 25, Train Y Loss = 13.00948,  Train X Loss = 0.00000, Val Loss = 13.79421
2025-01-17 10:47:10.055086 Epoch 26, Train Y Loss = 12.93776,  Train X Loss = 0.00000, Val Loss = 13.47986
2025-01-17 10:47:44.498924 Epoch 27, Train Y Loss = 12.88490,  Train X Loss = 0.00000, Val Loss = 13.64139
2025-01-17 10:48:18.864292 Epoch 28, Train Y Loss = 12.84017,  Train X Loss = 0.00000, Val Loss = 13.48720
2025-01-17 10:48:53.125213 Epoch 29, Train Y Loss = 12.84226,  Train X Loss = 0.00000, Val Loss = 13.53113
2025-01-17 10:49:27.454741 Epoch 30, Train Y Loss = 12.74486,  Train X Loss = 0.00000, Val Loss = 13.60160
2025-01-17 10:50:01.849629 Epoch 31, Train Y Loss = 12.23161,  Train X Loss = 0.00000, Val Loss = 13.22054
2025-01-17 10:50:36.229968 Epoch 32, Train Y Loss = 12.14813,  Train X Loss = 0.00000, Val Loss = 13.22556
2025-01-17 10:51:10.478342 Epoch 33, Train Y Loss = 12.12162,  Train X Loss = 0.00000, Val Loss = 13.23762
2025-01-17 10:51:44.798512 Epoch 34, Train Y Loss = 12.10149,  Train X Loss = 0.00000, Val Loss = 13.22757
2025-01-17 10:52:19.175161 Epoch 35, Train Y Loss = 12.08569,  Train X Loss = 0.00000, Val Loss = 13.23277
2025-01-17 10:52:53.513201 Epoch 36, Train Y Loss = 12.06983,  Train X Loss = 0.00000, Val Loss = 13.28256
2025-01-17 10:53:27.756230 Epoch 37, Train Y Loss = 12.05685,  Train X Loss = 0.00000, Val Loss = 13.28736
2025-01-17 10:54:02.079670 Epoch 38, Train Y Loss = 12.04085,  Train X Loss = 0.00000, Val Loss = 13.26914
2025-01-17 10:54:36.488264 Epoch 39, Train Y Loss = 12.03132,  Train X Loss = 0.00000, Val Loss = 13.30104
2025-01-17 10:55:10.843287 Epoch 40, Train Y Loss = 12.01825,  Train X Loss = 0.00000, Val Loss = 13.30265
2025-01-17 10:55:45.140547 Epoch 41, Train Y Loss = 12.00574,  Train X Loss = 0.00000, Val Loss = 13.28523
2025-01-17 10:56:19.474355 Epoch 42, Train Y Loss = 11.99822,  Train X Loss = 0.00000, Val Loss = 13.31879
2025-01-17 10:56:53.881898 Epoch 43, Train Y Loss = 11.98731,  Train X Loss = 0.00000, Val Loss = 13.38545
2025-01-17 10:57:28.203870 Epoch 44, Train Y Loss = 11.98188,  Train X Loss = 0.00000, Val Loss = 13.35450
2025-01-17 10:58:02.498819 Epoch 45, Train Y Loss = 11.96946,  Train X Loss = 0.00000, Val Loss = 13.34207
2025-01-17 10:58:36.889913 Epoch 46, Train Y Loss = 11.96168,  Train X Loss = 0.00000, Val Loss = 13.33556
2025-01-17 10:59:11.345473 Epoch 47, Train Y Loss = 11.95235,  Train X Loss = 0.00000, Val Loss = 13.33715
2025-01-17 10:59:45.771275 Epoch 48, Train Y Loss = 11.94574,  Train X Loss = 0.00000, Val Loss = 13.44071
2025-01-17 11:00:20.156027 Epoch 49, Train Y Loss = 11.93817,  Train X Loss = 0.00000, Val Loss = 13.36683
2025-01-17 11:00:54.627089 Epoch 50, Train Y Loss = 11.92832,  Train X Loss = 0.00000, Val Loss = 13.38611
2025-01-17 11:01:29.093750 Epoch 51, Train Y Loss = 11.86565,  Train X Loss = 0.00000, Val Loss = 13.33917
2025-01-17 11:02:03.599380 Epoch 52, Train Y Loss = 11.85832,  Train X Loss = 0.00000, Val Loss = 13.34403
2025-01-17 11:02:37.961523 Epoch 53, Train Y Loss = 11.85607,  Train X Loss = 0.00000, Val Loss = 13.33262
2025-01-17 11:03:12.513539 Epoch 54, Train Y Loss = 11.85338,  Train X Loss = 0.00000, Val Loss = 13.34566
2025-01-17 11:03:47.007397 Epoch 55, Train Y Loss = 11.85172,  Train X Loss = 0.00000, Val Loss = 13.33122
2025-01-17 11:04:21.489993 Epoch 56, Train Y Loss = 11.85034,  Train X Loss = 0.00000, Val Loss = 13.34591
2025-01-17 11:04:55.873343 Epoch 57, Train Y Loss = 11.84824,  Train X Loss = 0.00000, Val Loss = 13.34749
2025-01-17 11:05:30.323668 Epoch 58, Train Y Loss = 11.84803,  Train X Loss = 0.00000, Val Loss = 13.35824
2025-01-17 11:06:04.784696 Epoch 59, Train Y Loss = 11.84559,  Train X Loss = 0.00000, Val Loss = 13.35314
2025-01-17 11:06:39.265957 Epoch 60, Train Y Loss = 11.84377,  Train X Loss = 0.00000, Val Loss = 13.34284
2025-01-17 11:07:13.694435 Epoch 61, Train Y Loss = 11.84396,  Train X Loss = 0.00000, Val Loss = 13.36144
Early stopping at epoch: 61
Best at epoch 31:
Train Loss = 12.23161
Train RMSE = 22.06461, MAE = 12.49802, MAPE = 8.24777
Val Loss = 13.22054
Val RMSE = 24.65890, MAE = 13.65036, MAPE = 10.43195
--------- Test ---------
All Steps RMSE = 23.30236, MAE = 13.46807, MAPE = 8.84216
Step 1 RMSE = 19.48197, MAE = 11.71493, MAPE = 7.72156
Step 2 RMSE = 20.55570, MAE = 12.16372, MAPE = 7.99615
Step 3 RMSE = 21.45266, MAE = 12.57797, MAPE = 8.24407
Step 4 RMSE = 22.19924, MAE = 12.91917, MAPE = 8.46425
Step 5 RMSE = 22.81068, MAE = 13.21316, MAPE = 8.64197
Step 6 RMSE = 23.40178, MAE = 13.50183, MAPE = 8.82711
Step 7 RMSE = 23.87897, MAE = 13.74315, MAPE = 8.98960
Step 8 RMSE = 24.30167, MAE = 13.95489, MAPE = 9.12529
Step 9 RMSE = 24.65845, MAE = 14.15037, MAPE = 9.28346
Step 10 RMSE = 25.01929, MAE = 14.34816, MAPE = 9.43468
Step 11 RMSE = 25.31359, MAE = 14.55094, MAPE = 9.60338
Step 12 RMSE = 25.63910, MAE = 14.77846, MAPE = 9.77447
Inference time: 3.31 s
