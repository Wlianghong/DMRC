PEMSBAY
--------- DMRCMLP ---------
{
    "num_nodes": 325,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.7,
    "val_size": 0.1,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        15,
        35
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 30,
    "use_cl": false,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 93048409,
    "gpu": [
        6
    ],
    "save": false,
    "model_args": {
        "num_nodes": 325,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        385,212
├─Linear: 1-1                                 [16, 12, 325, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 325, 48]         --
│    └─Embedding: 2-1                         [16, 12, 325, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 325, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 325, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 325, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 325, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 325, 144]        158,224
├─Predictor: 1-4                              [16, 12, 325, 1]          --
│    └─ModuleList: 2-5                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 325, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 325, 144]        41,760
│    └─Linear: 2-6                            [16, 325, 12]             20,748
===============================================================================================
Total params: 1,129,504
Trainable params: 1,129,504
Non-trainable params: 0
Total mult-adds (M): 11.91
===============================================================================================
Input size (MB): 0.75
Forward/backward pass size (MB): 2847.94
Params size (MB): 2.98
Estimated Total Size (MB): 2851.66
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMSBAY-2025-01-22-00-25-24.pt
2025-01-22 00:28:36.482157 Epoch 1, Train Y Loss = 1.99912,  Train X Loss = 0.00000, Val Loss = 1.85122
2025-01-22 00:31:49.341699 Epoch 2, Train Y Loss = 1.65285,  Train X Loss = 0.00000, Val Loss = 1.72349
2025-01-22 00:35:02.007992 Epoch 3, Train Y Loss = 1.58980,  Train X Loss = 0.00000, Val Loss = 1.72974
2025-01-22 00:38:14.676096 Epoch 4, Train Y Loss = 1.55638,  Train X Loss = 0.00000, Val Loss = 1.70996
2025-01-22 00:41:27.143339 Epoch 5, Train Y Loss = 1.52867,  Train X Loss = 0.00000, Val Loss = 1.66533
2025-01-22 00:44:39.374038 Epoch 6, Train Y Loss = 1.50342,  Train X Loss = 0.00000, Val Loss = 1.67632
2025-01-22 00:47:51.800021 Epoch 7, Train Y Loss = 1.48336,  Train X Loss = 0.00000, Val Loss = 1.61088
2025-01-22 00:51:04.262301 Epoch 8, Train Y Loss = 1.46667,  Train X Loss = 0.00000, Val Loss = 1.60003
2025-01-22 00:54:16.800466 Epoch 9, Train Y Loss = 1.45215,  Train X Loss = 0.00000, Val Loss = 1.59981
2025-01-22 00:57:29.183342 Epoch 10, Train Y Loss = 1.44019,  Train X Loss = 0.00000, Val Loss = 1.59989
2025-01-22 01:00:41.450568 Epoch 11, Train Y Loss = 1.43073,  Train X Loss = 0.00000, Val Loss = 1.60808
2025-01-22 01:03:53.802332 Epoch 12, Train Y Loss = 1.41969,  Train X Loss = 0.00000, Val Loss = 1.60033
2025-01-22 01:07:06.230835 Epoch 13, Train Y Loss = 1.41060,  Train X Loss = 0.00000, Val Loss = 1.58966
2025-01-22 01:10:18.721276 Epoch 14, Train Y Loss = 1.40198,  Train X Loss = 0.00000, Val Loss = 1.59557
2025-01-22 01:13:31.156289 Epoch 15, Train Y Loss = 1.39469,  Train X Loss = 0.00000, Val Loss = 1.57826
2025-01-22 01:16:43.432905 Epoch 16, Train Y Loss = 1.33679,  Train X Loss = 0.00000, Val Loss = 1.56294
2025-01-22 01:19:55.916748 Epoch 17, Train Y Loss = 1.32259,  Train X Loss = 0.00000, Val Loss = 1.55466
2025-01-22 01:23:08.308727 Epoch 18, Train Y Loss = 1.31532,  Train X Loss = 0.00000, Val Loss = 1.55631
2025-01-22 01:26:20.679862 Epoch 19, Train Y Loss = 1.30940,  Train X Loss = 0.00000, Val Loss = 1.56438
2025-01-22 01:29:33.077618 Epoch 20, Train Y Loss = 1.30418,  Train X Loss = 0.00000, Val Loss = 1.56393
2025-01-22 01:32:45.295224 Epoch 21, Train Y Loss = 1.29988,  Train X Loss = 0.00000, Val Loss = 1.56756
2025-01-22 01:35:57.513345 Epoch 22, Train Y Loss = 1.29547,  Train X Loss = 0.00000, Val Loss = 1.56408
2025-01-22 01:39:09.894528 Epoch 23, Train Y Loss = 1.29118,  Train X Loss = 0.00000, Val Loss = 1.56719
2025-01-22 01:42:22.331990 Epoch 24, Train Y Loss = 1.28731,  Train X Loss = 0.00000, Val Loss = 1.57516
2025-01-22 01:45:34.877171 Epoch 25, Train Y Loss = 1.28329,  Train X Loss = 0.00000, Val Loss = 1.57054
2025-01-22 01:48:47.305556 Epoch 26, Train Y Loss = 1.28039,  Train X Loss = 0.00000, Val Loss = 1.56851
2025-01-22 01:51:59.605426 Epoch 27, Train Y Loss = 1.27677,  Train X Loss = 0.00000, Val Loss = 1.57754
2025-01-22 01:55:11.907743 Epoch 28, Train Y Loss = 1.27303,  Train X Loss = 0.00000, Val Loss = 1.58076
2025-01-22 01:58:24.333632 Epoch 29, Train Y Loss = 1.27018,  Train X Loss = 0.00000, Val Loss = 1.58468
2025-01-22 02:01:36.938202 Epoch 30, Train Y Loss = 1.26651,  Train X Loss = 0.00000, Val Loss = 1.57719
2025-01-22 02:04:49.432772 Epoch 31, Train Y Loss = 1.26361,  Train X Loss = 0.00000, Val Loss = 1.58072
2025-01-22 02:08:01.787238 Epoch 32, Train Y Loss = 1.26092,  Train X Loss = 0.00000, Val Loss = 1.57737
2025-01-22 02:11:14.114582 Epoch 33, Train Y Loss = 1.25747,  Train X Loss = 0.00000, Val Loss = 1.58077
2025-01-22 02:14:26.556104 Epoch 34, Train Y Loss = 1.25466,  Train X Loss = 0.00000, Val Loss = 1.58641
2025-01-22 02:17:39.095636 Epoch 35, Train Y Loss = 1.25189,  Train X Loss = 0.00000, Val Loss = 1.58638
2025-01-22 02:20:51.800435 Epoch 36, Train Y Loss = 1.24036,  Train X Loss = 0.00000, Val Loss = 1.58587
2025-01-22 02:24:04.273215 Epoch 37, Train Y Loss = 1.23754,  Train X Loss = 0.00000, Val Loss = 1.58623
2025-01-22 02:27:16.643094 Epoch 38, Train Y Loss = 1.23731,  Train X Loss = 0.00000, Val Loss = 1.58758
2025-01-22 02:30:29.105940 Epoch 39, Train Y Loss = 1.23606,  Train X Loss = 0.00000, Val Loss = 1.58658
2025-01-22 02:33:41.714300 Epoch 40, Train Y Loss = 1.23619,  Train X Loss = 0.00000, Val Loss = 1.58604
2025-01-22 02:36:54.335133 Epoch 41, Train Y Loss = 1.23512,  Train X Loss = 0.00000, Val Loss = 1.58865
2025-01-22 02:40:06.882473 Epoch 42, Train Y Loss = 1.23434,  Train X Loss = 0.00000, Val Loss = 1.58860
2025-01-22 02:43:19.315237 Epoch 43, Train Y Loss = 1.23446,  Train X Loss = 0.00000, Val Loss = 1.58869
2025-01-22 02:46:31.766541 Epoch 44, Train Y Loss = 1.23321,  Train X Loss = 0.00000, Val Loss = 1.58875
2025-01-22 02:49:44.334095 Epoch 45, Train Y Loss = 1.23291,  Train X Loss = 0.00000, Val Loss = 1.58953
2025-01-22 02:52:56.998781 Epoch 46, Train Y Loss = 1.23247,  Train X Loss = 0.00000, Val Loss = 1.58861
2025-01-22 02:56:11.856115 Epoch 47, Train Y Loss = 1.23210,  Train X Loss = 0.00000, Val Loss = 1.58918
Early stopping at epoch: 47
Best at epoch 17:
Train Loss = 1.32259
Train RMSE = 2.89265, MAE = 1.29669, MAPE = 2.75887
Val Loss = 1.55466
Val RMSE = 3.61729, MAE = 1.55296, MAPE = 3.54153
--------- Test ---------
All Steps RMSE = 3.62774, MAE = 1.56208, MAPE = 3.53143
Step 1 RMSE = 1.63736, MAE = 0.86216, MAPE = 1.66472
Step 2 RMSE = 2.31089, MAE = 1.13545, MAPE = 2.30804
Step 3 RMSE = 2.82908, MAE = 1.31854, MAPE = 2.78911
Step 4 RMSE = 3.22441, MAE = 1.45180, MAPE = 3.16900
Step 5 RMSE = 3.51792, MAE = 1.55061, MAPE = 3.46309
Step 6 RMSE = 3.74269, MAE = 1.62811, MAPE = 3.69936
Step 7 RMSE = 3.91636, MAE = 1.69162, MAPE = 3.89241
Step 8 RMSE = 4.05167, MAE = 1.74295, MAPE = 4.05159
Step 9 RMSE = 4.16106, MAE = 1.78693, MAPE = 4.18296
Step 10 RMSE = 4.24751, MAE = 1.82527, MAPE = 4.29300
Step 11 RMSE = 4.32390, MAE = 1.85934, MAPE = 4.38839
Step 12 RMSE = 4.39489, MAE = 1.89212, MAPE = 4.47557
Inference time: 18.29 s
