PEMS07
--------- DMRCMLP ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.001,
    "milestones": [
        20,
        40,
        55
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 25,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 6,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 93048409,
    "gpu": [
        4,
        5
    ],
    "save": false,
    "model_args": {
        "num_nodes": 883,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        888,204
├─Linear: 1-1                                 [16, 12, 883, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 883, 48]         --
│    └─Embedding: 2-1                         [16, 12, 883, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 883, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 883, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 883, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 883, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 883, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 883, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 883, 144]        158,224
├─Predictor: 1-4                              [16, 12, 883, 1]          --
│    └─Linear: 2-5                            [16, 12, 883, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 883, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 883, 144]        41,760
│    └─Linear: 2-7                            [16, 883, 12]             20,748
===============================================================================================
Total params: 1,653,376
Trainable params: 1,653,376
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 2.03
Forward/backward pass size (MB): 7932.93
Params size (MB): 3.06
Estimated Total Size (MB): 7938.02
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS07-2025-01-19-02-51-26.pt
2025-01-19 02:55:46.887567 Epoch 1, Train Y Loss = 31.10439,  Train X Loss = 22.25420, Val Loss = 25.72382
2025-01-19 03:00:05.999430 Epoch 2, Train Y Loss = 24.39041,  Train X Loss = 17.63486, Val Loss = 22.54618
2025-01-19 03:04:22.517611 Epoch 3, Train Y Loss = 22.87278,  Train X Loss = 17.15448, Val Loss = 22.73996
2025-01-19 03:08:36.411555 Epoch 4, Train Y Loss = 21.94018,  Train X Loss = 16.51270, Val Loss = 21.60005
2025-01-19 03:12:51.508463 Epoch 5, Train Y Loss = 21.55457,  Train X Loss = 13.56703, Val Loss = 21.74380
2025-01-19 03:17:05.816197 Epoch 6, Train Y Loss = 20.95431,  Train X Loss = 12.29384, Val Loss = 21.21980
2025-01-19 03:21:20.571613 Epoch 7, Train Y Loss = 20.62787,  Train X Loss = 11.92575, Val Loss = 20.22087
2025-01-19 03:25:35.766560 Epoch 8, Train Y Loss = 20.31175,  Train X Loss = 11.72713, Val Loss = 19.93796
2025-01-19 03:29:53.012936 Epoch 9, Train Y Loss = 20.08752,  Train X Loss = 11.51368, Val Loss = 20.42623
2025-01-19 03:34:10.996360 Epoch 10, Train Y Loss = 19.91233,  Train X Loss = 11.44589, Val Loss = 19.96282
2025-01-19 03:38:27.385856 Epoch 11, Train Y Loss = 19.66202,  Train X Loss = 11.24724, Val Loss = 19.86266
2025-01-19 03:42:50.772041 Epoch 12, Train Y Loss = 19.51958,  Train X Loss = 11.15946, Val Loss = 19.73987
2025-01-19 03:47:13.867903 Epoch 13, Train Y Loss = 19.40249,  Train X Loss = 11.12637, Val Loss = 19.77626
2025-01-19 03:51:36.476118 Epoch 14, Train Y Loss = 19.23278,  Train X Loss = 10.98329, Val Loss = 19.71152
2025-01-19 03:55:58.868339 Epoch 15, Train Y Loss = 19.18575,  Train X Loss = 10.99541, Val Loss = 19.57530
2025-01-19 04:00:21.931489 Epoch 16, Train Y Loss = 19.05640,  Train X Loss = 10.90516, Val Loss = 19.44435
2025-01-19 04:04:45.060965 Epoch 17, Train Y Loss = 18.94204,  Train X Loss = 10.82370, Val Loss = 19.30057
2025-01-19 04:09:08.261134 Epoch 18, Train Y Loss = 18.89806,  Train X Loss = 10.81501, Val Loss = 19.26629
2025-01-19 04:13:28.341312 Epoch 19, Train Y Loss = 18.81959,  Train X Loss = 10.73523, Val Loss = 19.12966
2025-01-19 04:17:52.428665 Epoch 20, Train Y Loss = 18.74821,  Train X Loss = 10.65481, Val Loss = 19.29478
2025-01-19 04:22:19.158683 Epoch 21, Train Y Loss = 17.96058,  Train X Loss = 10.28520, Val Loss = 18.66635
2025-01-19 04:26:43.682810 Epoch 22, Train Y Loss = 17.85174,  Train X Loss = 10.24628, Val Loss = 18.61801
2025-01-19 04:31:09.086903 Epoch 23, Train Y Loss = 17.81274,  Train X Loss = 10.22849, Val Loss = 18.59647
2025-01-19 04:35:34.794457 Epoch 24, Train Y Loss = 17.77873,  Train X Loss = 10.20901, Val Loss = 18.48784
2025-01-19 04:39:59.503197 Epoch 25, Train Y Loss = 17.75112,  Train X Loss = 10.19706, Val Loss = 18.49394
2025-01-19 04:44:24.311739 Epoch 26, Train Y Loss = 17.72052,  Train X Loss = 10.18614, Val Loss = 18.44530
2025-01-19 04:48:42.352033 Epoch 27, Train Y Loss = 17.69383,  Train X Loss = 10.18250, Val Loss = 18.49642
2025-01-19 04:52:59.190259 Epoch 28, Train Y Loss = 17.66965,  Train X Loss = 10.16903, Val Loss = 18.42393
2025-01-19 04:57:14.207614 Epoch 29, Train Y Loss = 17.64340,  Train X Loss = 10.16208, Val Loss = 18.46525
2025-01-19 05:01:28.700926 Epoch 30, Train Y Loss = 17.62544,  Train X Loss = 10.15232, Val Loss = 18.39306
2025-01-19 05:05:43.409221 Epoch 31, Train Y Loss = 17.60429,  Train X Loss = 10.14912, Val Loss = 18.44229
2025-01-19 05:09:59.720708 Epoch 32, Train Y Loss = 17.58818,  Train X Loss = 10.14518, Val Loss = 18.39789
2025-01-19 05:14:14.987682 Epoch 33, Train Y Loss = 17.55851,  Train X Loss = 10.13437, Val Loss = 18.39612
2025-01-19 05:18:30.901531 Epoch 34, Train Y Loss = 17.54071,  Train X Loss = 10.12988, Val Loss = 18.27340
2025-01-19 05:22:45.541683 Epoch 35, Train Y Loss = 17.51955,  Train X Loss = 10.12407, Val Loss = 18.30203
2025-01-19 05:27:00.987574 Epoch 36, Train Y Loss = 17.49655,  Train X Loss = 10.11851, Val Loss = 18.38377
2025-01-19 05:31:15.583625 Epoch 37, Train Y Loss = 17.47688,  Train X Loss = 10.11555, Val Loss = 18.27594
2025-01-19 05:35:29.855730 Epoch 38, Train Y Loss = 17.45926,  Train X Loss = 10.10918, Val Loss = 18.31932
2025-01-19 05:39:44.397807 Epoch 39, Train Y Loss = 17.44353,  Train X Loss = 10.10846, Val Loss = 18.33692
2025-01-19 05:43:59.909495 Epoch 40, Train Y Loss = 17.42422,  Train X Loss = 10.10518, Val Loss = 18.28192
2025-01-19 05:48:14.787745 Epoch 41, Train Y Loss = 17.31674,  Train X Loss = 10.07243, Val Loss = 18.22865
2025-01-19 05:52:29.510951 Epoch 42, Train Y Loss = 17.30229,  Train X Loss = 10.06797, Val Loss = 18.24726
2025-01-19 05:56:43.898392 Epoch 43, Train Y Loss = 17.30000,  Train X Loss = 10.06713, Val Loss = 18.24559
2025-01-19 06:00:59.208323 Epoch 44, Train Y Loss = 17.29440,  Train X Loss = 10.06421, Val Loss = 18.25223
2025-01-19 06:05:13.882636 Epoch 45, Train Y Loss = 17.29204,  Train X Loss = 10.06308, Val Loss = 18.26238
2025-01-19 06:09:28.783318 Epoch 46, Train Y Loss = 17.28920,  Train X Loss = 10.05930, Val Loss = 18.24925
2025-01-19 06:13:43.770872 Epoch 47, Train Y Loss = 17.28545,  Train X Loss = 10.06334, Val Loss = 18.23913
2025-01-19 06:17:58.752736 Epoch 48, Train Y Loss = 17.28276,  Train X Loss = 10.06164, Val Loss = 18.23951
2025-01-19 06:22:13.591325 Epoch 49, Train Y Loss = 17.27945,  Train X Loss = 10.06253, Val Loss = 18.22141
2025-01-19 06:26:28.605247 Epoch 50, Train Y Loss = 17.27620,  Train X Loss = 10.05586, Val Loss = 18.20770
2025-01-19 06:30:42.068830 Epoch 51, Train Y Loss = 17.27391,  Train X Loss = 10.05747, Val Loss = 18.25799
2025-01-19 06:34:56.463804 Epoch 52, Train Y Loss = 17.27037,  Train X Loss = 10.05478, Val Loss = 18.24659
2025-01-19 06:39:11.618734 Epoch 53, Train Y Loss = 17.26937,  Train X Loss = 10.05849, Val Loss = 18.26462
2025-01-19 06:43:27.281291 Epoch 54, Train Y Loss = 17.26677,  Train X Loss = 10.05295, Val Loss = 18.23074
2025-01-19 06:47:42.034245 Epoch 55, Train Y Loss = 17.26413,  Train X Loss = 10.05517, Val Loss = 18.25175
2025-01-19 06:51:55.800512 Epoch 56, Train Y Loss = 17.25204,  Train X Loss = 10.05759, Val Loss = 18.24187
2025-01-19 06:56:10.382093 Epoch 57, Train Y Loss = 17.24850,  Train X Loss = 10.05418, Val Loss = 18.23988
2025-01-19 07:00:24.463619 Epoch 58, Train Y Loss = 17.24876,  Train X Loss = 10.05267, Val Loss = 18.23915
2025-01-19 07:04:40.066614 Epoch 59, Train Y Loss = 17.24781,  Train X Loss = 10.05234, Val Loss = 18.24199
2025-01-19 07:08:56.498139 Epoch 60, Train Y Loss = 17.24912,  Train X Loss = 10.05498, Val Loss = 18.24624
2025-01-19 07:13:10.626524 Epoch 61, Train Y Loss = 17.24894,  Train X Loss = 10.04816, Val Loss = 18.24583
2025-01-19 07:17:24.762420 Epoch 62, Train Y Loss = 17.24850,  Train X Loss = 10.05099, Val Loss = 18.24179
2025-01-19 07:21:38.250327 Epoch 63, Train Y Loss = 17.24710,  Train X Loss = 10.04884, Val Loss = 18.24066
2025-01-19 07:25:52.396920 Epoch 64, Train Y Loss = 17.24613,  Train X Loss = 10.05026, Val Loss = 18.24619
2025-01-19 07:30:09.581367 Epoch 65, Train Y Loss = 17.24592,  Train X Loss = 10.04667, Val Loss = 18.24836
2025-01-19 07:34:25.055474 Epoch 66, Train Y Loss = 17.24515,  Train X Loss = 10.05635, Val Loss = 18.24913
2025-01-19 07:38:38.832360 Epoch 67, Train Y Loss = 17.24559,  Train X Loss = 10.04430, Val Loss = 18.24615
2025-01-19 07:42:54.790770 Epoch 68, Train Y Loss = 17.24375,  Train X Loss = 10.05437, Val Loss = 18.23935
2025-01-19 07:47:12.744624 Epoch 69, Train Y Loss = 17.24633,  Train X Loss = 10.05060, Val Loss = 18.24549
2025-01-19 07:51:26.925660 Epoch 70, Train Y Loss = 17.24449,  Train X Loss = 10.04698, Val Loss = 18.24460
2025-01-19 07:55:39.117918 Epoch 71, Train Y Loss = 17.24489,  Train X Loss = 10.05250, Val Loss = 18.24512
2025-01-19 07:59:54.336726 Epoch 72, Train Y Loss = 17.24435,  Train X Loss = 10.05043, Val Loss = 18.24042
2025-01-19 08:04:08.068051 Epoch 73, Train Y Loss = 17.24353,  Train X Loss = 10.05358, Val Loss = 18.24745
2025-01-19 08:08:22.541088 Epoch 74, Train Y Loss = 17.24272,  Train X Loss = 10.05513, Val Loss = 18.24521
2025-01-19 08:12:36.581558 Epoch 75, Train Y Loss = 17.24536,  Train X Loss = 10.04988, Val Loss = 18.24571
Early stopping at epoch: 75
Best at epoch 50:
Train Loss = 17.27620
Train RMSE = 30.23200, MAE = 17.71396, MAPE = 7.76408
Val Loss = 18.20770
Val RMSE = 31.84679, MAE = 18.73483, MAPE = 8.21306
--------- Test ---------
All Steps RMSE = 32.53222, MAE = 19.33615, MAPE = 8.01762
Step 1 RMSE = 26.50292, MAE = 16.23976, MAPE = 6.79772
Step 2 RMSE = 28.68548, MAE = 17.26984, MAPE = 7.20858
Step 3 RMSE = 29.99895, MAE = 17.94210, MAPE = 7.47267
Step 4 RMSE = 31.00656, MAE = 18.47576, MAPE = 7.67956
Step 5 RMSE = 31.85590, MAE = 18.93111, MAPE = 7.85334
Step 6 RMSE = 32.60656, MAE = 19.35752, MAPE = 8.01630
Step 7 RMSE = 33.27653, MAE = 19.73475, MAPE = 8.16073
Step 8 RMSE = 33.89710, MAE = 20.09288, MAPE = 8.29377
Step 9 RMSE = 34.46283, MAE = 20.44339, MAPE = 8.43233
Step 10 RMSE = 34.99040, MAE = 20.78426, MAPE = 8.58526
Step 11 RMSE = 35.53605, MAE = 21.16319, MAPE = 8.74936
Step 12 RMSE = 36.11410, MAE = 21.59631, MAPE = 8.96065
Inference time: 28.98 s
