PEMS04
--------- DMRCMLP ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        55
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        1
    ],
    "save": false,
    "model_args": {
        "num_nodes": 307,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        390,540
├─Linear: 1-1                                 [16, 12, 307, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 307, 48]         --
│    └─Embedding: 2-1                         [16, 12, 307, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 307, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 307, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 307, 144]        158,224
├─Predictor: 1-4                              [16, 12, 307, 1]          --
│    └─Linear: 2-5                            [16, 12, 307, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 307, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 307, 144]        41,760
│    └─Linear: 2-7                            [16, 307, 12]             20,748
===============================================================================================
Total params: 1,155,712
Trainable params: 1,155,712
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.71
Forward/backward pass size (MB): 2758.11
Params size (MB): 3.06
Estimated Total Size (MB): 2761.88
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS04-2025-01-17-06-53-17.pt
2025-01-17 06:54:33.267697 Epoch 1, Train Y Loss = 28.76630,  Train X Loss = 21.94544, Val Loss = 25.28712
2025-01-17 06:55:49.178004 Epoch 2, Train Y Loss = 22.83469,  Train X Loss = 17.58507, Val Loss = 22.96979
2025-01-17 06:57:04.954349 Epoch 3, Train Y Loss = 21.21257,  Train X Loss = 17.01567, Val Loss = 21.14137
2025-01-17 06:58:20.824843 Epoch 4, Train Y Loss = 20.29081,  Train X Loss = 16.61273, Val Loss = 20.18808
2025-01-17 06:59:36.783834 Epoch 5, Train Y Loss = 19.75170,  Train X Loss = 16.48723, Val Loss = 20.49210
2025-01-17 07:00:52.723652 Epoch 6, Train Y Loss = 19.30145,  Train X Loss = 16.32225, Val Loss = 19.79375
2025-01-17 07:02:08.684106 Epoch 7, Train Y Loss = 18.90508,  Train X Loss = 16.14455, Val Loss = 19.45956
2025-01-17 07:03:24.738236 Epoch 8, Train Y Loss = 18.63491,  Train X Loss = 16.02647, Val Loss = 19.29429
2025-01-17 07:04:40.877797 Epoch 9, Train Y Loss = 18.49494,  Train X Loss = 16.11993, Val Loss = 19.58281
2025-01-17 07:05:56.875090 Epoch 10, Train Y Loss = 18.29769,  Train X Loss = 15.80849, Val Loss = 19.19787
2025-01-17 07:07:12.992169 Epoch 11, Train Y Loss = 18.12892,  Train X Loss = 15.70599, Val Loss = 18.50643
2025-01-17 07:08:29.059141 Epoch 12, Train Y Loss = 17.92329,  Train X Loss = 15.65953, Val Loss = 19.02464
2025-01-17 07:09:45.146693 Epoch 13, Train Y Loss = 17.87823,  Train X Loss = 15.57929, Val Loss = 19.04843
2025-01-17 07:11:01.281600 Epoch 14, Train Y Loss = 17.73015,  Train X Loss = 15.49358, Val Loss = 18.48191
2025-01-17 07:12:17.203061 Epoch 15, Train Y Loss = 17.59810,  Train X Loss = 15.42862, Val Loss = 18.21580
2025-01-17 07:13:33.219182 Epoch 16, Train Y Loss = 17.56537,  Train X Loss = 15.37913, Val Loss = 18.68651
2025-01-17 07:14:49.089923 Epoch 17, Train Y Loss = 17.37699,  Train X Loss = 15.27698, Val Loss = 18.25814
2025-01-17 07:16:05.104366 Epoch 18, Train Y Loss = 17.35973,  Train X Loss = 15.26235, Val Loss = 19.26501
2025-01-17 07:17:21.007669 Epoch 19, Train Y Loss = 17.31580,  Train X Loss = 15.18049, Val Loss = 18.24225
2025-01-17 07:18:36.894227 Epoch 20, Train Y Loss = 17.21999,  Train X Loss = 15.16076, Val Loss = 18.14631
2025-01-17 07:19:52.934599 Epoch 21, Train Y Loss = 16.58420,  Train X Loss = 14.82346, Val Loss = 17.57691
2025-01-17 07:21:08.798272 Epoch 22, Train Y Loss = 16.49950,  Train X Loss = 14.77803, Val Loss = 17.59911
2025-01-17 07:22:24.744981 Epoch 23, Train Y Loss = 16.46449,  Train X Loss = 14.75791, Val Loss = 17.56699
2025-01-17 07:23:40.636522 Epoch 24, Train Y Loss = 16.44753,  Train X Loss = 14.75645, Val Loss = 17.57318
2025-01-17 07:24:56.610974 Epoch 25, Train Y Loss = 16.41959,  Train X Loss = 14.73730, Val Loss = 17.58640
2025-01-17 07:26:12.498948 Epoch 26, Train Y Loss = 16.40248,  Train X Loss = 14.72460, Val Loss = 17.57555
2025-01-17 07:27:28.506268 Epoch 27, Train Y Loss = 16.37957,  Train X Loss = 14.69796, Val Loss = 17.53810
2025-01-17 07:28:44.424462 Epoch 28, Train Y Loss = 16.36335,  Train X Loss = 14.70415, Val Loss = 17.55059
2025-01-17 07:30:00.271484 Epoch 29, Train Y Loss = 16.34974,  Train X Loss = 14.69750, Val Loss = 17.53095
2025-01-17 07:31:16.265875 Epoch 30, Train Y Loss = 16.33002,  Train X Loss = 14.68433, Val Loss = 17.59340
2025-01-17 07:32:32.130533 Epoch 31, Train Y Loss = 16.30576,  Train X Loss = 14.67240, Val Loss = 17.54907
2025-01-17 07:33:48.117397 Epoch 32, Train Y Loss = 16.28693,  Train X Loss = 14.65390, Val Loss = 17.50119
2025-01-17 07:35:03.981779 Epoch 33, Train Y Loss = 16.27285,  Train X Loss = 14.65900, Val Loss = 17.51663
2025-01-17 07:36:19.925656 Epoch 34, Train Y Loss = 16.26677,  Train X Loss = 14.65534, Val Loss = 17.50755
2025-01-17 07:37:35.820013 Epoch 35, Train Y Loss = 16.25201,  Train X Loss = 14.64269, Val Loss = 17.59394
2025-01-17 07:38:51.816578 Epoch 36, Train Y Loss = 16.17542,  Train X Loss = 14.60440, Val Loss = 17.47760
2025-01-17 07:40:07.814638 Epoch 37, Train Y Loss = 16.16603,  Train X Loss = 14.60162, Val Loss = 17.49955
2025-01-17 07:41:23.773068 Epoch 38, Train Y Loss = 16.15938,  Train X Loss = 14.60275, Val Loss = 17.48460
2025-01-17 07:42:39.914480 Epoch 39, Train Y Loss = 16.16097,  Train X Loss = 14.60639, Val Loss = 17.46154
2025-01-17 07:43:55.828926 Epoch 40, Train Y Loss = 16.15743,  Train X Loss = 14.59218, Val Loss = 17.47359
2025-01-17 07:45:11.830611 Epoch 41, Train Y Loss = 16.15226,  Train X Loss = 14.58775, Val Loss = 17.48770
2025-01-17 07:46:27.765920 Epoch 42, Train Y Loss = 16.14980,  Train X Loss = 14.59733, Val Loss = 17.46775
2025-01-17 07:47:43.859229 Epoch 43, Train Y Loss = 16.15386,  Train X Loss = 14.59111, Val Loss = 17.49260
2025-01-17 07:48:59.708111 Epoch 44, Train Y Loss = 16.14722,  Train X Loss = 14.59910, Val Loss = 17.47791
2025-01-17 07:50:15.596260 Epoch 45, Train Y Loss = 16.14372,  Train X Loss = 14.57888, Val Loss = 17.47507
2025-01-17 07:51:31.516614 Epoch 46, Train Y Loss = 16.13919,  Train X Loss = 14.58162, Val Loss = 17.49627
2025-01-17 07:52:47.323912 Epoch 47, Train Y Loss = 16.13746,  Train X Loss = 14.58937, Val Loss = 17.47065
2025-01-17 07:54:03.103860 Epoch 48, Train Y Loss = 16.13562,  Train X Loss = 14.57113, Val Loss = 17.48544
2025-01-17 07:55:18.744945 Epoch 49, Train Y Loss = 16.13160,  Train X Loss = 14.57639, Val Loss = 17.46810
2025-01-17 07:56:34.496355 Epoch 50, Train Y Loss = 16.13841,  Train X Loss = 14.58381, Val Loss = 17.48334
2025-01-17 07:57:50.151670 Epoch 51, Train Y Loss = 16.12669,  Train X Loss = 14.57414, Val Loss = 17.49123
2025-01-17 07:59:05.792276 Epoch 52, Train Y Loss = 16.12633,  Train X Loss = 14.56960, Val Loss = 17.48487
2025-01-17 08:00:21.548956 Epoch 53, Train Y Loss = 16.12677,  Train X Loss = 14.58637, Val Loss = 17.49876
2025-01-17 08:01:37.124502 Epoch 54, Train Y Loss = 16.12917,  Train X Loss = 14.57859, Val Loss = 17.46431
2025-01-17 08:02:52.809127 Epoch 55, Train Y Loss = 16.12666,  Train X Loss = 14.58267, Val Loss = 17.48413
2025-01-17 08:04:08.389698 Epoch 56, Train Y Loss = 16.11641,  Train X Loss = 14.56735, Val Loss = 17.47848
2025-01-17 08:05:24.038294 Epoch 57, Train Y Loss = 16.11783,  Train X Loss = 14.56231, Val Loss = 17.47921
2025-01-17 08:06:39.614118 Epoch 58, Train Y Loss = 16.12075,  Train X Loss = 14.57438, Val Loss = 17.47375
2025-01-17 08:07:55.209259 Epoch 59, Train Y Loss = 16.11497,  Train X Loss = 14.57371, Val Loss = 17.47597
2025-01-17 08:09:10.865817 Epoch 60, Train Y Loss = 16.11473,  Train X Loss = 14.57518, Val Loss = 17.47340
2025-01-17 08:10:26.446266 Epoch 61, Train Y Loss = 16.11487,  Train X Loss = 14.57298, Val Loss = 17.47616
2025-01-17 08:11:42.262702 Epoch 62, Train Y Loss = 16.11668,  Train X Loss = 14.57495, Val Loss = 17.48092
2025-01-17 08:12:58.106214 Epoch 63, Train Y Loss = 16.10829,  Train X Loss = 14.57746, Val Loss = 17.47843
2025-01-17 08:14:13.961986 Epoch 64, Train Y Loss = 16.11023,  Train X Loss = 14.56696, Val Loss = 17.47690
2025-01-17 08:15:29.724894 Epoch 65, Train Y Loss = 16.11140,  Train X Loss = 14.56818, Val Loss = 17.48145
2025-01-17 08:16:45.334357 Epoch 66, Train Y Loss = 16.10740,  Train X Loss = 14.57415, Val Loss = 17.47275
2025-01-17 08:18:00.847086 Epoch 67, Train Y Loss = 16.11473,  Train X Loss = 14.58536, Val Loss = 17.48495
2025-01-17 08:19:16.519205 Epoch 68, Train Y Loss = 16.11314,  Train X Loss = 14.58233, Val Loss = 17.47977
2025-01-17 08:20:32.334642 Epoch 69, Train Y Loss = 16.11371,  Train X Loss = 14.57367, Val Loss = 17.48180
Early stopping at epoch: 69
Best at epoch 39:
Train Loss = 16.16097
Train RMSE = 27.70456, MAE = 16.59889, MAPE = 11.85637
Val Loss = 17.46154
Val RMSE = 30.46539, MAE = 18.14579, MAPE = 11.74072
--------- Test ---------
All Steps RMSE = 30.67926, MAE = 18.29226, MAPE = 12.11349
Step 1 RMSE = 26.77298, MAE = 16.41437, MAPE = 10.85474
Step 2 RMSE = 27.99932, MAE = 17.01460, MAPE = 11.32027
Step 3 RMSE = 28.98745, MAE = 17.48294, MAPE = 11.62745
Step 4 RMSE = 29.74247, MAE = 17.83088, MAPE = 11.85859
Step 5 RMSE = 30.36129, MAE = 18.11616, MAPE = 12.00919
Step 6 RMSE = 30.84616, MAE = 18.34795, MAPE = 12.12990
Step 7 RMSE = 31.29385, MAE = 18.57215, MAPE = 12.28731
Step 8 RMSE = 31.66874, MAE = 18.76542, MAPE = 12.40812
Step 9 RMSE = 32.01096, MAE = 18.95447, MAPE = 12.52312
Step 10 RMSE = 32.30928, MAE = 19.14085, MAPE = 12.64849
Step 11 RMSE = 32.59835, MAE = 19.33039, MAPE = 12.77570
Step 12 RMSE = 32.89664, MAE = 19.53686, MAPE = 12.91873
Inference time: 6.02 s
