PEMS08
--------- DMRCMLP ---------
{
    "num_nodes": 170,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0015,
    "milestones": [
        30,
        50,
        70
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 51970489,
    "gpu": [
        2
    ],
    "save": true,
    "model_args": {
        "num_nodes": 170,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.15,
        "use_recon": true,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        272,172
├─Linear: 1-1                                 [16, 12, 170, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 170, 48]         --
│    └─Embedding: 2-1                         [16, 12, 170, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 170, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 170, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 170, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 170, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 170, 144]        158,224
├─Predictor: 1-4                              [16, 12, 170, 1]          --
│    └─Linear: 2-5                            [16, 12, 170, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 170, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 170, 144]        41,760
│    └─Linear: 2-7                            [16, 170, 12]             20,748
===============================================================================================
Total params: 1,037,344
Trainable params: 1,037,344
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.39
Forward/backward pass size (MB): 1527.29
Params size (MB): 3.06
Estimated Total Size (MB): 1530.74
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS08-2025-01-16-21-31-07.pt
2025-01-16 21:31:46.050300 Epoch 1, Train Y Loss = 24.35494,  Train X Loss = 18.98562, Val Loss = 19.21933
2025-01-16 21:32:24.946691 Epoch 2, Train Y Loss = 18.61485,  Train X Loss = 14.24819, Val Loss = 19.32192
2025-01-16 21:33:03.809497 Epoch 3, Train Y Loss = 17.60806,  Train X Loss = 13.68438, Val Loss = 17.25513
2025-01-16 21:33:42.682489 Epoch 4, Train Y Loss = 16.85332,  Train X Loss = 13.16377, Val Loss = 16.24739
2025-01-16 21:34:21.592812 Epoch 5, Train Y Loss = 16.42186,  Train X Loss = 12.84699, Val Loss = 15.89547
2025-01-16 21:35:00.463675 Epoch 6, Train Y Loss = 15.91868,  Train X Loss = 12.58063, Val Loss = 16.01494
2025-01-16 21:35:39.218465 Epoch 7, Train Y Loss = 15.54521,  Train X Loss = 12.46983, Val Loss = 15.21559
2025-01-16 21:36:18.119689 Epoch 8, Train Y Loss = 15.29626,  Train X Loss = 12.38121, Val Loss = 15.27202
2025-01-16 21:36:57.020165 Epoch 9, Train Y Loss = 15.04108,  Train X Loss = 12.25939, Val Loss = 14.81628
2025-01-16 21:37:35.934283 Epoch 10, Train Y Loss = 14.88832,  Train X Loss = 12.19577, Val Loss = 15.03806
2025-01-16 21:38:14.818780 Epoch 11, Train Y Loss = 14.67782,  Train X Loss = 12.08365, Val Loss = 14.55826
2025-01-16 21:38:53.724925 Epoch 12, Train Y Loss = 14.58075,  Train X Loss = 11.95728, Val Loss = 14.73908
2025-01-16 21:39:32.630312 Epoch 13, Train Y Loss = 14.38466,  Train X Loss = 11.90027, Val Loss = 14.20506
2025-01-16 21:40:11.527377 Epoch 14, Train Y Loss = 14.29281,  Train X Loss = 11.86822, Val Loss = 14.28663
2025-01-16 21:40:50.471077 Epoch 15, Train Y Loss = 14.08654,  Train X Loss = 11.81560, Val Loss = 13.98968
2025-01-16 21:41:29.224704 Epoch 16, Train Y Loss = 13.99465,  Train X Loss = 11.75104, Val Loss = 13.82571
2025-01-16 21:42:08.132833 Epoch 17, Train Y Loss = 13.85917,  Train X Loss = 11.71801, Val Loss = 13.85676
2025-01-16 21:42:47.036710 Epoch 18, Train Y Loss = 13.76755,  Train X Loss = 11.64187, Val Loss = 13.64200
2025-01-16 21:43:25.950886 Epoch 19, Train Y Loss = 13.71740,  Train X Loss = 11.61811, Val Loss = 13.99624
2025-01-16 21:44:04.855097 Epoch 20, Train Y Loss = 13.64726,  Train X Loss = 11.55995, Val Loss = 13.89263
2025-01-16 21:44:43.727145 Epoch 21, Train Y Loss = 13.60163,  Train X Loss = 11.56383, Val Loss = 13.66515
2025-01-16 21:45:22.613120 Epoch 22, Train Y Loss = 13.56610,  Train X Loss = 11.44798, Val Loss = 13.65646
2025-01-16 21:46:01.533712 Epoch 23, Train Y Loss = 13.48090,  Train X Loss = 11.43339, Val Loss = 13.73744
2025-01-16 21:46:40.442711 Epoch 24, Train Y Loss = 13.48647,  Train X Loss = 11.44293, Val Loss = 13.60512
2025-01-16 21:47:19.126628 Epoch 25, Train Y Loss = 13.38636,  Train X Loss = 11.35587, Val Loss = 13.50054
2025-01-16 21:47:58.012221 Epoch 26, Train Y Loss = 13.37784,  Train X Loss = 11.38168, Val Loss = 13.43969
2025-01-16 21:48:36.939295 Epoch 27, Train Y Loss = 13.33994,  Train X Loss = 11.34257, Val Loss = 13.60063
2025-01-16 21:49:15.841867 Epoch 28, Train Y Loss = 13.30659,  Train X Loss = 11.33066, Val Loss = 13.49331
2025-01-16 21:49:55.378022 Epoch 29, Train Y Loss = 13.27435,  Train X Loss = 11.31365, Val Loss = 13.66157
2025-01-16 21:50:43.406254 Epoch 30, Train Y Loss = 13.25380,  Train X Loss = 11.25485, Val Loss = 13.35944
2025-01-16 21:51:31.488420 Epoch 31, Train Y Loss = 12.67818,  Train X Loss = 11.00191, Val Loss = 12.94735
2025-01-16 21:52:22.401110 Epoch 32, Train Y Loss = 12.58923,  Train X Loss = 10.96691, Val Loss = 12.92325
2025-01-16 21:53:10.318058 Epoch 33, Train Y Loss = 12.56648,  Train X Loss = 10.94584, Val Loss = 12.90519
2025-01-16 21:54:01.132964 Epoch 34, Train Y Loss = 12.54842,  Train X Loss = 10.93558, Val Loss = 12.92978
2025-01-16 21:54:48.939038 Epoch 35, Train Y Loss = 12.53470,  Train X Loss = 10.93032, Val Loss = 12.92124
2025-01-16 21:55:36.515010 Epoch 36, Train Y Loss = 12.51972,  Train X Loss = 10.91058, Val Loss = 12.96629
2025-01-16 21:56:24.025857 Epoch 37, Train Y Loss = 12.50851,  Train X Loss = 10.92781, Val Loss = 12.95609
2025-01-16 21:57:14.893943 Epoch 38, Train Y Loss = 12.49685,  Train X Loss = 10.90925, Val Loss = 12.95109
2025-01-16 21:58:02.772513 Epoch 39, Train Y Loss = 12.48639,  Train X Loss = 10.89954, Val Loss = 12.92180
2025-01-16 21:58:50.764493 Epoch 40, Train Y Loss = 12.47507,  Train X Loss = 10.88820, Val Loss = 12.93216
2025-01-16 21:59:41.253475 Epoch 41, Train Y Loss = 12.46800,  Train X Loss = 10.89127, Val Loss = 12.92612
2025-01-16 22:00:30.019799 Epoch 42, Train Y Loss = 12.46216,  Train X Loss = 10.88372, Val Loss = 12.95649
2025-01-16 22:01:19.338849 Epoch 43, Train Y Loss = 12.45213,  Train X Loss = 10.88275, Val Loss = 12.95369
2025-01-16 22:02:10.236314 Epoch 44, Train Y Loss = 12.44428,  Train X Loss = 10.86879, Val Loss = 12.97174
2025-01-16 22:02:58.230484 Epoch 45, Train Y Loss = 12.43661,  Train X Loss = 10.85791, Val Loss = 12.96355
2025-01-16 22:03:46.455195 Epoch 46, Train Y Loss = 12.43088,  Train X Loss = 10.84871, Val Loss = 12.91929
2025-01-16 22:04:34.921528 Epoch 47, Train Y Loss = 12.42115,  Train X Loss = 10.82834, Val Loss = 12.97561
2025-01-16 22:05:22.828755 Epoch 48, Train Y Loss = 12.41559,  Train X Loss = 10.82373, Val Loss = 12.92287
2025-01-16 22:06:11.151574 Epoch 49, Train Y Loss = 12.41172,  Train X Loss = 10.80448, Val Loss = 12.99448
2025-01-16 22:07:01.810474 Epoch 50, Train Y Loss = 12.40804,  Train X Loss = 10.79629, Val Loss = 13.02051
2025-01-16 22:07:42.903312 Epoch 51, Train Y Loss = 12.34155,  Train X Loss = 10.77297, Val Loss = 12.91757
2025-01-16 22:08:32.649321 Epoch 52, Train Y Loss = 12.32888,  Train X Loss = 10.77303, Val Loss = 12.91695
2025-01-16 22:09:20.592883 Epoch 53, Train Y Loss = 12.32836,  Train X Loss = 10.76390, Val Loss = 12.91596
2025-01-16 22:10:11.714638 Epoch 54, Train Y Loss = 12.32964,  Train X Loss = 10.78055, Val Loss = 12.91979
2025-01-16 22:10:59.724604 Epoch 55, Train Y Loss = 12.32599,  Train X Loss = 10.77072, Val Loss = 12.91467
2025-01-16 22:11:47.945033 Epoch 56, Train Y Loss = 12.32440,  Train X Loss = 10.77306, Val Loss = 12.91441
2025-01-16 22:12:36.307357 Epoch 57, Train Y Loss = 12.32045,  Train X Loss = 10.76184, Val Loss = 12.91883
2025-01-16 22:13:23.998942 Epoch 58, Train Y Loss = 12.32167,  Train X Loss = 10.76187, Val Loss = 12.92478
2025-01-16 22:14:12.040550 Epoch 59, Train Y Loss = 12.31882,  Train X Loss = 10.75335, Val Loss = 12.92182
2025-01-16 22:15:00.401310 Epoch 60, Train Y Loss = 12.31684,  Train X Loss = 10.76066, Val Loss = 12.92719
2025-01-16 22:15:51.721756 Epoch 61, Train Y Loss = 12.31586,  Train X Loss = 10.76071, Val Loss = 12.92313
2025-01-16 22:16:40.830638 Epoch 62, Train Y Loss = 12.31638,  Train X Loss = 10.77217, Val Loss = 12.93435
2025-01-16 22:17:28.574751 Epoch 63, Train Y Loss = 12.31495,  Train X Loss = 10.73247, Val Loss = 12.93337
Early stopping at epoch: 63
Best at epoch 33:
Train Loss = 12.56648
Train RMSE = 22.62897, MAE = 12.80398, MAPE = 8.40445
Val Loss = 12.90519
Val RMSE = 23.49339, MAE = 13.34335, MAPE = 9.79985
--------- Test ---------
All Steps RMSE = 22.67538, MAE = 13.22685, MAPE = 8.74938
Step 1 RMSE = 18.79852, MAE = 11.25958, MAPE = 7.45443
Step 2 RMSE = 20.15524, MAE = 11.91550, MAPE = 7.89802
Step 3 RMSE = 21.02429, MAE = 12.34136, MAPE = 8.11794
Step 4 RMSE = 21.69923, MAE = 12.65704, MAPE = 8.34949
Step 5 RMSE = 22.24819, MAE = 12.93476, MAPE = 8.50903
Step 6 RMSE = 22.71530, MAE = 13.16811, MAPE = 8.67408
Step 7 RMSE = 23.16943, MAE = 13.41245, MAPE = 8.86514
Step 8 RMSE = 23.53609, MAE = 13.61087, MAPE = 8.97937
Step 9 RMSE = 23.92431, MAE = 13.87114, MAPE = 9.22842
Step 10 RMSE = 24.24610, MAE = 14.07266, MAPE = 9.36430
Step 11 RMSE = 24.59284, MAE = 14.39674, MAPE = 9.55510
Step 12 RMSE = 25.11551, MAE = 15.08209, MAPE = 9.99730
Inference time: 3.41 s
