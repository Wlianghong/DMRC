PEMS04
--------- DMRCMLP ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        55
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 150,
    "early_stop": 30,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 34110658,
    "gpu": [
        1
    ],
    "save": false,
    "model_args": {
        "num_nodes": 307,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        390,540
├─Linear: 1-1                                 [16, 12, 307, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 307, 48]         --
│    └─Embedding: 2-1                         [16, 12, 307, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 307, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 307, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 307, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 307, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 307, 144]        158,224
├─Predictor: 1-4                              [16, 12, 307, 1]          --
│    └─Linear: 2-5                            [16, 12, 307, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 307, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 307, 144]        41,760
│    └─Linear: 2-7                            [16, 307, 12]             20,748
===============================================================================================
Total params: 1,155,712
Trainable params: 1,155,712
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.71
Forward/backward pass size (MB): 2758.11
Params size (MB): 3.06
Estimated Total Size (MB): 2761.88
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS04-2025-01-17-20-07-23.pt
2025-01-17 20:08:21.921656 Epoch 1, Train Y Loss = 28.20302,  Train X Loss = 0.00000, Val Loss = 24.26115
2025-01-17 20:09:20.604087 Epoch 2, Train Y Loss = 22.21778,  Train X Loss = 0.00000, Val Loss = 22.95424
2025-01-17 20:10:19.433419 Epoch 3, Train Y Loss = 20.80270,  Train X Loss = 0.00000, Val Loss = 20.72739
2025-01-17 20:11:18.259279 Epoch 4, Train Y Loss = 20.11371,  Train X Loss = 0.00000, Val Loss = 20.50986
2025-01-17 20:12:17.058681 Epoch 5, Train Y Loss = 19.42924,  Train X Loss = 0.00000, Val Loss = 20.49236
2025-01-17 20:13:15.733705 Epoch 6, Train Y Loss = 18.96795,  Train X Loss = 0.00000, Val Loss = 19.47979
2025-01-17 20:14:14.505421 Epoch 7, Train Y Loss = 18.64042,  Train X Loss = 0.00000, Val Loss = 18.86030
2025-01-17 20:15:13.255912 Epoch 8, Train Y Loss = 18.39470,  Train X Loss = 0.00000, Val Loss = 18.79223
2025-01-17 20:16:11.749664 Epoch 9, Train Y Loss = 18.07692,  Train X Loss = 0.00000, Val Loss = 19.09944
2025-01-17 20:17:10.304244 Epoch 10, Train Y Loss = 18.07371,  Train X Loss = 0.00000, Val Loss = 19.14946
2025-01-17 20:18:09.029181 Epoch 11, Train Y Loss = 17.69699,  Train X Loss = 0.00000, Val Loss = 18.85242
2025-01-17 20:19:07.715272 Epoch 12, Train Y Loss = 17.65458,  Train X Loss = 0.00000, Val Loss = 18.31913
2025-01-17 20:20:06.352259 Epoch 13, Train Y Loss = 17.52952,  Train X Loss = 0.00000, Val Loss = 18.36130
2025-01-17 20:21:05.004863 Epoch 14, Train Y Loss = 17.36088,  Train X Loss = 0.00000, Val Loss = 18.33203
2025-01-17 20:22:03.278928 Epoch 15, Train Y Loss = 17.26756,  Train X Loss = 0.00000, Val Loss = 18.12316
2025-01-17 20:23:02.023513 Epoch 16, Train Y Loss = 17.17754,  Train X Loss = 0.00000, Val Loss = 18.28692
2025-01-17 20:24:00.931942 Epoch 17, Train Y Loss = 17.09157,  Train X Loss = 0.00000, Val Loss = 18.12489
2025-01-17 20:24:59.487835 Epoch 18, Train Y Loss = 16.99404,  Train X Loss = 0.00000, Val Loss = 18.27040
2025-01-17 20:25:58.173866 Epoch 19, Train Y Loss = 16.93464,  Train X Loss = 0.00000, Val Loss = 18.39938
2025-01-17 20:26:56.727840 Epoch 20, Train Y Loss = 16.86519,  Train X Loss = 0.00000, Val Loss = 17.91370
2025-01-17 20:27:55.320091 Epoch 21, Train Y Loss = 16.23202,  Train X Loss = 0.00000, Val Loss = 17.59809
2025-01-17 20:28:53.930291 Epoch 22, Train Y Loss = 16.14825,  Train X Loss = 0.00000, Val Loss = 17.55472
2025-01-17 20:29:52.758961 Epoch 23, Train Y Loss = 16.10754,  Train X Loss = 0.00000, Val Loss = 17.53044
2025-01-17 20:30:51.516515 Epoch 24, Train Y Loss = 16.08374,  Train X Loss = 0.00000, Val Loss = 17.56188
2025-01-17 20:31:50.246075 Epoch 25, Train Y Loss = 16.05817,  Train X Loss = 0.00000, Val Loss = 17.52015
2025-01-17 20:32:48.984763 Epoch 26, Train Y Loss = 16.03371,  Train X Loss = 0.00000, Val Loss = 17.58570
2025-01-17 20:33:47.612789 Epoch 27, Train Y Loss = 16.00988,  Train X Loss = 0.00000, Val Loss = 17.55509
2025-01-17 20:34:46.483085 Epoch 28, Train Y Loss = 15.97474,  Train X Loss = 0.00000, Val Loss = 17.59200
2025-01-17 20:35:45.338531 Epoch 29, Train Y Loss = 15.95741,  Train X Loss = 0.00000, Val Loss = 17.54190
2025-01-17 20:36:44.073276 Epoch 30, Train Y Loss = 15.93996,  Train X Loss = 0.00000, Val Loss = 17.58931
2025-01-17 20:37:42.870060 Epoch 31, Train Y Loss = 15.91055,  Train X Loss = 0.00000, Val Loss = 17.57106
2025-01-17 20:38:41.395837 Epoch 32, Train Y Loss = 15.89842,  Train X Loss = 0.00000, Val Loss = 17.58615
2025-01-17 20:39:40.084273 Epoch 33, Train Y Loss = 15.88133,  Train X Loss = 0.00000, Val Loss = 17.56789
2025-01-17 20:40:38.581354 Epoch 34, Train Y Loss = 15.85729,  Train X Loss = 0.00000, Val Loss = 17.56720
2025-01-17 20:41:37.307137 Epoch 35, Train Y Loss = 15.83982,  Train X Loss = 0.00000, Val Loss = 17.53036
2025-01-17 20:42:35.794559 Epoch 36, Train Y Loss = 15.76289,  Train X Loss = 0.00000, Val Loss = 17.54800
2025-01-17 20:43:34.378804 Epoch 37, Train Y Loss = 15.75566,  Train X Loss = 0.00000, Val Loss = 17.53541
2025-01-17 20:44:32.810327 Epoch 38, Train Y Loss = 15.74930,  Train X Loss = 0.00000, Val Loss = 17.52976
2025-01-17 20:45:31.326516 Epoch 39, Train Y Loss = 15.74800,  Train X Loss = 0.00000, Val Loss = 17.54039
2025-01-17 20:46:29.990574 Epoch 40, Train Y Loss = 15.74426,  Train X Loss = 0.00000, Val Loss = 17.53757
2025-01-17 20:47:28.660769 Epoch 41, Train Y Loss = 15.74207,  Train X Loss = 0.00000, Val Loss = 17.54209
2025-01-17 20:48:27.494711 Epoch 42, Train Y Loss = 15.73814,  Train X Loss = 0.00000, Val Loss = 17.53711
2025-01-17 20:49:26.430211 Epoch 43, Train Y Loss = 15.73400,  Train X Loss = 0.00000, Val Loss = 17.53053
2025-01-17 20:50:25.059769 Epoch 44, Train Y Loss = 15.73591,  Train X Loss = 0.00000, Val Loss = 17.53641
2025-01-17 20:51:23.533663 Epoch 45, Train Y Loss = 15.72661,  Train X Loss = 0.00000, Val Loss = 17.54333
2025-01-17 20:52:22.264231 Epoch 46, Train Y Loss = 15.72357,  Train X Loss = 0.00000, Val Loss = 17.54181
2025-01-17 20:53:21.098476 Epoch 47, Train Y Loss = 15.72037,  Train X Loss = 0.00000, Val Loss = 17.53568
2025-01-17 20:54:19.786749 Epoch 48, Train Y Loss = 15.72636,  Train X Loss = 0.00000, Val Loss = 17.53337
2025-01-17 20:55:18.412336 Epoch 49, Train Y Loss = 15.71990,  Train X Loss = 0.00000, Val Loss = 17.56679
2025-01-17 20:56:17.199290 Epoch 50, Train Y Loss = 15.71700,  Train X Loss = 0.00000, Val Loss = 17.53406
2025-01-17 20:57:15.891716 Epoch 51, Train Y Loss = 15.71061,  Train X Loss = 0.00000, Val Loss = 17.53993
2025-01-17 20:58:14.653268 Epoch 52, Train Y Loss = 15.70818,  Train X Loss = 0.00000, Val Loss = 17.55307
2025-01-17 20:59:13.252811 Epoch 53, Train Y Loss = 15.70800,  Train X Loss = 0.00000, Val Loss = 17.55176
2025-01-17 21:00:12.089321 Epoch 54, Train Y Loss = 15.70729,  Train X Loss = 0.00000, Val Loss = 17.55608
2025-01-17 21:01:10.946074 Epoch 55, Train Y Loss = 15.70022,  Train X Loss = 0.00000, Val Loss = 17.53980
Early stopping at epoch: 55
Best at epoch 25:
Train Loss = 16.05817
Train RMSE = 27.61716, MAE = 16.50260, MAPE = 11.87706
Val Loss = 17.52015
Val RMSE = 30.50082, MAE = 18.18681, MAPE = 11.75513
--------- Test ---------
All Steps RMSE = 30.19714, MAE = 18.16573, MAPE = 11.99998
Step 1 RMSE = 26.99036, MAE = 16.53934, MAPE = 10.94849
Step 2 RMSE = 27.97294, MAE = 17.01569, MAPE = 11.28804
Step 3 RMSE = 28.73057, MAE = 17.40974, MAPE = 11.53435
Step 4 RMSE = 29.34753, MAE = 17.71697, MAPE = 11.70185
Step 5 RMSE = 29.86013, MAE = 17.97640, MAPE = 11.89486
Step 6 RMSE = 30.28895, MAE = 18.19800, MAPE = 11.98810
Step 7 RMSE = 30.66640, MAE = 18.39798, MAPE = 12.15241
Step 8 RMSE = 31.00933, MAE = 18.58652, MAPE = 12.25193
Step 9 RMSE = 31.30947, MAE = 18.76629, MAPE = 12.42155
Step 10 RMSE = 31.59584, MAE = 18.93035, MAPE = 12.45683
Step 11 RMSE = 31.90319, MAE = 19.12023, MAPE = 12.61476
Step 12 RMSE = 32.20618, MAE = 19.33105, MAPE = 12.74647
Inference time: 6.01 s
