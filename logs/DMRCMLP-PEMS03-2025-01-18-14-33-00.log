PEMS03
--------- DMRCMLP ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        20,
        35,
        50
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 8,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 34110658,
    "gpu": [
        3
    ],
    "save": false,
    "model_args": {
        "num_nodes": 358,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        434,604
├─Linear: 1-1                                 [16, 12, 358, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 358, 48]         --
│    └─Embedding: 2-1                         [16, 12, 358, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 358, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 358, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 358, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 358, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 358, 144]        158,224
├─Predictor: 1-4                              [16, 12, 358, 1]          --
│    └─Linear: 2-5                            [16, 12, 358, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 358, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 358, 144]        41,760
│    └─Linear: 2-7                            [16, 358, 12]             20,748
===============================================================================================
Total params: 1,199,776
Trainable params: 1,199,776
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 0.82
Forward/backward pass size (MB): 3216.29
Params size (MB): 3.06
Estimated Total Size (MB): 3220.18
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS03-2025-01-18-14-33-00.pt
2025-01-18 14:34:48.343479 Epoch 1, Train Y Loss = 20.84314,  Train X Loss = 0.00000, Val Loss = 16.91365
2025-01-18 14:36:36.379495 Epoch 2, Train Y Loss = 16.27215,  Train X Loss = 0.00000, Val Loss = 15.63370
2025-01-18 14:38:24.417838 Epoch 3, Train Y Loss = 15.08317,  Train X Loss = 0.00000, Val Loss = 14.63811
2025-01-18 14:40:12.560982 Epoch 4, Train Y Loss = 14.56462,  Train X Loss = 0.00000, Val Loss = 14.85396
2025-01-18 14:42:01.262433 Epoch 5, Train Y Loss = 14.19096,  Train X Loss = 0.00000, Val Loss = 15.22189
2025-01-18 14:43:49.801654 Epoch 6, Train Y Loss = 14.03101,  Train X Loss = 0.00000, Val Loss = 14.14531
2025-01-18 14:45:37.939566 Epoch 7, Train Y Loss = 13.65283,  Train X Loss = 0.00000, Val Loss = 14.10650
2025-01-18 14:47:25.576016 Epoch 8, Train Y Loss = 13.44156,  Train X Loss = 0.00000, Val Loss = 13.78468
2025-01-18 14:49:13.007706 Epoch 9, Train Y Loss = 13.32132,  Train X Loss = 0.00000, Val Loss = 14.29023
2025-01-18 14:51:00.407179 Epoch 10, Train Y Loss = 13.14937,  Train X Loss = 0.00000, Val Loss = 13.68681
2025-01-18 14:52:47.675559 Epoch 11, Train Y Loss = 13.04509,  Train X Loss = 0.00000, Val Loss = 13.45742
2025-01-18 14:54:35.187735 Epoch 12, Train Y Loss = 12.94334,  Train X Loss = 0.00000, Val Loss = 13.90373
2025-01-18 14:56:22.486690 Epoch 13, Train Y Loss = 12.79975,  Train X Loss = 0.00000, Val Loss = 13.43810
2025-01-18 14:58:09.858041 Epoch 14, Train Y Loss = 12.75205,  Train X Loss = 0.00000, Val Loss = 13.45966
2025-01-18 14:59:57.259642 Epoch 15, Train Y Loss = 12.68252,  Train X Loss = 0.00000, Val Loss = 13.38448
2025-01-18 15:01:44.511730 Epoch 16, Train Y Loss = 12.64118,  Train X Loss = 0.00000, Val Loss = 13.69274
2025-01-18 15:03:31.703731 Epoch 17, Train Y Loss = 12.50449,  Train X Loss = 0.00000, Val Loss = 13.31272
2025-01-18 15:05:19.441822 Epoch 18, Train Y Loss = 12.45002,  Train X Loss = 0.00000, Val Loss = 13.50579
2025-01-18 15:07:06.722374 Epoch 19, Train Y Loss = 12.44077,  Train X Loss = 0.00000, Val Loss = 13.22476
2025-01-18 15:08:54.113423 Epoch 20, Train Y Loss = 12.35305,  Train X Loss = 0.00000, Val Loss = 13.28951
2025-01-18 15:10:41.434447 Epoch 21, Train Y Loss = 11.88153,  Train X Loss = 0.00000, Val Loss = 12.89384
2025-01-18 15:12:28.457081 Epoch 22, Train Y Loss = 11.81170,  Train X Loss = 0.00000, Val Loss = 12.94556
2025-01-18 15:14:15.901885 Epoch 23, Train Y Loss = 11.78639,  Train X Loss = 0.00000, Val Loss = 12.93560
2025-01-18 15:16:03.031132 Epoch 24, Train Y Loss = 11.76507,  Train X Loss = 0.00000, Val Loss = 12.93653
2025-01-18 15:17:50.178593 Epoch 25, Train Y Loss = 11.74649,  Train X Loss = 0.00000, Val Loss = 12.94760
2025-01-18 15:19:37.229873 Epoch 26, Train Y Loss = 11.72882,  Train X Loss = 0.00000, Val Loss = 12.99940
2025-01-18 15:21:24.323752 Epoch 27, Train Y Loss = 11.71093,  Train X Loss = 0.00000, Val Loss = 12.97752
2025-01-18 15:23:11.702256 Epoch 28, Train Y Loss = 11.69519,  Train X Loss = 0.00000, Val Loss = 12.94803
2025-01-18 15:24:58.382203 Epoch 29, Train Y Loss = 11.68105,  Train X Loss = 0.00000, Val Loss = 12.92956
2025-01-18 15:26:45.523615 Epoch 30, Train Y Loss = 11.66742,  Train X Loss = 0.00000, Val Loss = 12.97416
2025-01-18 15:28:32.524263 Epoch 31, Train Y Loss = 11.65251,  Train X Loss = 0.00000, Val Loss = 12.97446
2025-01-18 15:30:19.762280 Epoch 32, Train Y Loss = 11.64091,  Train X Loss = 0.00000, Val Loss = 13.02995
2025-01-18 15:32:06.829894 Epoch 33, Train Y Loss = 11.62736,  Train X Loss = 0.00000, Val Loss = 12.98504
2025-01-18 15:33:53.905451 Epoch 34, Train Y Loss = 11.61414,  Train X Loss = 0.00000, Val Loss = 12.97494
2025-01-18 15:35:41.387904 Epoch 35, Train Y Loss = 11.60215,  Train X Loss = 0.00000, Val Loss = 12.99055
2025-01-18 15:37:28.580323 Epoch 36, Train Y Loss = 11.53704,  Train X Loss = 0.00000, Val Loss = 12.98657
2025-01-18 15:39:16.605080 Epoch 37, Train Y Loss = 11.52847,  Train X Loss = 0.00000, Val Loss = 12.95137
2025-01-18 15:41:05.010051 Epoch 38, Train Y Loss = 11.52575,  Train X Loss = 0.00000, Val Loss = 12.97381
2025-01-18 15:42:53.270001 Epoch 39, Train Y Loss = 11.52349,  Train X Loss = 0.00000, Val Loss = 12.99273
2025-01-18 15:44:40.659484 Epoch 40, Train Y Loss = 11.52118,  Train X Loss = 0.00000, Val Loss = 12.97592
2025-01-18 15:46:28.216236 Epoch 41, Train Y Loss = 11.51870,  Train X Loss = 0.00000, Val Loss = 12.99594
Early stopping at epoch: 41
Best at epoch 21:
Train Loss = 11.88153
Train RMSE = 20.30224, MAE = 12.21858, MAPE = 11.32943
Val Loss = 12.89384
Val RMSE = 21.81191, MAE = 13.41236, MAPE = 12.72119
--------- Test ---------
All Steps RMSE = 25.28410, MAE = 15.03458, MAPE = 15.32249
Step 1 RMSE = 19.54701, MAE = 12.40996, MAPE = 13.03741
Step 2 RMSE = 21.28292, MAE = 13.14781, MAPE = 13.68040
Step 3 RMSE = 22.63838, MAE = 13.73872, MAPE = 14.20726
Step 4 RMSE = 23.78796, MAE = 14.25450, MAPE = 14.62111
Step 5 RMSE = 24.63769, MAE = 14.67693, MAPE = 15.01230
Step 6 RMSE = 25.35075, MAE = 15.04517, MAPE = 15.38411
Step 7 RMSE = 26.06030, MAE = 15.42622, MAPE = 15.55813
Step 8 RMSE = 26.63163, MAE = 15.73882, MAPE = 15.86285
Step 9 RMSE = 27.16414, MAE = 16.05080, MAPE = 16.15942
Step 10 RMSE = 27.68704, MAE = 16.34915, MAPE = 16.44152
Step 11 RMSE = 28.14419, MAE = 16.62286, MAPE = 16.74505
Step 12 RMSE = 28.69496, MAE = 16.95409, MAPE = 17.16048
Inference time: 11.00 s
