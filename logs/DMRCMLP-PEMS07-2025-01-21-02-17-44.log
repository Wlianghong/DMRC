PEMS07
--------- DMRCMLP ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.001,
    "milestones": [
        20,
        40,
        55
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 120,
    "early_stop": 25,
    "use_cl": false,
    "cl_step_size": 2500,
    "adaptive_mask": false,
    "change_mask_ratio": 6,
    "ratio_decay": 0.5,
    "ratio_threshold": 0.02,
    "seed": 20436023,
    "gpu": [
        4,
        5
    ],
    "save": false,
    "model_args": {
        "num_nodes": 883,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "input_dim": 1,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "temporal_embedding_dim": 48,
        "spatial_embedding_dim": 0,
        "adaptive_embedding_dim": 72,
        "add_norm": false,
        "mask_ratio": 0.0,
        "use_recon": false,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_shared_layers": 2,
        "num_branch_layers": 2,
        "dropout": 0.1
    }
}
===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DMRCMLP                                       --                        888,204
├─Linear: 1-1                                 [16, 12, 883, 24]         48
├─TimeEmbedding: 1-2                          [16, 12, 883, 48]         --
│    └─Embedding: 2-1                         [16, 12, 883, 24]         6,912
│    └─Embedding: 2-2                         [16, 12, 883, 24]         168
├─ModuleList: 1-3                             --                        --
│    └─STAttnBlock: 2-3                       [16, 12, 883, 144]        --
│    │    └─SelfAttentionLayer: 3-1           [16, 12, 883, 144]        158,224
│    │    └─SelfAttentionLayer: 3-2           [16, 12, 883, 144]        158,224
│    └─STAttnBlock: 2-4                       [16, 12, 883, 144]        --
│    │    └─SelfAttentionLayer: 3-3           [16, 12, 883, 144]        158,224
│    │    └─SelfAttentionLayer: 3-4           [16, 12, 883, 144]        158,224
├─Predictor: 1-4                              [16, 12, 883, 1]          --
│    └─Linear: 2-5                            [16, 12, 883, 144]        20,880
│    └─ModuleList: 2-6                        --                        --
│    │    └─MultiLayerPerceptron: 3-5         [16, 12, 883, 144]        41,760
│    │    └─MultiLayerPerceptron: 3-6         [16, 12, 883, 144]        41,760
│    └─Linear: 2-7                            [16, 883, 12]             20,748
===============================================================================================
Total params: 1,653,376
Trainable params: 1,653,376
Non-trainable params: 0
Total mult-adds (M): 12.24
===============================================================================================
Input size (MB): 2.03
Forward/backward pass size (MB): 7932.93
Params size (MB): 3.06
Estimated Total Size (MB): 7938.02
===============================================================================================
Loss: LossFusion
Saved Model: saved_models/DMRCMLP-PEMS07-2025-01-21-02-17-44.pt
2025-01-21 02:21:17.198538 Epoch 1, Train Y Loss = 30.20906,  Train X Loss = 0.00000, Val Loss = 28.14057
2025-01-21 02:24:50.057020 Epoch 2, Train Y Loss = 23.71012,  Train X Loss = 0.00000, Val Loss = 23.29149
2025-01-21 02:28:21.828808 Epoch 3, Train Y Loss = 22.12532,  Train X Loss = 0.00000, Val Loss = 21.81285
2025-01-21 02:31:53.282407 Epoch 4, Train Y Loss = 21.30483,  Train X Loss = 0.00000, Val Loss = 21.09167
2025-01-21 02:35:24.575782 Epoch 5, Train Y Loss = 20.77145,  Train X Loss = 0.00000, Val Loss = 20.77148
2025-01-21 02:38:57.139519 Epoch 6, Train Y Loss = 20.28241,  Train X Loss = 0.00000, Val Loss = 20.83788
2025-01-21 02:42:29.744671 Epoch 7, Train Y Loss = 20.00944,  Train X Loss = 0.00000, Val Loss = 20.43507
2025-01-21 02:46:02.222189 Epoch 8, Train Y Loss = 19.80892,  Train X Loss = 0.00000, Val Loss = 19.81864
2025-01-21 02:49:33.936936 Epoch 9, Train Y Loss = 19.39538,  Train X Loss = 0.00000, Val Loss = 20.00231
2025-01-21 02:53:05.309786 Epoch 10, Train Y Loss = 19.24840,  Train X Loss = 0.00000, Val Loss = 19.42825
2025-01-21 02:56:37.248834 Epoch 11, Train Y Loss = 18.98155,  Train X Loss = 0.00000, Val Loss = 19.60386
2025-01-21 03:00:09.995914 Epoch 12, Train Y Loss = 18.79988,  Train X Loss = 0.00000, Val Loss = 19.73609
2025-01-21 03:03:41.992322 Epoch 13, Train Y Loss = 18.61929,  Train X Loss = 0.00000, Val Loss = 19.31462
2025-01-21 03:07:14.803440 Epoch 14, Train Y Loss = 18.54948,  Train X Loss = 0.00000, Val Loss = 19.27562
2025-01-21 03:10:46.606803 Epoch 15, Train Y Loss = 18.33920,  Train X Loss = 0.00000, Val Loss = 19.05415
2025-01-21 03:14:18.658284 Epoch 16, Train Y Loss = 18.26066,  Train X Loss = 0.00000, Val Loss = 19.16409
2025-01-21 03:17:51.431704 Epoch 17, Train Y Loss = 18.16951,  Train X Loss = 0.00000, Val Loss = 19.07783
2025-01-21 03:21:23.066646 Epoch 18, Train Y Loss = 18.03273,  Train X Loss = 0.00000, Val Loss = 18.94421
2025-01-21 03:24:55.494837 Epoch 19, Train Y Loss = 17.94236,  Train X Loss = 0.00000, Val Loss = 18.88015
2025-01-21 03:28:27.834285 Epoch 20, Train Y Loss = 17.89788,  Train X Loss = 0.00000, Val Loss = 18.75221
2025-01-21 03:31:59.872602 Epoch 21, Train Y Loss = 17.11024,  Train X Loss = 0.00000, Val Loss = 18.60236
2025-01-21 03:35:31.018998 Epoch 22, Train Y Loss = 16.99328,  Train X Loss = 0.00000, Val Loss = 18.64529
2025-01-21 03:39:02.722359 Epoch 23, Train Y Loss = 16.94029,  Train X Loss = 0.00000, Val Loss = 18.72235
2025-01-21 03:42:34.457418 Epoch 24, Train Y Loss = 16.89708,  Train X Loss = 0.00000, Val Loss = 18.73719
2025-01-21 03:46:06.897667 Epoch 25, Train Y Loss = 16.85689,  Train X Loss = 0.00000, Val Loss = 18.76786
2025-01-21 03:49:38.341497 Epoch 26, Train Y Loss = 16.81613,  Train X Loss = 0.00000, Val Loss = 18.77305
2025-01-21 03:53:10.670872 Epoch 27, Train Y Loss = 16.78201,  Train X Loss = 0.00000, Val Loss = 18.72230
2025-01-21 03:56:43.236475 Epoch 28, Train Y Loss = 16.75010,  Train X Loss = 0.00000, Val Loss = 18.77800
2025-01-21 04:00:15.687071 Epoch 29, Train Y Loss = 16.71404,  Train X Loss = 0.00000, Val Loss = 18.91683
2025-01-21 04:03:47.621156 Epoch 30, Train Y Loss = 16.68644,  Train X Loss = 0.00000, Val Loss = 18.95099
2025-01-21 04:07:19.605290 Epoch 31, Train Y Loss = 16.65227,  Train X Loss = 0.00000, Val Loss = 19.02872
2025-01-21 04:10:52.371063 Epoch 32, Train Y Loss = 16.62382,  Train X Loss = 0.00000, Val Loss = 19.04589
2025-01-21 04:14:24.324178 Epoch 33, Train Y Loss = 16.59244,  Train X Loss = 0.00000, Val Loss = 19.11605
2025-01-21 04:17:55.441997 Epoch 34, Train Y Loss = 16.56370,  Train X Loss = 0.00000, Val Loss = 19.09700
2025-01-21 04:21:28.384037 Epoch 35, Train Y Loss = 16.53748,  Train X Loss = 0.00000, Val Loss = 19.17527
2025-01-21 04:25:00.810624 Epoch 36, Train Y Loss = 16.50605,  Train X Loss = 0.00000, Val Loss = 19.22490
2025-01-21 04:28:33.207820 Epoch 37, Train Y Loss = 16.47832,  Train X Loss = 0.00000, Val Loss = 19.20783
2025-01-21 04:32:05.403311 Epoch 38, Train Y Loss = 16.45208,  Train X Loss = 0.00000, Val Loss = 19.16789
2025-01-21 04:35:38.477307 Epoch 39, Train Y Loss = 16.42567,  Train X Loss = 0.00000, Val Loss = 19.35580
2025-01-21 04:39:10.268282 Epoch 40, Train Y Loss = 16.39990,  Train X Loss = 0.00000, Val Loss = 19.24197
2025-01-21 04:42:42.586395 Epoch 41, Train Y Loss = 16.27841,  Train X Loss = 0.00000, Val Loss = 19.34850
2025-01-21 04:46:14.565368 Epoch 42, Train Y Loss = 16.26185,  Train X Loss = 0.00000, Val Loss = 19.34900
2025-01-21 04:49:46.045486 Epoch 43, Train Y Loss = 16.25642,  Train X Loss = 0.00000, Val Loss = 19.38043
2025-01-21 04:53:17.915273 Epoch 44, Train Y Loss = 16.24996,  Train X Loss = 0.00000, Val Loss = 19.37098
2025-01-21 04:56:50.282059 Epoch 45, Train Y Loss = 16.24276,  Train X Loss = 0.00000, Val Loss = 19.38808
2025-01-21 05:00:22.729715 Epoch 46, Train Y Loss = 16.23878,  Train X Loss = 0.00000, Val Loss = 19.41871
Early stopping at epoch: 46
Best at epoch 21:
Train Loss = 17.11024
Train RMSE = 29.98749, MAE = 17.37905, MAPE = 7.63927
Val Loss = 18.60236
Val RMSE = 32.64633, MAE = 19.12772, MAPE = 8.25153
--------- Test ---------
All Steps RMSE = 33.25718, MAE = 19.68187, MAPE = 8.12818
Step 1 RMSE = 27.08423, MAE = 16.55682, MAPE = 6.97022
Step 2 RMSE = 29.09969, MAE = 17.47371, MAPE = 7.29602
Step 3 RMSE = 30.49423, MAE = 18.18658, MAPE = 7.53513
Step 4 RMSE = 31.59995, MAE = 18.77435, MAPE = 7.75888
Step 5 RMSE = 32.56272, MAE = 19.29887, MAPE = 7.96779
Step 6 RMSE = 33.33249, MAE = 19.71645, MAPE = 8.12307
Step 7 RMSE = 34.08888, MAE = 20.15679, MAPE = 8.27998
Step 8 RMSE = 34.75261, MAE = 20.53508, MAPE = 8.44011
Step 9 RMSE = 35.31005, MAE = 20.85764, MAPE = 8.55674
Step 10 RMSE = 35.87191, MAE = 21.20756, MAPE = 8.70557
Step 11 RMSE = 36.39798, MAE = 21.53527, MAPE = 8.85636
Step 12 RMSE = 36.93172, MAE = 21.88022, MAPE = 9.04720
Inference time: 27.79 s
